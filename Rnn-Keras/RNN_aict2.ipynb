{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZrAZl1IoeVEA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, BatchNormalization, LSTM, Discretization, Dropout,TimeDistributed, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "carregando_clear = np.load('/content/drive/MyDrive/CLEAR(1).npy', mmap_mode='r')\n",
        "dados_clear = carregando_clear[:5000]\n",
        "\n",
        "carregamento_lte1m = np.load('/content/drive/MyDrive/LTE_1M.npy', mmap_mode='r')\n",
        "dados_lte1m = carregamento_lte1m[:5000]\n",
        "\n",
        "dados_wifi = np.load('/content/drive/MyDrive/WIFI.npy', mmap_mode='r')\n",
        "dados_wifi = carregamento_lte1m[:5000]"
      ],
      "metadata": {
        "id": "44xSL0mxsWmN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dados_clear.shape,dados_lte1m.shape,dados_wifi.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V6vXss7qqAr",
        "outputId": "46952316-c484-4b08-9956-d859424b7c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 1) (5000, 1) (5000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "  def separate_complex_column(data):\n",
        "  # Separar a parte real e imagin√°ria em duas colunas\n",
        "      real_part = data.real\n",
        "      imag_part = data.imag\n",
        "      return real_part,imag_part\n",
        "\n",
        "  def montando_datasets(dados_1, dados_2):\n",
        "  # juntando os dados\n",
        "      real1, imag1 = separate_complex_column(dados_1)\n",
        "      real2, imag2 = separate_complex_column(dados_2)\n",
        "      atributos1 = np.ones(len(dados_1))\n",
        "      atributos2 = np.zeros(len(dados_2))\n",
        "      dados1 = np.column_stack((real1, imag1, atributos1))\n",
        "      dados2 = np.column_stack((real2, imag2, atributos2))\n",
        "      conjunto = np.vstack([dados1, dados2])\n",
        "      indices = np.random.permutation(len(conjunto))\n",
        "      data = conjunto[indices]\n",
        "      return data\n",
        "\n",
        "  def remodelar(data,feture):\n",
        "  # remodelando os dados\n",
        "      df = pd.DataFrame(data, columns =  ['real','imag', 'clfq'] )\n",
        "      df_junt = df[['real', 'imag']].to_numpy()\n",
        "      data_dim = df_junt.reshape(len(data)//100, 100, feture)\n",
        "      data_dim = data_dim.astype(np.float32)\n",
        "      alvo = df['clfq'].values\n",
        "      alvo_dim = alvo.reshape(len(alvo)//100,100, feture-1)\n",
        "      alvo_dim = alvo_dim.astype(np.float32)\n",
        "      return data_dim,alvo_dim\n",
        "\n",
        "\n",
        "def processos(dados_1,dados_2,feture): \n",
        "    data = montando_datasets(dados_1, dados_2)\n",
        "    X , Y = remodelar(data,feture)\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "Zdh3dlB0skIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = processos(dados_clear, dados_lte1m,2)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdXlV2W9uRLD",
        "outputId": "52c6ac2b-4f35-4b15-bf62-9b30b2df74ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-3.0518622e-05  0.0000000e+00]\n",
            "  [ 3.0518622e-05  1.5259311e-04]\n",
            "  [ 9.1555863e-05  2.7466760e-04]\n",
            "  ...\n",
            "  [ 2.1363035e-04  3.0518622e-05]\n",
            "  [-2.1363035e-04 -1.5259311e-04]\n",
            "  [ 2.4414898e-04 -1.2207449e-04]]\n",
            "\n",
            " [[-9.1555863e-05  6.1037244e-05]\n",
            "  [ 0.0000000e+00  6.1037244e-05]\n",
            "  [ 3.0518622e-05 -6.1037244e-05]\n",
            "  ...\n",
            "  [ 2.1363035e-04  3.0518622e-05]\n",
            "  [ 2.7466760e-04  3.0518622e-05]\n",
            "  [ 0.0000000e+00 -1.8311173e-04]]\n",
            "\n",
            " [[ 9.1555863e-05  1.5259311e-04]\n",
            "  [ 1.5259311e-04 -6.1037244e-05]\n",
            "  [-3.0518622e-05 -6.1037244e-05]\n",
            "  ...\n",
            "  [ 9.1555863e-05 -1.5259311e-04]\n",
            "  [-1.8311173e-04  3.0518622e-05]\n",
            "  [-1.5259311e-04  2.1363035e-04]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 2.1363035e-04  2.1363035e-04]\n",
            "  [ 3.0518622e-05  3.0518622e-05]\n",
            "  [-9.1555863e-05  0.0000000e+00]\n",
            "  ...\n",
            "  [ 3.0518622e-05 -9.1555863e-05]\n",
            "  [-2.7466760e-04 -1.5259311e-04]\n",
            "  [-1.2207449e-04 -3.0518622e-05]]\n",
            "\n",
            " [[-9.1555863e-05 -9.1555863e-05]\n",
            "  [ 0.0000000e+00  2.7466760e-04]\n",
            "  [-1.5259311e-04 -1.5259311e-04]\n",
            "  ...\n",
            "  [ 3.0518622e-05  1.8311173e-04]\n",
            "  [ 6.1037244e-05  6.1037244e-05]\n",
            "  [ 3.0518622e-05  0.0000000e+00]]\n",
            "\n",
            " [[ 2.4414898e-04 -1.2207449e-04]\n",
            "  [ 3.3570486e-04  9.1555863e-05]\n",
            "  [ 3.3570486e-04  3.0518622e-05]\n",
            "  ...\n",
            "  [-9.1555863e-05 -2.4414898e-04]\n",
            "  [ 0.0000000e+00 -1.2207449e-04]\n",
            "  [-9.1555863e-05  6.1037244e-05]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clear x Lte1m"
      ],
      "metadata": {
        "id": "m--2M6J9mH0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=None, train_size=0.7,random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape=(None, 2)))\n",
        "model.add(SimpleRNN(units=528,input_shape=(None, 2),activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\",return_sequences=True))\n",
        "model.add(SimpleRNN(units=264,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(SimpleRNN(units=128, activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(SimpleRNN(units=64,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\",return_sequences=True))\n",
        "model.add(Dense(units=32,activation='tanh'))\n",
        "model.add(Dense(units=16,activation=\"relu\"))\n",
        "model.add(Dense(units=8, activation='tanh'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "opt = Adamax(\n",
        "    learning_rate=0.0003,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer =opt, metrics=['accuracy','AUC', 'Precision', 'Recall'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2J-Tmott59c",
        "outputId": "056f524a-a31d-4110-c53c-06ae55d82383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 7s 363ms/step - loss: 0.6940 - accuracy: 0.4916 - auc: 0.4938 - precision: 0.4778 - recall: 0.1409\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 384ms/step - loss: 0.6937 - accuracy: 0.5040 - auc: 0.4944 - precision: 0.5070 - recall: 0.4204\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 365ms/step - loss: 0.6940 - accuracy: 0.5004 - auc: 0.5045 - precision: 0.5046 - recall: 0.2474\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 2s 558ms/step - loss: 0.6936 - accuracy: 0.5029 - auc: 0.5071 - precision: 0.5032 - recall: 0.7492\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 629ms/step - loss: 0.6934 - accuracy: 0.4993 - auc: 0.4968 - precision: 0.5010 - recall: 0.5716\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 477ms/step - loss: 0.6929 - accuracy: 0.5047 - auc: 0.5141 - precision: 0.5040 - recall: 0.8235\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 0.6930 - accuracy: 0.5086 - auc: 0.5112 - precision: 0.5066 - recall: 0.8002\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 1s 370ms/step - loss: 0.6928 - accuracy: 0.5071 - auc: 0.5152 - precision: 0.5059 - recall: 0.7640\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 1s 380ms/step - loss: 0.6931 - accuracy: 0.5039 - auc: 0.5075 - precision: 0.5093 - recall: 0.3126\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 1s 369ms/step - loss: 0.6929 - accuracy: 0.5106 - auc: 0.5153 - precision: 0.5141 - recall: 0.4509\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.6928 - accuracy: 0.5089 - auc: 0.5176 - precision: 0.5068 - recall: 0.7993\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 1s 378ms/step - loss: 0.6928 - accuracy: 0.5116 - auc: 0.5184 - precision: 0.5121 - recall: 0.5679\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 1s 370ms/step - loss: 0.6929 - accuracy: 0.5099 - auc: 0.5140 - precision: 0.5177 - recall: 0.3410\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 440ms/step - loss: 0.6928 - accuracy: 0.5046 - auc: 0.5153 - precision: 0.5053 - recall: 0.6066\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 2s 660ms/step - loss: 0.6925 - accuracy: 0.5149 - auc: 0.5259 - precision: 0.5113 - recall: 0.7506\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 2s 569ms/step - loss: 0.6923 - accuracy: 0.5177 - auc: 0.5292 - precision: 0.5147 - recall: 0.6806\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 1s 395ms/step - loss: 0.6920 - accuracy: 0.5256 - auc: 0.5365 - precision: 0.5214 - recall: 0.6672\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 0.6918 - accuracy: 0.5233 - auc: 0.5362 - precision: 0.5194 - recall: 0.6707\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 1s 380ms/step - loss: 0.6914 - accuracy: 0.5261 - auc: 0.5436 - precision: 0.5243 - recall: 0.6015\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 1s 371ms/step - loss: 0.6912 - accuracy: 0.5317 - auc: 0.5440 - precision: 0.5359 - recall: 0.4990\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 1s 376ms/step - loss: 0.6906 - accuracy: 0.5340 - auc: 0.5506 - precision: 0.5329 - recall: 0.5790\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 1s 373ms/step - loss: 0.6901 - accuracy: 0.5347 - auc: 0.5534 - precision: 0.5330 - recall: 0.5890\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 1s 366ms/step - loss: 0.6896 - accuracy: 0.5394 - auc: 0.5581 - precision: 0.5399 - recall: 0.5562\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 1s 390ms/step - loss: 0.6892 - accuracy: 0.5424 - auc: 0.5578 - precision: 0.5424 - recall: 0.5642\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 2s 653ms/step - loss: 0.6886 - accuracy: 0.5407 - auc: 0.5632 - precision: 0.5436 - recall: 0.5283\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 2s 624ms/step - loss: 0.6884 - accuracy: 0.5416 - auc: 0.5606 - precision: 0.5406 - recall: 0.5756\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.6880 - accuracy: 0.5429 - auc: 0.5643 - precision: 0.5379 - recall: 0.6322\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.6873 - accuracy: 0.5473 - auc: 0.5713 - precision: 0.5460 - recall: 0.5807\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 1s 385ms/step - loss: 0.6870 - accuracy: 0.5510 - auc: 0.5716 - precision: 0.5590 - recall: 0.4993\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 0.6865 - accuracy: 0.5484 - auc: 0.5707 - precision: 0.5582 - recall: 0.4805\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 1s 367ms/step - loss: 0.6857 - accuracy: 0.5541 - auc: 0.5791 - precision: 0.5652 - recall: 0.4833\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 1s 385ms/step - loss: 0.6858 - accuracy: 0.5570 - auc: 0.5811 - precision: 0.5660 - recall: 0.5030\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 1s 369ms/step - loss: 0.6846 - accuracy: 0.5619 - auc: 0.5883 - precision: 0.5712 - recall: 0.5090\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 1s 378ms/step - loss: 0.6842 - accuracy: 0.5639 - auc: 0.5892 - precision: 0.5682 - recall: 0.5457\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 2s 837ms/step - loss: 0.6830 - accuracy: 0.5611 - auc: 0.5933 - precision: 0.5620 - recall: 0.5693\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 573ms/step - loss: 0.6824 - accuracy: 0.5666 - auc: 0.5953 - precision: 0.5665 - recall: 0.5810\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 1s 370ms/step - loss: 0.6813 - accuracy: 0.5686 - auc: 0.5993 - precision: 0.5728 - recall: 0.5522\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 1s 381ms/step - loss: 0.6811 - accuracy: 0.5676 - auc: 0.5993 - precision: 0.5758 - recall: 0.5252\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 1s 364ms/step - loss: 0.6802 - accuracy: 0.5701 - auc: 0.6036 - precision: 0.5758 - recall: 0.5451\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 1s 386ms/step - loss: 0.6788 - accuracy: 0.5806 - auc: 0.6133 - precision: 0.5833 - recall: 0.5753\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 1s 380ms/step - loss: 0.6784 - accuracy: 0.5756 - auc: 0.6102 - precision: 0.5767 - recall: 0.5798\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 1s 372ms/step - loss: 0.6777 - accuracy: 0.5769 - auc: 0.6123 - precision: 0.5813 - recall: 0.5605\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 1s 372ms/step - loss: 0.6764 - accuracy: 0.5811 - auc: 0.6177 - precision: 0.5921 - recall: 0.5317\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.6758 - accuracy: 0.5811 - auc: 0.6197 - precision: 0.5906 - recall: 0.5391\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 2s 619ms/step - loss: 0.6750 - accuracy: 0.5871 - auc: 0.6248 - precision: 0.5941 - recall: 0.5599\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 2s 620ms/step - loss: 0.6736 - accuracy: 0.5913 - auc: 0.6305 - precision: 0.5944 - recall: 0.5844\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 1s 366ms/step - loss: 0.6725 - accuracy: 0.5933 - auc: 0.6343 - precision: 0.5918 - recall: 0.6112\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 1s 402ms/step - loss: 0.6712 - accuracy: 0.5960 - auc: 0.6360 - precision: 0.5979 - recall: 0.5952\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 0.6690 - accuracy: 0.6006 - auc: 0.6446 - precision: 0.6072 - recall: 0.5779\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 2s 626ms/step - loss: 0.6686 - accuracy: 0.5997 - auc: 0.6450 - precision: 0.6036 - recall: 0.5895\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 650ms/step - loss: 0.6671 - accuracy: 0.6010 - auc: 0.6477 - precision: 0.6088 - recall: 0.5736\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.6653 - accuracy: 0.6031 - auc: 0.6511 - precision: 0.6128 - recall: 0.5682\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 1s 448ms/step - loss: 0.6643 - accuracy: 0.6056 - auc: 0.6548 - precision: 0.6090 - recall: 0.5978\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 2s 635ms/step - loss: 0.6621 - accuracy: 0.6114 - auc: 0.6632 - precision: 0.6180 - recall: 0.5912\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 584ms/step - loss: 0.6608 - accuracy: 0.6120 - auc: 0.6641 - precision: 0.6257 - recall: 0.5645\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 1s 382ms/step - loss: 0.6588 - accuracy: 0.6157 - auc: 0.6703 - precision: 0.6308 - recall: 0.5650\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 0.6565 - accuracy: 0.6271 - auc: 0.6778 - precision: 0.6437 - recall: 0.5756\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 0.6543 - accuracy: 0.6307 - auc: 0.6859 - precision: 0.6427 - recall: 0.5949\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 1s 372ms/step - loss: 0.6537 - accuracy: 0.6279 - auc: 0.6825 - precision: 0.6448 - recall: 0.5756\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 1s 398ms/step - loss: 0.6516 - accuracy: 0.6340 - auc: 0.6897 - precision: 0.6571 - recall: 0.5662\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 1s 378ms/step - loss: 0.6492 - accuracy: 0.6396 - auc: 0.6955 - precision: 0.6599 - recall: 0.5816\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 1s 405ms/step - loss: 0.6468 - accuracy: 0.6381 - auc: 0.6974 - precision: 0.6557 - recall: 0.5875\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 1s 411ms/step - loss: 0.6457 - accuracy: 0.6400 - auc: 0.7015 - precision: 0.6543 - recall: 0.5992\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 2s 623ms/step - loss: 0.6443 - accuracy: 0.6436 - auc: 0.7011 - precision: 0.6541 - recall: 0.6149\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 2s 642ms/step - loss: 0.6409 - accuracy: 0.6500 - auc: 0.7079 - precision: 0.6636 - recall: 0.6137\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 1s 378ms/step - loss: 0.6402 - accuracy: 0.6473 - auc: 0.7112 - precision: 0.6605 - recall: 0.6114\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 1s 388ms/step - loss: 0.6365 - accuracy: 0.6540 - auc: 0.7191 - precision: 0.6753 - recall: 0.5981\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 1s 376ms/step - loss: 0.6344 - accuracy: 0.6499 - auc: 0.7189 - precision: 0.6751 - recall: 0.5827\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.6310 - accuracy: 0.6591 - auc: 0.7278 - precision: 0.6818 - recall: 0.6015\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 1s 388ms/step - loss: 0.6275 - accuracy: 0.6659 - auc: 0.7324 - precision: 0.6910 - recall: 0.6046\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 0.6260 - accuracy: 0.6656 - auc: 0.7338 - precision: 0.6776 - recall: 0.6365\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 1s 372ms/step - loss: 0.6217 - accuracy: 0.6720 - auc: 0.7441 - precision: 0.6778 - recall: 0.6604\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 1s 381ms/step - loss: 0.6205 - accuracy: 0.6751 - auc: 0.7445 - precision: 0.6845 - recall: 0.6541\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 2s 626ms/step - loss: 0.6184 - accuracy: 0.6750 - auc: 0.7456 - precision: 0.6919 - recall: 0.6354\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 2s 635ms/step - loss: 0.6174 - accuracy: 0.6723 - auc: 0.7451 - precision: 0.6832 - recall: 0.6470\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 1s 376ms/step - loss: 0.6138 - accuracy: 0.6760 - auc: 0.7509 - precision: 0.6840 - recall: 0.6587\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 0.6113 - accuracy: 0.6813 - auc: 0.7544 - precision: 0.7004 - recall: 0.6376\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 1s 365ms/step - loss: 0.6087 - accuracy: 0.6864 - auc: 0.7598 - precision: 0.7010 - recall: 0.6541\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 1s 393ms/step - loss: 0.6066 - accuracy: 0.6936 - auc: 0.7649 - precision: 0.7058 - recall: 0.6678\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 1s 392ms/step - loss: 0.6026 - accuracy: 0.6949 - auc: 0.7698 - precision: 0.7022 - recall: 0.6806\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 1s 385ms/step - loss: 0.6011 - accuracy: 0.6936 - auc: 0.7700 - precision: 0.7045 - recall: 0.6707\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 1s 368ms/step - loss: 0.5955 - accuracy: 0.7001 - auc: 0.7785 - precision: 0.7075 - recall: 0.6863\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 0.5952 - accuracy: 0.6974 - auc: 0.7750 - precision: 0.7035 - recall: 0.6863\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 2s 636ms/step - loss: 0.5908 - accuracy: 0.7103 - auc: 0.7871 - precision: 0.7160 - recall: 0.7005\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 2s 622ms/step - loss: 0.5853 - accuracy: 0.7110 - auc: 0.7928 - precision: 0.7196 - recall: 0.6948\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 1s 369ms/step - loss: 0.5826 - accuracy: 0.7129 - auc: 0.7941 - precision: 0.7299 - recall: 0.6792\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 1s 392ms/step - loss: 0.5768 - accuracy: 0.7186 - auc: 0.8049 - precision: 0.7302 - recall: 0.6966\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.5742 - accuracy: 0.7237 - auc: 0.8074 - precision: 0.7357 - recall: 0.7014\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 0.5711 - accuracy: 0.7281 - auc: 0.8110 - precision: 0.7369 - recall: 0.7128\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 1s 380ms/step - loss: 0.5679 - accuracy: 0.7306 - auc: 0.8124 - precision: 0.7384 - recall: 0.7173\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 1s 385ms/step - loss: 0.5623 - accuracy: 0.7354 - auc: 0.8187 - precision: 0.7458 - recall: 0.7173\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 1s 368ms/step - loss: 0.5605 - accuracy: 0.7341 - auc: 0.8190 - precision: 0.7442 - recall: 0.7165\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.5547 - accuracy: 0.7414 - auc: 0.8261 - precision: 0.7502 - recall: 0.7267\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 2s 626ms/step - loss: 0.5524 - accuracy: 0.7429 - auc: 0.8281 - precision: 0.7551 - recall: 0.7216\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 2s 619ms/step - loss: 0.5506 - accuracy: 0.7380 - auc: 0.8268 - precision: 0.7556 - recall: 0.7065\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 2s 396ms/step - loss: 0.5506 - accuracy: 0.7430 - auc: 0.8270 - precision: 0.7614 - recall: 0.7105\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 1s 384ms/step - loss: 0.5439 - accuracy: 0.7506 - auc: 0.8356 - precision: 0.7618 - recall: 0.7319\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 1s 368ms/step - loss: 0.5457 - accuracy: 0.7467 - auc: 0.8308 - precision: 0.7568 - recall: 0.7299\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 1s 382ms/step - loss: 0.5364 - accuracy: 0.7580 - auc: 0.8402 - precision: 0.7681 - recall: 0.7418\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 0.5327 - accuracy: 0.7594 - auc: 0.8428 - precision: 0.7723 - recall: 0.7384\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_9 (Batc  (None, None, 2)          8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " simple_rnn_36 (SimpleRNN)   (None, None, 528)         280368    \n",
            "                                                                 \n",
            " simple_rnn_37 (SimpleRNN)   (None, None, 264)         209352    \n",
            "                                                                 \n",
            " simple_rnn_38 (SimpleRNN)   (None, None, 128)         50304     \n",
            "                                                                 \n",
            " simple_rnn_39 (SimpleRNN)   (None, None, 64)          12352     \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, None, 32)          2080      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, None, 16)          528       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, None, 1)           9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 555,137\n",
            "Trainable params: 555,133\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model.predict(X_test)\n",
        "trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test.flatten(), trainPredict_binary.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rAS8hAcxIqj",
        "outputId": "0eeb92b9-1517-4e1c-f041-91073b6cc8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb526027370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 696ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i2enp3hmuqL",
        "outputId": "fb5ab4e7-9396-474a-d449-da21ef5d363a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[570 958]\n",
            " [578 894]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clear x Wifi"
      ],
      "metadata": {
        "id": "R1aWRvcImWSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape=(None, 2)))\n",
        "model.add(SimpleRNN(units=528,input_shape=(None, 2),activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\",return_sequences=True))\n",
        "model.add(SimpleRNN(units=264,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(SimpleRNN(units=128, activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(SimpleRNN(units=64,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\",return_sequences=True))\n",
        "model.add(Dense(units=32,activation='tanh'))\n",
        "model.add(Dense(units=16,activation=\"relu\"))\n",
        "model.add(Dense(units=8, activation='tanh'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "opt = Adamax(\n",
        "    learning_rate=0.0003,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07)\n",
        "X2,Y2 = processos(dados_clear, dados_wifi,2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X2, Y2, test_size=None, train_size=0.7,random_state=42)\n",
        "model.compile(loss='binary_crossentropy', optimizer =opt, metrics=['accuracy','AUC', 'Precision', 'Recall'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4WZ5GS0bg4C",
        "outputId": "701f8629-552f-4f13-eae9-de262bccfa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 53s 424ms/step - loss: 0.6942 - accuracy: 0.5056 - auc: 0.5096 - precision: 0.5079 - recall: 0.6083\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.6957 - accuracy: 0.5014 - auc: 0.4961 - precision: 0.5046 - recall: 0.5859\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6951 - accuracy: 0.4994 - auc: 0.4946 - precision: 0.5032 - recall: 0.5272\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.6944 - accuracy: 0.4983 - auc: 0.4988 - precision: 0.5019 - recall: 0.5876\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.6950 - accuracy: 0.5033 - auc: 0.5056 - precision: 0.5048 - recall: 0.7611\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.6930 - accuracy: 0.5166 - auc: 0.5175 - precision: 0.5166 - recall: 0.6352\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 0.6933 - accuracy: 0.5049 - auc: 0.5094 - precision: 0.5106 - recall: 0.4246\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 3s 536ms/step - loss: 0.6931 - accuracy: 0.5049 - auc: 0.5108 - precision: 0.5095 - recall: 0.4714\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 347ms/step - loss: 0.6929 - accuracy: 0.5080 - auc: 0.5120 - precision: 0.5109 - recall: 0.5590\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.6932 - accuracy: 0.5120 - auc: 0.5137 - precision: 0.5136 - recall: 0.6006\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 324ms/step - loss: 0.6929 - accuracy: 0.5069 - auc: 0.5141 - precision: 0.5090 - recall: 0.6063\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 0.6930 - accuracy: 0.5094 - auc: 0.5111 - precision: 0.5139 - recall: 0.4929\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.6936 - accuracy: 0.4996 - auc: 0.5018 - precision: 0.5041 - recall: 0.4334\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 0.6934 - accuracy: 0.5064 - auc: 0.5085 - precision: 0.5092 - recall: 0.5731\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.6935 - accuracy: 0.5100 - auc: 0.5079 - precision: 0.5100 - recall: 0.7095\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 3s 550ms/step - loss: 0.6938 - accuracy: 0.5023 - auc: 0.5062 - precision: 0.5048 - recall: 0.6494\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 0.6938 - accuracy: 0.4946 - auc: 0.4930 - precision: 0.4985 - recall: 0.4841\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.6929 - accuracy: 0.5109 - auc: 0.5154 - precision: 0.5182 - recall: 0.4201\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 0.6930 - accuracy: 0.5081 - auc: 0.5087 - precision: 0.5105 - recall: 0.5873\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 318ms/step - loss: 0.6927 - accuracy: 0.5153 - auc: 0.5183 - precision: 0.5139 - recall: 0.7086\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.6929 - accuracy: 0.5133 - auc: 0.5128 - precision: 0.5125 - recall: 0.7010\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 0.6926 - accuracy: 0.5174 - auc: 0.5196 - precision: 0.5144 - recall: 0.7616\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 0.6923 - accuracy: 0.5213 - auc: 0.5210 - precision: 0.5183 - recall: 0.7120\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.6925 - accuracy: 0.5147 - auc: 0.5198 - precision: 0.5144 - recall: 0.6621\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.6926 - accuracy: 0.5151 - auc: 0.5179 - precision: 0.5146 - recall: 0.6712\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.6925 - accuracy: 0.5217 - auc: 0.5218 - precision: 0.5186 - recall: 0.7103\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.6925 - accuracy: 0.5173 - auc: 0.5232 - precision: 0.5170 - recall: 0.6437\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.6924 - accuracy: 0.5170 - auc: 0.5205 - precision: 0.5187 - recall: 0.5785\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6929 - accuracy: 0.5204 - auc: 0.5172 - precision: 0.5208 - recall: 0.6077\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 0.6928 - accuracy: 0.5159 - auc: 0.5161 - precision: 0.5151 - recall: 0.6709\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 3s 547ms/step - loss: 0.6930 - accuracy: 0.5113 - auc: 0.5098 - precision: 0.5117 - recall: 0.6610\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.6925 - accuracy: 0.5211 - auc: 0.5207 - precision: 0.5239 - recall: 0.5468\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 0.6926 - accuracy: 0.5154 - auc: 0.5214 - precision: 0.5189 - recall: 0.5298\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.6931 - accuracy: 0.5164 - auc: 0.5141 - precision: 0.5170 - recall: 0.6168\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.6933 - accuracy: 0.5123 - auc: 0.5100 - precision: 0.5135 - recall: 0.6162\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 0.6931 - accuracy: 0.5184 - auc: 0.5096 - precision: 0.5169 - recall: 0.6814\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6928 - accuracy: 0.5101 - auc: 0.5127 - precision: 0.5094 - recall: 0.7574\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.6929 - accuracy: 0.5141 - auc: 0.5128 - precision: 0.5132 - recall: 0.7007\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 3s 532ms/step - loss: 0.6924 - accuracy: 0.5151 - auc: 0.5209 - precision: 0.5173 - recall: 0.5672\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.6918 - accuracy: 0.5237 - auc: 0.5296 - precision: 0.5247 - recall: 0.5848\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 3s 546ms/step - loss: 0.6919 - accuracy: 0.5210 - auc: 0.5283 - precision: 0.5194 - recall: 0.6644\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6922 - accuracy: 0.5174 - auc: 0.5253 - precision: 0.5160 - recall: 0.6842\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.6937 - accuracy: 0.5056 - auc: 0.5033 - precision: 0.5072 - recall: 0.6655\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.6923 - accuracy: 0.5160 - auc: 0.5215 - precision: 0.5154 - recall: 0.6638\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.6921 - accuracy: 0.5187 - auc: 0.5292 - precision: 0.5181 - recall: 0.6463\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 3s 544ms/step - loss: 0.6919 - accuracy: 0.5190 - auc: 0.5319 - precision: 0.5181 - recall: 0.6522\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.6915 - accuracy: 0.5261 - auc: 0.5376 - precision: 0.5232 - recall: 0.6740\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.6917 - accuracy: 0.5286 - auc: 0.5362 - precision: 0.5296 - recall: 0.5782\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.6916 - accuracy: 0.5259 - auc: 0.5328 - precision: 0.5286 - recall: 0.5482\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.6913 - accuracy: 0.5294 - auc: 0.5355 - precision: 0.5292 - recall: 0.6009\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.6910 - accuracy: 0.5289 - auc: 0.5405 - precision: 0.5287 - recall: 0.6006\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 0.6915 - accuracy: 0.5296 - auc: 0.5355 - precision: 0.5300 - recall: 0.5884\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 0.6918 - accuracy: 0.5253 - auc: 0.5337 - precision: 0.5261 - recall: 0.5850\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.6918 - accuracy: 0.5184 - auc: 0.5300 - precision: 0.5203 - recall: 0.5703\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 0.6913 - accuracy: 0.5280 - auc: 0.5393 - precision: 0.5307 - recall: 0.5493\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 318ms/step - loss: 0.6919 - accuracy: 0.5209 - auc: 0.5290 - precision: 0.5270 - recall: 0.4816\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 0.6929 - accuracy: 0.5103 - auc: 0.5143 - precision: 0.5163 - recall: 0.4495\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.6926 - accuracy: 0.5133 - auc: 0.5189 - precision: 0.5178 - recall: 0.5000\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 0.6918 - accuracy: 0.5220 - auc: 0.5281 - precision: 0.5237 - recall: 0.5700\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 417ms/step - loss: 0.6917 - accuracy: 0.5213 - auc: 0.5304 - precision: 0.5228 - recall: 0.5762\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 3s 552ms/step - loss: 0.6916 - accuracy: 0.5227 - auc: 0.5333 - precision: 0.5236 - recall: 0.5870\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.6914 - accuracy: 0.5261 - auc: 0.5346 - precision: 0.5278 - recall: 0.5669\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 0.6915 - accuracy: 0.5254 - auc: 0.5338 - precision: 0.5257 - recall: 0.5975\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.6919 - accuracy: 0.5196 - auc: 0.5266 - precision: 0.5203 - recall: 0.5984\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.6913 - accuracy: 0.5251 - auc: 0.5360 - precision: 0.5260 - recall: 0.5839\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.6915 - accuracy: 0.5229 - auc: 0.5348 - precision: 0.5242 - recall: 0.5782\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 0.6914 - accuracy: 0.5207 - auc: 0.5348 - precision: 0.5219 - recall: 0.5839\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.6919 - accuracy: 0.5180 - auc: 0.5277 - precision: 0.5208 - recall: 0.5473\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 3s 667ms/step - loss: 0.6918 - accuracy: 0.5197 - auc: 0.5288 - precision: 0.5248 - recall: 0.4977\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.6916 - accuracy: 0.5231 - auc: 0.5332 - precision: 0.5276 - recall: 0.5147\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.6914 - accuracy: 0.5260 - auc: 0.5376 - precision: 0.5277 - recall: 0.5666\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.6913 - accuracy: 0.5273 - auc: 0.5377 - precision: 0.5289 - recall: 0.5686\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.6917 - accuracy: 0.5211 - auc: 0.5312 - precision: 0.5269 - recall: 0.4889\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.6912 - accuracy: 0.5240 - auc: 0.5378 - precision: 0.5329 - recall: 0.4501\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 338ms/step - loss: 0.6923 - accuracy: 0.5211 - auc: 0.5259 - precision: 0.5236 - recall: 0.5527\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 3s 545ms/step - loss: 0.6920 - accuracy: 0.5204 - auc: 0.5260 - precision: 0.5201 - recall: 0.6261\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.6929 - accuracy: 0.5114 - auc: 0.5163 - precision: 0.5131 - recall: 0.5989\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 0.6928 - accuracy: 0.5087 - auc: 0.5147 - precision: 0.5131 - recall: 0.4932\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.6923 - accuracy: 0.5189 - auc: 0.5241 - precision: 0.5258 - recall: 0.4620\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 324ms/step - loss: 0.6918 - accuracy: 0.5214 - auc: 0.5284 - precision: 0.5246 - recall: 0.5380\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.6923 - accuracy: 0.5189 - auc: 0.5243 - precision: 0.5185 - recall: 0.6363\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.6927 - accuracy: 0.5089 - auc: 0.5159 - precision: 0.5114 - recall: 0.5706\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6926 - accuracy: 0.5076 - auc: 0.5158 - precision: 0.5109 - recall: 0.5357\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 3s 541ms/step - loss: 0.6922 - accuracy: 0.5171 - auc: 0.5252 - precision: 0.5171 - recall: 0.6341\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 354ms/step - loss: 0.6921 - accuracy: 0.5133 - auc: 0.5238 - precision: 0.5176 - recall: 0.5051\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.6917 - accuracy: 0.5220 - auc: 0.5321 - precision: 0.5283 - recall: 0.4816\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.6913 - accuracy: 0.5261 - auc: 0.5362 - precision: 0.5288 - recall: 0.5488\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 0.6912 - accuracy: 0.5299 - auc: 0.5365 - precision: 0.5312 - recall: 0.5720\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.6916 - accuracy: 0.5293 - auc: 0.5312 - precision: 0.5300 - recall: 0.5839\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 0.6913 - accuracy: 0.5297 - auc: 0.5351 - precision: 0.5309 - recall: 0.5748\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.6914 - accuracy: 0.5279 - auc: 0.5358 - precision: 0.5311 - recall: 0.5397\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 3s 555ms/step - loss: 0.6915 - accuracy: 0.5271 - auc: 0.5334 - precision: 0.5307 - recall: 0.5349\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.6918 - accuracy: 0.5200 - auc: 0.5290 - precision: 0.5215 - recall: 0.5782\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 0.6917 - accuracy: 0.5246 - auc: 0.5331 - precision: 0.5226 - recall: 0.6562\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 313ms/step - loss: 0.6928 - accuracy: 0.5131 - auc: 0.5167 - precision: 0.5140 - recall: 0.6244\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.6922 - accuracy: 0.5116 - auc: 0.5203 - precision: 0.5140 - recall: 0.5655\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 324ms/step - loss: 0.6918 - accuracy: 0.5151 - auc: 0.5284 - precision: 0.5186 - recall: 0.5303\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6914 - accuracy: 0.5256 - auc: 0.5356 - precision: 0.5255 - recall: 0.6035\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 0.6914 - accuracy: 0.5254 - auc: 0.5362 - precision: 0.5240 - recall: 0.6372\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 463ms/step - loss: 0.6915 - accuracy: 0.5253 - auc: 0.5349 - precision: 0.5237 - recall: 0.6426\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_10 (Bat  (None, None, 2)          8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " simple_rnn_40 (SimpleRNN)   (None, None, 528)         280368    \n",
            "                                                                 \n",
            " simple_rnn_41 (SimpleRNN)   (None, None, 264)         209352    \n",
            "                                                                 \n",
            " simple_rnn_42 (SimpleRNN)   (None, None, 128)         50304     \n",
            "                                                                 \n",
            " simple_rnn_43 (SimpleRNN)   (None, None, 64)          12352     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, None, 32)          2080      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, None, 16)          528       \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, None, 1)           9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 555,137\n",
            "Trainable params: 555,133\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model.predict(X_test)\n",
        "trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test.flatten(), trainPredict_binary.flatten())\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BLP8JgqdPRz",
        "outputId": "acb1b560-f3d3-4348-f02c-9718f254ea10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 695ms/step\n",
            "[[763 767]\n",
            " [730 740]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lte1m x wifi"
      ],
      "metadata": {
        "id": "UvXuDApym9NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape=(None, 2)))\n",
        "model.add(SimpleRNN(units=528,input_shape=(None, 2),activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\",return_sequences=True))\n",
        "model.add(SimpleRNN(units=264,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(SimpleRNN(units=128, activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(SimpleRNN(units=64,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\",return_sequences=True))\n",
        "model.add(Dense(units=32,activation='tanh'))\n",
        "model.add(Dense(units=16,activation=\"relu\"))\n",
        "model.add(Dense(units=8, activation='tanh'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "opt = Adamax(\n",
        "    learning_rate=0.0003,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07)\n",
        "\n",
        "X3,Y3 = processos(dados_lte1m, dados_wifi,2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X2, Y2, test_size=None, train_size=0.7,random_state=42)\n",
        "model.compile(loss='binary_crossentropy', optimizer =opt, metrics=['accuracy','AUC', 'Precision', 'Recall'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cibeZZrrgfVg",
        "outputId": "55a28b02-9b88-4e7c-ba35-482fed76e4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 9s 329ms/step - loss: 0.6938 - accuracy: 0.5036 - auc: 0.4977 - precision: 0.5038 - recall: 0.9972\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.6939 - accuracy: 0.5061 - auc: 0.5089 - precision: 0.5061 - recall: 0.8362\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 328ms/step - loss: 0.6931 - accuracy: 0.5086 - auc: 0.5108 - precision: 0.5084 - recall: 0.7543\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 0.6929 - accuracy: 0.5126 - auc: 0.5186 - precision: 0.5159 - recall: 0.5349\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.6925 - accuracy: 0.5170 - auc: 0.5162 - precision: 0.5205 - recall: 0.5295\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 0.6925 - accuracy: 0.5127 - auc: 0.5261 - precision: 0.5224 - recall: 0.3866\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.6916 - accuracy: 0.5243 - auc: 0.5431 - precision: 0.5288 - recall: 0.5147\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 0.6909 - accuracy: 0.5306 - auc: 0.5461 - precision: 0.5350 - recall: 0.5238\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.6900 - accuracy: 0.5376 - auc: 0.5516 - precision: 0.5441 - recall: 0.5088\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 0.6892 - accuracy: 0.5423 - auc: 0.5583 - precision: 0.5451 - recall: 0.5550\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6880 - accuracy: 0.5459 - auc: 0.5675 - precision: 0.5462 - recall: 0.5850\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.6871 - accuracy: 0.5450 - auc: 0.5667 - precision: 0.5423 - recall: 0.6239\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 324ms/step - loss: 0.6861 - accuracy: 0.5447 - auc: 0.5770 - precision: 0.5396 - recall: 0.6593\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 455ms/step - loss: 0.6857 - accuracy: 0.5429 - auc: 0.5743 - precision: 0.5390 - recall: 0.6426\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 3s 550ms/step - loss: 0.6840 - accuracy: 0.5509 - auc: 0.5869 - precision: 0.5472 - recall: 0.6312\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 318ms/step - loss: 0.6822 - accuracy: 0.5584 - auc: 0.5951 - precision: 0.5537 - recall: 0.6386\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.6811 - accuracy: 0.5651 - auc: 0.5992 - precision: 0.5585 - recall: 0.6553\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.6796 - accuracy: 0.5744 - auc: 0.6084 - precision: 0.5715 - recall: 0.6222\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 318ms/step - loss: 0.6781 - accuracy: 0.5824 - auc: 0.6171 - precision: 0.5817 - recall: 0.6103\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 0.6774 - accuracy: 0.5736 - auc: 0.6137 - precision: 0.5651 - recall: 0.6684\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 0.6745 - accuracy: 0.5927 - auc: 0.6286 - precision: 0.5924 - recall: 0.6154\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 3s 554ms/step - loss: 0.6730 - accuracy: 0.5886 - auc: 0.6307 - precision: 0.5990 - recall: 0.5558\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.6696 - accuracy: 0.5989 - auc: 0.6438 - precision: 0.6111 - recall: 0.5612\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.6671 - accuracy: 0.6041 - auc: 0.6499 - precision: 0.6096 - recall: 0.5969\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 0.6647 - accuracy: 0.6087 - auc: 0.6557 - precision: 0.6152 - recall: 0.5972\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.6618 - accuracy: 0.6137 - auc: 0.6649 - precision: 0.6271 - recall: 0.5762\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.6581 - accuracy: 0.6213 - auc: 0.6736 - precision: 0.6283 - recall: 0.6088\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 0.6542 - accuracy: 0.6230 - auc: 0.6853 - precision: 0.6306 - recall: 0.6083\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 378ms/step - loss: 0.6521 - accuracy: 0.6300 - auc: 0.6859 - precision: 0.6419 - recall: 0.6015\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 3s 542ms/step - loss: 0.6471 - accuracy: 0.6376 - auc: 0.7008 - precision: 0.6545 - recall: 0.5950\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 356ms/step - loss: 0.6442 - accuracy: 0.6430 - auc: 0.7046 - precision: 0.6587 - recall: 0.6052\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 0.6390 - accuracy: 0.6490 - auc: 0.7169 - precision: 0.6644 - recall: 0.6134\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6344 - accuracy: 0.6551 - auc: 0.7245 - precision: 0.6690 - recall: 0.6250\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.6295 - accuracy: 0.6590 - auc: 0.7323 - precision: 0.6739 - recall: 0.6267\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.6249 - accuracy: 0.6651 - auc: 0.7374 - precision: 0.6814 - recall: 0.6304\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.6187 - accuracy: 0.6734 - auc: 0.7485 - precision: 0.6844 - recall: 0.6533\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.6147 - accuracy: 0.6773 - auc: 0.7548 - precision: 0.6960 - recall: 0.6386\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.6073 - accuracy: 0.6849 - auc: 0.7647 - precision: 0.7005 - recall: 0.6545\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.6022 - accuracy: 0.6907 - auc: 0.7712 - precision: 0.7118 - recall: 0.6491\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.5948 - accuracy: 0.6973 - auc: 0.7807 - precision: 0.7104 - recall: 0.6743\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 0.5850 - accuracy: 0.7080 - auc: 0.7936 - precision: 0.7243 - recall: 0.6791\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.5782 - accuracy: 0.7090 - auc: 0.7975 - precision: 0.7246 - recall: 0.6817\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.5719 - accuracy: 0.7216 - auc: 0.8084 - precision: 0.7415 - recall: 0.6871\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.5653 - accuracy: 0.7274 - auc: 0.8112 - precision: 0.7506 - recall: 0.6876\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 3s 540ms/step - loss: 0.5597 - accuracy: 0.7266 - auc: 0.8169 - precision: 0.7466 - recall: 0.6925\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 3s 490ms/step - loss: 0.5494 - accuracy: 0.7376 - auc: 0.8279 - precision: 0.7610 - recall: 0.6987\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 422ms/step - loss: 0.5417 - accuracy: 0.7427 - auc: 0.8307 - precision: 0.7518 - recall: 0.7307\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 0.5338 - accuracy: 0.7493 - auc: 0.8401 - precision: 0.7650 - recall: 0.7253\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.5261 - accuracy: 0.7553 - auc: 0.8467 - precision: 0.7858 - recall: 0.7072\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 318ms/step - loss: 0.5193 - accuracy: 0.7583 - auc: 0.8496 - precision: 0.7777 - recall: 0.7287\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.5097 - accuracy: 0.7654 - auc: 0.8573 - precision: 0.7965 - recall: 0.7180\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.4997 - accuracy: 0.7730 - auc: 0.8657 - precision: 0.7971 - recall: 0.7372\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 3s 535ms/step - loss: 0.4937 - accuracy: 0.7743 - auc: 0.8683 - precision: 0.8029 - recall: 0.7319\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 359ms/step - loss: 0.4859 - accuracy: 0.7790 - auc: 0.8735 - precision: 0.8002 - recall: 0.7483\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 314ms/step - loss: 0.4763 - accuracy: 0.7851 - auc: 0.8796 - precision: 0.8104 - recall: 0.7489\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 324ms/step - loss: 0.4674 - accuracy: 0.7917 - auc: 0.8846 - precision: 0.8159 - recall: 0.7577\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 324ms/step - loss: 0.4597 - accuracy: 0.7980 - auc: 0.8897 - precision: 0.8252 - recall: 0.7602\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 0.4548 - accuracy: 0.8003 - auc: 0.8914 - precision: 0.8235 - recall: 0.7684\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.4462 - accuracy: 0.8040 - auc: 0.8965 - precision: 0.8331 - recall: 0.7642\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.4358 - accuracy: 0.8077 - auc: 0.9014 - precision: 0.8466 - recall: 0.7554\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 0.4315 - accuracy: 0.8100 - auc: 0.9027 - precision: 0.8290 - recall: 0.7849\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 0.4283 - accuracy: 0.8094 - auc: 0.9029 - precision: 0.8330 - recall: 0.7778\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 318ms/step - loss: 0.4212 - accuracy: 0.8130 - auc: 0.9061 - precision: 0.8380 - recall: 0.7798\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 319ms/step - loss: 0.4187 - accuracy: 0.8146 - auc: 0.9063 - precision: 0.8410 - recall: 0.7795\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 0.4098 - accuracy: 0.8227 - auc: 0.9129 - precision: 0.8522 - recall: 0.7843\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.3998 - accuracy: 0.8286 - auc: 0.9169 - precision: 0.8590 - recall: 0.7894\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 0.3906 - accuracy: 0.8310 - auc: 0.9221 - precision: 0.8543 - recall: 0.8013\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 540ms/step - loss: 0.3827 - accuracy: 0.8357 - auc: 0.9259 - precision: 0.8616 - recall: 0.8030\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 3s 490ms/step - loss: 0.3745 - accuracy: 0.8440 - auc: 0.9297 - precision: 0.8691 - recall: 0.8129\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 328ms/step - loss: 0.3726 - accuracy: 0.8420 - auc: 0.9295 - precision: 0.8643 - recall: 0.8143\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 322ms/step - loss: 0.3636 - accuracy: 0.8466 - auc: 0.9335 - precision: 0.8602 - recall: 0.8305\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.3606 - accuracy: 0.8440 - auc: 0.9334 - precision: 0.8704 - recall: 0.8112\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.3562 - accuracy: 0.8491 - auc: 0.9355 - precision: 0.8846 - recall: 0.8058\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.3529 - accuracy: 0.8480 - auc: 0.9355 - precision: 0.8602 - recall: 0.8339\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 0.3475 - accuracy: 0.8509 - auc: 0.9391 - precision: 0.8916 - recall: 0.8016\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 0.3413 - accuracy: 0.8501 - auc: 0.9389 - precision: 0.8606 - recall: 0.8384\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.3366 - accuracy: 0.8557 - auc: 0.9419 - precision: 0.8765 - recall: 0.8308\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.3303 - accuracy: 0.8587 - auc: 0.9439 - precision: 0.8707 - recall: 0.8452\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.3258 - accuracy: 0.8606 - auc: 0.9458 - precision: 0.8860 - recall: 0.8302\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.3200 - accuracy: 0.8620 - auc: 0.9471 - precision: 0.8750 - recall: 0.8472\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 316ms/step - loss: 0.3147 - accuracy: 0.8684 - auc: 0.9496 - precision: 0.8966 - recall: 0.8353\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 310ms/step - loss: 0.3129 - accuracy: 0.8663 - auc: 0.9494 - precision: 0.8776 - recall: 0.8537\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.3073 - accuracy: 0.8691 - auc: 0.9510 - precision: 0.8873 - recall: 0.8481\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 3s 546ms/step - loss: 0.3022 - accuracy: 0.8704 - auc: 0.9523 - precision: 0.8871 - recall: 0.8512\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 3s 583ms/step - loss: 0.2981 - accuracy: 0.8734 - auc: 0.9534 - precision: 0.8751 - recall: 0.8736\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.2918 - accuracy: 0.8746 - auc: 0.9558 - precision: 0.8946 - recall: 0.8515\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.2953 - accuracy: 0.8733 - auc: 0.9536 - precision: 0.8787 - recall: 0.8685\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.2872 - accuracy: 0.8803 - auc: 0.9572 - precision: 0.8933 - recall: 0.8659\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.2807 - accuracy: 0.8846 - auc: 0.9598 - precision: 0.8988 - recall: 0.8688\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 315ms/step - loss: 0.2773 - accuracy: 0.8814 - auc: 0.9597 - precision: 0.8975 - recall: 0.8634\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 0.2729 - accuracy: 0.8850 - auc: 0.9612 - precision: 0.8948 - recall: 0.8747\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 3s 534ms/step - loss: 0.2698 - accuracy: 0.8869 - auc: 0.9620 - precision: 0.9014 - recall: 0.8707\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 381ms/step - loss: 0.2655 - accuracy: 0.8931 - auc: 0.9636 - precision: 0.9010 - recall: 0.8852\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 323ms/step - loss: 0.2610 - accuracy: 0.8923 - auc: 0.9649 - precision: 0.9011 - recall: 0.8832\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 0.2602 - accuracy: 0.8890 - auc: 0.9642 - precision: 0.9083 - recall: 0.8673\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 0.2641 - accuracy: 0.8904 - auc: 0.9626 - precision: 0.8973 - recall: 0.8838\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 317ms/step - loss: 0.2642 - accuracy: 0.8891 - auc: 0.9625 - precision: 0.9076 - recall: 0.8685\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 0.2622 - accuracy: 0.8890 - auc: 0.9630 - precision: 0.8841 - recall: 0.8974\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 425ms/step - loss: 0.2601 - accuracy: 0.8909 - auc: 0.9633 - precision: 0.9013 - recall: 0.8798\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 3s 543ms/step - loss: 0.2572 - accuracy: 0.8887 - auc: 0.9637 - precision: 0.8922 - recall: 0.8863\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_11 (Bat  (None, None, 2)          8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " simple_rnn_44 (SimpleRNN)   (None, None, 528)         280368    \n",
            "                                                                 \n",
            " simple_rnn_45 (SimpleRNN)   (None, None, 264)         209352    \n",
            "                                                                 \n",
            " simple_rnn_46 (SimpleRNN)   (None, None, 128)         50304     \n",
            "                                                                 \n",
            " simple_rnn_47 (SimpleRNN)   (None, None, 64)          12352     \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, None, 32)          2080      \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, None, 16)          528       \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, None, 1)           9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 555,137\n",
            "Trainable params: 555,133\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model.predict(X_test)\n",
        "trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test.flatten(), trainPredict_binary.flatten())\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXHK4W1phbu_",
        "outputId": "04551e8a-de29-4566-c0af-3bb61383f541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 139ms/step\n",
            "[[791 737]\n",
            " [755 717]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste de Dropout"
      ],
      "metadata": {
        "id": "vyVezxzHnXRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = processos(dados_clear, dados_lte1m,2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=None, train_size=0.7,random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape=(None, 2)))\n",
        "model.add(SimpleRNN(units=528,input_shape=(None, 2),activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\",return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(units=264,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(units=128, activation=\"tanh\",kernel_initializer=\"glorot_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(units=64,activation=\"relu\",kernel_initializer=\"he_uniform\",recurrent_initializer=\"orthogonal\", return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=32,activation='tanh'))\n",
        "model.add(Dense(units=16,activation=\"relu\"))\n",
        "model.add(Dense(units=8, activation='tanh'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "opt = Adamax(\n",
        "    learning_rate=0.0003,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer =opt, metrics=['accuracy','AUC', 'Precision', 'Recall'])\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=32)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PgI_kK7hxMuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e8923f-5b48-4ed1-a870-c78d86621587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 13s 738ms/step - loss: 0.6949 - accuracy: 0.4977 - auc: 0.4999 - precision: 0.4966 - recall: 0.5514\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 6s 563ms/step - loss: 0.6940 - accuracy: 0.5051 - auc: 0.5040 - precision: 0.5052 - recall: 0.3503\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 8s 765ms/step - loss: 0.6940 - accuracy: 0.5008 - auc: 0.4966 - precision: 0.4986 - recall: 0.2608\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 6s 558ms/step - loss: 0.6936 - accuracy: 0.5029 - auc: 0.5031 - precision: 0.5024 - recall: 0.2832\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 8s 730ms/step - loss: 0.6937 - accuracy: 0.5039 - auc: 0.5012 - precision: 0.5035 - recall: 0.3405\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 6s 548ms/step - loss: 0.6933 - accuracy: 0.5025 - auc: 0.5035 - precision: 0.5022 - recall: 0.2304\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 8s 752ms/step - loss: 0.6932 - accuracy: 0.5040 - auc: 0.5042 - precision: 0.5047 - recall: 0.2634\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 7s 604ms/step - loss: 0.6932 - accuracy: 0.5035 - auc: 0.5025 - precision: 0.5037 - recall: 0.2763\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 9s 786ms/step - loss: 0.6931 - accuracy: 0.5044 - auc: 0.5052 - precision: 0.5051 - recall: 0.2922\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 6s 553ms/step - loss: 0.6930 - accuracy: 0.5063 - auc: 0.5094 - precision: 0.5074 - recall: 0.3257\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 8s 765ms/step - loss: 0.6933 - accuracy: 0.5012 - auc: 0.5034 - precision: 0.4995 - recall: 0.3565\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 6s 572ms/step - loss: 0.6931 - accuracy: 0.5034 - auc: 0.5066 - precision: 0.5029 - recall: 0.3202\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 8s 769ms/step - loss: 0.6931 - accuracy: 0.5052 - auc: 0.5047 - precision: 0.5056 - recall: 0.3364\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 6s 557ms/step - loss: 0.6928 - accuracy: 0.5099 - auc: 0.5123 - precision: 0.5125 - recall: 0.3443\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 8s 751ms/step - loss: 0.6928 - accuracy: 0.5116 - auc: 0.5150 - precision: 0.5136 - recall: 0.3822\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.6930 - accuracy: 0.5081 - auc: 0.5129 - precision: 0.5075 - recall: 0.4459\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 8s 728ms/step - loss: 0.6930 - accuracy: 0.5071 - auc: 0.5117 - precision: 0.5068 - recall: 0.4163\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 0.6929 - accuracy: 0.5098 - auc: 0.5155 - precision: 0.5096 - recall: 0.4402\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 8s 735ms/step - loss: 0.6927 - accuracy: 0.5123 - auc: 0.5175 - precision: 0.5137 - recall: 0.4033\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 6s 566ms/step - loss: 0.6931 - accuracy: 0.5099 - auc: 0.5128 - precision: 0.5109 - recall: 0.3927\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 8s 757ms/step - loss: 0.6930 - accuracy: 0.5075 - auc: 0.5128 - precision: 0.5091 - recall: 0.3356\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 6s 589ms/step - loss: 0.6924 - accuracy: 0.5151 - auc: 0.5219 - precision: 0.5195 - recall: 0.3646\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 8s 733ms/step - loss: 0.6925 - accuracy: 0.5154 - auc: 0.5202 - precision: 0.5185 - recall: 0.3919\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 6s 558ms/step - loss: 0.6930 - accuracy: 0.5150 - auc: 0.5163 - precision: 0.5168 - recall: 0.4158\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 8s 770ms/step - loss: 0.6927 - accuracy: 0.5126 - auc: 0.5173 - precision: 0.5139 - recall: 0.4115\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 6s 581ms/step - loss: 0.6928 - accuracy: 0.5117 - auc: 0.5146 - precision: 0.5119 - recall: 0.4390\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 8s 771ms/step - loss: 0.6924 - accuracy: 0.5125 - auc: 0.5202 - precision: 0.5140 - recall: 0.4022\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 6s 578ms/step - loss: 0.6926 - accuracy: 0.5109 - auc: 0.5180 - precision: 0.5121 - recall: 0.3988\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 8s 780ms/step - loss: 0.6924 - accuracy: 0.5144 - auc: 0.5213 - precision: 0.5172 - recall: 0.3891\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 6s 559ms/step - loss: 0.6921 - accuracy: 0.5146 - auc: 0.5242 - precision: 0.5169 - recall: 0.4025\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 8s 728ms/step - loss: 0.6922 - accuracy: 0.5161 - auc: 0.5239 - precision: 0.5187 - recall: 0.4042\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 7s 603ms/step - loss: 0.6919 - accuracy: 0.5153 - auc: 0.5251 - precision: 0.5165 - recall: 0.4305\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 11s 946ms/step - loss: 0.6921 - accuracy: 0.5177 - auc: 0.5250 - precision: 0.5198 - recall: 0.4264\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 6s 572ms/step - loss: 0.6917 - accuracy: 0.5188 - auc: 0.5275 - precision: 0.5221 - recall: 0.4098\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 8s 753ms/step - loss: 0.6918 - accuracy: 0.5193 - auc: 0.5282 - precision: 0.5232 - recall: 0.4016\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 6s 534ms/step - loss: 0.6918 - accuracy: 0.5203 - auc: 0.5293 - precision: 0.5251 - recall: 0.3939\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 8s 756ms/step - loss: 0.6917 - accuracy: 0.5195 - auc: 0.5297 - precision: 0.5208 - recall: 0.4506\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 6s 565ms/step - loss: 0.6916 - accuracy: 0.5215 - auc: 0.5305 - precision: 0.5222 - recall: 0.4709\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 8s 746ms/step - loss: 0.6915 - accuracy: 0.5196 - auc: 0.5302 - precision: 0.5214 - recall: 0.4427\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.6921 - accuracy: 0.5179 - auc: 0.5264 - precision: 0.5226 - recall: 0.3798\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 9s 781ms/step - loss: 0.6916 - accuracy: 0.5227 - auc: 0.5314 - precision: 0.5278 - recall: 0.4033\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 7s 591ms/step - loss: 0.6912 - accuracy: 0.5225 - auc: 0.5345 - precision: 0.5252 - recall: 0.4389\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 8s 670ms/step - loss: 0.6913 - accuracy: 0.5240 - auc: 0.5330 - precision: 0.5262 - recall: 0.4535\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 6s 585ms/step - loss: 0.6906 - accuracy: 0.5263 - auc: 0.5386 - precision: 0.5290 - recall: 0.4537\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 8s 717ms/step - loss: 0.6910 - accuracy: 0.5241 - auc: 0.5354 - precision: 0.5274 - recall: 0.4358\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 7s 604ms/step - loss: 0.6907 - accuracy: 0.5266 - auc: 0.5388 - precision: 0.5268 - recall: 0.4953\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 8s 643ms/step - loss: 0.6901 - accuracy: 0.5304 - auc: 0.5436 - precision: 0.5324 - recall: 0.4764\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 6s 589ms/step - loss: 0.6908 - accuracy: 0.5281 - auc: 0.5390 - precision: 0.5313 - recall: 0.4515\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 8s 689ms/step - loss: 0.6905 - accuracy: 0.5276 - auc: 0.5395 - precision: 0.5324 - recall: 0.4298\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 7s 599ms/step - loss: 0.6903 - accuracy: 0.5302 - auc: 0.5430 - precision: 0.5337 - recall: 0.4558\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 8s 686ms/step - loss: 0.6906 - accuracy: 0.5289 - auc: 0.5409 - precision: 0.5314 - recall: 0.4640\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 7s 639ms/step - loss: 0.6903 - accuracy: 0.5255 - auc: 0.5390 - precision: 0.5268 - recall: 0.4740\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 7s 619ms/step - loss: 0.6902 - accuracy: 0.5296 - auc: 0.5413 - precision: 0.5339 - recall: 0.4433\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 7s 641ms/step - loss: 0.6902 - accuracy: 0.5309 - auc: 0.5425 - precision: 0.5348 - recall: 0.4524\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 8s 645ms/step - loss: 0.6898 - accuracy: 0.5293 - auc: 0.5437 - precision: 0.5320 - recall: 0.4632\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 7s 622ms/step - loss: 0.6891 - accuracy: 0.5366 - auc: 0.5507 - precision: 0.5397 - recall: 0.4779\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 8s 659ms/step - loss: 0.6897 - accuracy: 0.5337 - auc: 0.5468 - precision: 0.5348 - recall: 0.4962\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 7s 634ms/step - loss: 0.6889 - accuracy: 0.5367 - auc: 0.5510 - precision: 0.5374 - recall: 0.5068\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 7s 637ms/step - loss: 0.6883 - accuracy: 0.5364 - auc: 0.5545 - precision: 0.5388 - recall: 0.4858\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 6s 595ms/step - loss: 0.6888 - accuracy: 0.5339 - auc: 0.5508 - precision: 0.5374 - recall: 0.4660\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 7s 641ms/step - loss: 0.6879 - accuracy: 0.5381 - auc: 0.5566 - precision: 0.5420 - recall: 0.4746\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 7s 605ms/step - loss: 0.6876 - accuracy: 0.5378 - auc: 0.5558 - precision: 0.5399 - recall: 0.4933\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 8s 711ms/step - loss: 0.6870 - accuracy: 0.5398 - auc: 0.5601 - precision: 0.5412 - recall: 0.5049\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 8s 747ms/step - loss: 0.6871 - accuracy: 0.5419 - auc: 0.5603 - precision: 0.5419 - recall: 0.5243\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 7s 559ms/step - loss: 0.6866 - accuracy: 0.5443 - auc: 0.5623 - precision: 0.5451 - recall: 0.5187\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 8s 745ms/step - loss: 0.6873 - accuracy: 0.5386 - auc: 0.5581 - precision: 0.5402 - recall: 0.4999\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 6s 545ms/step - loss: 0.6860 - accuracy: 0.5443 - auc: 0.5645 - precision: 0.5463 - recall: 0.5068\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 7s 690ms/step - loss: 0.6857 - accuracy: 0.5463 - auc: 0.5675 - precision: 0.5473 - recall: 0.5188\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 7s 563ms/step - loss: 0.6866 - accuracy: 0.5474 - auc: 0.5637 - precision: 0.5513 - recall: 0.4946\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 8s 695ms/step - loss: 0.6857 - accuracy: 0.5431 - auc: 0.5657 - precision: 0.5436 - recall: 0.5198\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 7s 550ms/step - loss: 0.6862 - accuracy: 0.5449 - auc: 0.5658 - precision: 0.5466 - recall: 0.5107\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 8s 698ms/step - loss: 0.6850 - accuracy: 0.5497 - auc: 0.5703 - precision: 0.5520 - recall: 0.5137\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 7s 601ms/step - loss: 0.6838 - accuracy: 0.5521 - auc: 0.5753 - precision: 0.5541 - recall: 0.5196\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 8s 697ms/step - loss: 0.6836 - accuracy: 0.5549 - auc: 0.5760 - precision: 0.5582 - recall: 0.5135\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 7s 555ms/step - loss: 0.6833 - accuracy: 0.5578 - auc: 0.5780 - precision: 0.5601 - recall: 0.5265\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 8s 705ms/step - loss: 0.6830 - accuracy: 0.5544 - auc: 0.5783 - precision: 0.5566 - recall: 0.5218\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 7s 574ms/step - loss: 0.6823 - accuracy: 0.5561 - auc: 0.5812 - precision: 0.5592 - recall: 0.5175\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 7s 685ms/step - loss: 0.6815 - accuracy: 0.5569 - auc: 0.5830 - precision: 0.5596 - recall: 0.5218\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 7s 564ms/step - loss: 0.6815 - accuracy: 0.5559 - auc: 0.5835 - precision: 0.5589 - recall: 0.5179\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 7s 667ms/step - loss: 0.6815 - accuracy: 0.5579 - auc: 0.5834 - precision: 0.5596 - recall: 0.5314\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 7s 584ms/step - loss: 0.6804 - accuracy: 0.5579 - auc: 0.5867 - precision: 0.5621 - recall: 0.5114\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 7s 661ms/step - loss: 0.6796 - accuracy: 0.5626 - auc: 0.5902 - precision: 0.5631 - recall: 0.5470\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 7s 610ms/step - loss: 0.6791 - accuracy: 0.5622 - auc: 0.5909 - precision: 0.5649 - recall: 0.5298\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 7s 633ms/step - loss: 0.6789 - accuracy: 0.5621 - auc: 0.5902 - precision: 0.5669 - recall: 0.5154\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 7s 633ms/step - loss: 0.6760 - accuracy: 0.5679 - auc: 0.6013 - precision: 0.5714 - recall: 0.5324\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 7s 673ms/step - loss: 0.6762 - accuracy: 0.5709 - auc: 0.6023 - precision: 0.5708 - recall: 0.5610\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 7s 608ms/step - loss: 0.6774 - accuracy: 0.5659 - auc: 0.5958 - precision: 0.5691 - recall: 0.5320\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 7s 677ms/step - loss: 0.6768 - accuracy: 0.5679 - auc: 0.5990 - precision: 0.5715 - recall: 0.5317\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 7s 617ms/step - loss: 0.6757 - accuracy: 0.5690 - auc: 0.6025 - precision: 0.5693 - recall: 0.5561\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 7s 669ms/step - loss: 0.6743 - accuracy: 0.5726 - auc: 0.6060 - precision: 0.5791 - recall: 0.5224\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 7s 595ms/step - loss: 0.6737 - accuracy: 0.5738 - auc: 0.6079 - precision: 0.5782 - recall: 0.5363\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 7s 692ms/step - loss: 0.6732 - accuracy: 0.5752 - auc: 0.6091 - precision: 0.5791 - recall: 0.5414\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 7s 625ms/step - loss: 0.6715 - accuracy: 0.5795 - auc: 0.6147 - precision: 0.5811 - recall: 0.5610\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 8s 768ms/step - loss: 0.6720 - accuracy: 0.5759 - auc: 0.6118 - precision: 0.5784 - recall: 0.5505\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 6s 554ms/step - loss: 0.6716 - accuracy: 0.5799 - auc: 0.6140 - precision: 0.5822 - recall: 0.5568\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 8s 766ms/step - loss: 0.6705 - accuracy: 0.5769 - auc: 0.6151 - precision: 0.5788 - recall: 0.5555\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 6s 586ms/step - loss: 0.6689 - accuracy: 0.5828 - auc: 0.6209 - precision: 0.5836 - recall: 0.5694\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 8s 765ms/step - loss: 0.6680 - accuracy: 0.5820 - auc: 0.6222 - precision: 0.5859 - recall: 0.5503\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 6s 587ms/step - loss: 0.6659 - accuracy: 0.5846 - auc: 0.6268 - precision: 0.5876 - recall: 0.5589\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 8s 746ms/step - loss: 0.6661 - accuracy: 0.5907 - auc: 0.6287 - precision: 0.5927 - recall: 0.5720\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.6668 - accuracy: 0.5858 - auc: 0.6254 - precision: 0.5868 - recall: 0.5713\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 8s 780ms/step - loss: 0.6658 - accuracy: 0.5881 - auc: 0.6281 - precision: 0.5943 - recall: 0.5472\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 7s 596ms/step - loss: 0.6662 - accuracy: 0.5894 - auc: 0.6283 - precision: 0.5904 - recall: 0.5756\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 8s 738ms/step - loss: 0.6648 - accuracy: 0.5874 - auc: 0.6291 - precision: 0.5904 - recall: 0.5628\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 7s 596ms/step - loss: 0.6636 - accuracy: 0.5897 - auc: 0.6316 - precision: 0.5963 - recall: 0.5473\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 9s 798ms/step - loss: 0.6604 - accuracy: 0.5935 - auc: 0.6389 - precision: 0.5949 - recall: 0.5784\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 6s 580ms/step - loss: 0.6612 - accuracy: 0.5963 - auc: 0.6387 - precision: 0.5966 - recall: 0.5870\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 8s 755ms/step - loss: 0.6587 - accuracy: 0.5991 - auc: 0.6440 - precision: 0.6052 - recall: 0.5630\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 6s 591ms/step - loss: 0.6585 - accuracy: 0.5970 - auc: 0.6430 - precision: 0.6000 - recall: 0.5750\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 8s 759ms/step - loss: 0.6570 - accuracy: 0.5985 - auc: 0.6472 - precision: 0.6009 - recall: 0.5792\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 6s 588ms/step - loss: 0.6578 - accuracy: 0.5991 - auc: 0.6452 - precision: 0.6001 - recall: 0.5865\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 8s 766ms/step - loss: 0.6569 - accuracy: 0.6014 - auc: 0.6473 - precision: 0.6033 - recall: 0.5848\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 7s 592ms/step - loss: 0.6569 - accuracy: 0.6008 - auc: 0.6481 - precision: 0.6053 - recall: 0.5725\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 8s 722ms/step - loss: 0.6557 - accuracy: 0.6012 - auc: 0.6494 - precision: 0.6059 - recall: 0.5720\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 7s 605ms/step - loss: 0.6555 - accuracy: 0.6043 - auc: 0.6498 - precision: 0.6069 - recall: 0.5856\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 8s 738ms/step - loss: 0.6552 - accuracy: 0.6019 - auc: 0.6501 - precision: 0.6082 - recall: 0.5663\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 10s 944ms/step - loss: 0.6536 - accuracy: 0.6059 - auc: 0.6538 - precision: 0.6089 - recall: 0.5852\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.6515 - accuracy: 0.6098 - auc: 0.6582 - precision: 0.6114 - recall: 0.5960\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 8s 747ms/step - loss: 0.6499 - accuracy: 0.6104 - auc: 0.6607 - precision: 0.6130 - recall: 0.5924\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 7s 602ms/step - loss: 0.6502 - accuracy: 0.6125 - auc: 0.6618 - precision: 0.6183 - recall: 0.5820\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 8s 758ms/step - loss: 0.6482 - accuracy: 0.6137 - auc: 0.6643 - precision: 0.6183 - recall: 0.5880\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 6s 578ms/step - loss: 0.6476 - accuracy: 0.6137 - auc: 0.6648 - precision: 0.6182 - recall: 0.5884\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 9s 811ms/step - loss: 0.6482 - accuracy: 0.6121 - auc: 0.6633 - precision: 0.6167 - recall: 0.5859\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 6s 580ms/step - loss: 0.6450 - accuracy: 0.6153 - auc: 0.6694 - precision: 0.6195 - recall: 0.5919\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 8s 753ms/step - loss: 0.6458 - accuracy: 0.6183 - auc: 0.6694 - precision: 0.6215 - recall: 0.5995\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.6448 - accuracy: 0.6180 - auc: 0.6702 - precision: 0.6209 - recall: 0.6002\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 8s 782ms/step - loss: 0.6437 - accuracy: 0.6183 - auc: 0.6719 - precision: 0.6239 - recall: 0.5902\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 0.6440 - accuracy: 0.6158 - auc: 0.6710 - precision: 0.6169 - recall: 0.6052\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 8s 779ms/step - loss: 0.6402 - accuracy: 0.6217 - auc: 0.6777 - precision: 0.6288 - recall: 0.5886\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 6s 588ms/step - loss: 0.6392 - accuracy: 0.6212 - auc: 0.6783 - precision: 0.6216 - recall: 0.6135\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 8s 774ms/step - loss: 0.6381 - accuracy: 0.6260 - auc: 0.6816 - precision: 0.6278 - recall: 0.6133\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 7s 639ms/step - loss: 0.6393 - accuracy: 0.6250 - auc: 0.6794 - precision: 0.6307 - recall: 0.5980\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 8s 693ms/step - loss: 0.6372 - accuracy: 0.6239 - auc: 0.6815 - precision: 0.6254 - recall: 0.6120\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 7s 590ms/step - loss: 0.6392 - accuracy: 0.6208 - auc: 0.6783 - precision: 0.6269 - recall: 0.5908\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 8s 681ms/step - loss: 0.6360 - accuracy: 0.6273 - auc: 0.6847 - precision: 0.6299 - recall: 0.6117\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 7s 654ms/step - loss: 0.6360 - accuracy: 0.6281 - auc: 0.6842 - precision: 0.6315 - recall: 0.6098\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 8s 646ms/step - loss: 0.6326 - accuracy: 0.6299 - auc: 0.6896 - precision: 0.6358 - recall: 0.6029\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 7s 642ms/step - loss: 0.6304 - accuracy: 0.6333 - auc: 0.6928 - precision: 0.6362 - recall: 0.6174\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 7s 636ms/step - loss: 0.6324 - accuracy: 0.6301 - auc: 0.6896 - precision: 0.6322 - recall: 0.6168\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 7s 684ms/step - loss: 0.6312 - accuracy: 0.6357 - auc: 0.6926 - precision: 0.6398 - recall: 0.6159\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 7s 601ms/step - loss: 0.6291 - accuracy: 0.6352 - auc: 0.6948 - precision: 0.6376 - recall: 0.6211\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 7s 672ms/step - loss: 0.6273 - accuracy: 0.6369 - auc: 0.6980 - precision: 0.6390 - recall: 0.6242\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 7s 595ms/step - loss: 0.6272 - accuracy: 0.6388 - auc: 0.6982 - precision: 0.6434 - recall: 0.6176\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 8s 696ms/step - loss: 0.6248 - accuracy: 0.6401 - auc: 0.7020 - precision: 0.6395 - recall: 0.6372\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 7s 604ms/step - loss: 0.6240 - accuracy: 0.6391 - auc: 0.7017 - precision: 0.6515 - recall: 0.5936\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 8s 742ms/step - loss: 0.6241 - accuracy: 0.6409 - auc: 0.7040 - precision: 0.6403 - recall: 0.6378\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.6216 - accuracy: 0.6435 - auc: 0.7059 - precision: 0.6493 - recall: 0.6192\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 8s 769ms/step - loss: 0.6220 - accuracy: 0.6435 - auc: 0.7054 - precision: 0.6478 - recall: 0.6242\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 6s 556ms/step - loss: 0.6245 - accuracy: 0.6395 - auc: 0.7019 - precision: 0.6515 - recall: 0.5955\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 8s 741ms/step - loss: 0.6202 - accuracy: 0.6444 - auc: 0.7079 - precision: 0.6467 - recall: 0.6317\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 6s 564ms/step - loss: 0.6175 - accuracy: 0.6464 - auc: 0.7112 - precision: 0.6523 - recall: 0.6224\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 8s 714ms/step - loss: 0.6185 - accuracy: 0.6456 - auc: 0.7103 - precision: 0.6495 - recall: 0.6277\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 7s 576ms/step - loss: 0.6146 - accuracy: 0.6522 - auc: 0.7162 - precision: 0.6575 - recall: 0.6309\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 8s 744ms/step - loss: 0.6157 - accuracy: 0.6505 - auc: 0.7140 - precision: 0.6534 - recall: 0.6365\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 6s 567ms/step - loss: 0.6140 - accuracy: 0.6508 - auc: 0.7168 - precision: 0.6528 - recall: 0.6399\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 8s 759ms/step - loss: 0.6150 - accuracy: 0.6468 - auc: 0.7146 - precision: 0.6503 - recall: 0.6305\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 6s 594ms/step - loss: 0.6150 - accuracy: 0.6501 - auc: 0.7154 - precision: 0.6597 - recall: 0.6156\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 8s 755ms/step - loss: 0.6104 - accuracy: 0.6541 - auc: 0.7216 - precision: 0.6557 - recall: 0.6445\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 6s 551ms/step - loss: 0.6128 - accuracy: 0.6500 - auc: 0.7169 - precision: 0.6517 - recall: 0.6399\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 8s 741ms/step - loss: 0.6094 - accuracy: 0.6567 - auc: 0.7232 - precision: 0.6648 - recall: 0.6279\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 6s 543ms/step - loss: 0.6091 - accuracy: 0.6541 - auc: 0.7231 - precision: 0.6531 - recall: 0.6531\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 8s 748ms/step - loss: 0.6096 - accuracy: 0.6563 - auc: 0.7227 - precision: 0.6604 - recall: 0.6393\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 6s 551ms/step - loss: 0.6056 - accuracy: 0.6585 - auc: 0.7274 - precision: 0.6677 - recall: 0.6270\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 8s 748ms/step - loss: 0.6076 - accuracy: 0.6576 - auc: 0.7248 - precision: 0.6593 - recall: 0.6477\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 6s 567ms/step - loss: 0.6040 - accuracy: 0.6602 - auc: 0.7292 - precision: 0.6637 - recall: 0.6454\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 8s 787ms/step - loss: 0.6051 - accuracy: 0.6591 - auc: 0.7272 - precision: 0.6623 - recall: 0.6452\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 6s 572ms/step - loss: 0.6020 - accuracy: 0.6606 - auc: 0.7313 - precision: 0.6639 - recall: 0.6464\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 8s 754ms/step - loss: 0.6035 - accuracy: 0.6595 - auc: 0.7296 - precision: 0.6688 - recall: 0.6278\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 6s 551ms/step - loss: 0.6016 - accuracy: 0.6633 - auc: 0.7323 - precision: 0.6663 - recall: 0.6504\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 8s 756ms/step - loss: 0.5989 - accuracy: 0.6632 - auc: 0.7352 - precision: 0.6689 - recall: 0.6424\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 6s 554ms/step - loss: 0.5994 - accuracy: 0.6634 - auc: 0.7356 - precision: 0.6665 - recall: 0.6501\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 8s 746ms/step - loss: 0.5999 - accuracy: 0.6632 - auc: 0.7343 - precision: 0.6668 - recall: 0.6482\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 6s 548ms/step - loss: 0.5936 - accuracy: 0.6694 - auc: 0.7427 - precision: 0.6720 - recall: 0.6579\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 8s 787ms/step - loss: 0.5958 - accuracy: 0.6678 - auc: 0.7398 - precision: 0.6670 - recall: 0.6662\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 6s 578ms/step - loss: 0.5937 - accuracy: 0.6679 - auc: 0.7414 - precision: 0.6741 - recall: 0.6462\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 8s 749ms/step - loss: 0.5935 - accuracy: 0.6711 - auc: 0.7432 - precision: 0.6795 - recall: 0.6437\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 6s 562ms/step - loss: 0.5908 - accuracy: 0.6723 - auc: 0.7459 - precision: 0.6760 - recall: 0.6581\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 8s 749ms/step - loss: 0.5910 - accuracy: 0.6736 - auc: 0.7450 - precision: 0.6802 - recall: 0.6516\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.5890 - accuracy: 0.6730 - auc: 0.7473 - precision: 0.6721 - recall: 0.6719\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 8s 766ms/step - loss: 0.5918 - accuracy: 0.6747 - auc: 0.7452 - precision: 0.6773 - recall: 0.6638\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.5874 - accuracy: 0.6751 - auc: 0.7494 - precision: 0.6848 - recall: 0.6453\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 8s 733ms/step - loss: 0.5876 - accuracy: 0.6768 - auc: 0.7494 - precision: 0.6772 - recall: 0.6719\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 6s 564ms/step - loss: 0.5872 - accuracy: 0.6772 - auc: 0.7496 - precision: 0.6815 - recall: 0.6618\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 8s 770ms/step - loss: 0.5847 - accuracy: 0.6770 - auc: 0.7527 - precision: 0.6782 - recall: 0.6699\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 6s 562ms/step - loss: 0.5830 - accuracy: 0.6772 - auc: 0.7540 - precision: 0.6831 - recall: 0.6574\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 8s 734ms/step - loss: 0.5808 - accuracy: 0.6832 - auc: 0.7575 - precision: 0.6879 - recall: 0.6671\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 7s 599ms/step - loss: 0.5785 - accuracy: 0.6799 - auc: 0.7588 - precision: 0.6866 - recall: 0.6583\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 8s 759ms/step - loss: 0.5765 - accuracy: 0.6854 - auc: 0.7618 - precision: 0.6919 - recall: 0.6649\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 6s 581ms/step - loss: 0.5785 - accuracy: 0.6849 - auc: 0.7596 - precision: 0.6891 - recall: 0.6700\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 8s 751ms/step - loss: 0.5786 - accuracy: 0.6836 - auc: 0.7600 - precision: 0.6842 - recall: 0.6785\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 6s 555ms/step - loss: 0.5802 - accuracy: 0.6834 - auc: 0.7581 - precision: 0.6930 - recall: 0.6553\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 8s 759ms/step - loss: 0.5765 - accuracy: 0.6833 - auc: 0.7610 - precision: 0.6885 - recall: 0.6660\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 7s 596ms/step - loss: 0.5759 - accuracy: 0.6841 - auc: 0.7626 - precision: 0.6832 - recall: 0.6830\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 8s 759ms/step - loss: 0.5748 - accuracy: 0.6867 - auc: 0.7640 - precision: 0.6905 - recall: 0.6732\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 6s 564ms/step - loss: 0.5732 - accuracy: 0.6887 - auc: 0.7659 - precision: 0.6953 - recall: 0.6686\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 8s 780ms/step - loss: 0.5705 - accuracy: 0.6886 - auc: 0.7678 - precision: 0.6952 - recall: 0.6685\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 6s 579ms/step - loss: 0.5710 - accuracy: 0.6882 - auc: 0.7671 - precision: 0.6904 - recall: 0.6790\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 8s 750ms/step - loss: 0.5689 - accuracy: 0.6904 - auc: 0.7700 - precision: 0.6996 - recall: 0.6640\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 6s 562ms/step - loss: 0.5655 - accuracy: 0.6928 - auc: 0.7731 - precision: 0.6920 - recall: 0.6916\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 8s 735ms/step - loss: 0.5654 - accuracy: 0.6945 - auc: 0.7733 - precision: 0.7011 - recall: 0.6748\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 7s 614ms/step - loss: 0.5668 - accuracy: 0.6944 - auc: 0.7724 - precision: 0.7039 - recall: 0.6680\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 8s 673ms/step - loss: 0.5665 - accuracy: 0.6930 - auc: 0.7716 - precision: 0.6947 - recall: 0.6853\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 7s 610ms/step - loss: 0.5679 - accuracy: 0.6933 - auc: 0.7709 - precision: 0.7009 - recall: 0.6711\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 8s 667ms/step - loss: 0.5626 - accuracy: 0.6956 - auc: 0.7764 - precision: 0.6946 - recall: 0.6949\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 6s 592ms/step - loss: 0.5614 - accuracy: 0.6974 - auc: 0.7769 - precision: 0.7031 - recall: 0.6801\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 8s 664ms/step - loss: 0.5594 - accuracy: 0.6971 - auc: 0.7788 - precision: 0.7021 - recall: 0.6814\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 7s 611ms/step - loss: 0.5575 - accuracy: 0.7013 - auc: 0.7821 - precision: 0.7120 - recall: 0.6728\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 8s 682ms/step - loss: 0.5564 - accuracy: 0.7005 - auc: 0.7823 - precision: 0.7039 - recall: 0.6889\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 7s 599ms/step - loss: 0.5594 - accuracy: 0.7014 - auc: 0.7802 - precision: 0.7016 - recall: 0.6977\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 8s 676ms/step - loss: 0.5576 - accuracy: 0.6998 - auc: 0.7813 - precision: 0.7022 - recall: 0.6906\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 7s 677ms/step - loss: 0.5571 - accuracy: 0.6980 - auc: 0.7811 - precision: 0.7054 - recall: 0.6770\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 7s 643ms/step - loss: 0.5539 - accuracy: 0.7060 - auc: 0.7854 - precision: 0.7093 - recall: 0.6951\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 7s 652ms/step - loss: 0.5544 - accuracy: 0.7048 - auc: 0.7850 - precision: 0.7134 - recall: 0.6817\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 7s 605ms/step - loss: 0.5535 - accuracy: 0.7029 - auc: 0.7852 - precision: 0.7065 - recall: 0.6909\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 8s 703ms/step - loss: 0.5520 - accuracy: 0.7053 - auc: 0.7867 - precision: 0.7100 - recall: 0.6912\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 7s 610ms/step - loss: 0.5481 - accuracy: 0.7077 - auc: 0.7908 - precision: 0.7095 - recall: 0.7002\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 8s 721ms/step - loss: 0.5497 - accuracy: 0.7053 - auc: 0.7887 - precision: 0.7099 - recall: 0.6913\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 7s 576ms/step - loss: 0.5464 - accuracy: 0.7091 - auc: 0.7917 - precision: 0.7136 - recall: 0.6958\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 8s 730ms/step - loss: 0.5481 - accuracy: 0.7084 - auc: 0.7904 - precision: 0.7117 - recall: 0.6977\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 0.5472 - accuracy: 0.7079 - auc: 0.7910 - precision: 0.7143 - recall: 0.6901\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 8s 755ms/step - loss: 0.5431 - accuracy: 0.7112 - auc: 0.7949 - precision: 0.7121 - recall: 0.7063\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 6s 572ms/step - loss: 0.5413 - accuracy: 0.7142 - auc: 0.7971 - precision: 0.7212 - recall: 0.6954\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 8s 748ms/step - loss: 0.5411 - accuracy: 0.7117 - auc: 0.7967 - precision: 0.7141 - recall: 0.7032\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 6s 584ms/step - loss: 0.5426 - accuracy: 0.7122 - auc: 0.7954 - precision: 0.7187 - recall: 0.6946\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 8s 761ms/step - loss: 0.5404 - accuracy: 0.7125 - auc: 0.7968 - precision: 0.7179 - recall: 0.6975\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 6s 559ms/step - loss: 0.5394 - accuracy: 0.7159 - auc: 0.7989 - precision: 0.7218 - recall: 0.6999\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 8s 779ms/step - loss: 0.5386 - accuracy: 0.7142 - auc: 0.7995 - precision: 0.7169 - recall: 0.7051\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 6s 553ms/step - loss: 0.5367 - accuracy: 0.7175 - auc: 0.8008 - precision: 0.7225 - recall: 0.7036\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 8s 782ms/step - loss: 0.5339 - accuracy: 0.7166 - auc: 0.8023 - precision: 0.7197 - recall: 0.7068\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 7s 590ms/step - loss: 0.5394 - accuracy: 0.7177 - auc: 0.7990 - precision: 0.7250 - recall: 0.6989\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 8s 750ms/step - loss: 0.5363 - accuracy: 0.7162 - auc: 0.8011 - precision: 0.7204 - recall: 0.7038\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 0.5293 - accuracy: 0.7217 - auc: 0.8075 - precision: 0.7254 - recall: 0.7108\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 8s 755ms/step - loss: 0.5277 - accuracy: 0.7214 - auc: 0.8080 - precision: 0.7229 - recall: 0.7154\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.5301 - accuracy: 0.7210 - auc: 0.8066 - precision: 0.7268 - recall: 0.7055\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 8s 763ms/step - loss: 0.5273 - accuracy: 0.7219 - auc: 0.8084 - precision: 0.7286 - recall: 0.7046\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 6s 558ms/step - loss: 0.5254 - accuracy: 0.7243 - auc: 0.8112 - precision: 0.7259 - recall: 0.7181\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 9s 800ms/step - loss: 0.5261 - accuracy: 0.7214 - auc: 0.8093 - precision: 0.7247 - recall: 0.7115\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 6s 554ms/step - loss: 0.5280 - accuracy: 0.7229 - auc: 0.8084 - precision: 0.7263 - recall: 0.7127\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 8s 755ms/step - loss: 0.5263 - accuracy: 0.7251 - auc: 0.8101 - precision: 0.7316 - recall: 0.7085\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 6s 567ms/step - loss: 0.5245 - accuracy: 0.7234 - auc: 0.8113 - precision: 0.7250 - recall: 0.7171\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 8s 747ms/step - loss: 0.5250 - accuracy: 0.7222 - auc: 0.8103 - precision: 0.7243 - recall: 0.7149\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 6s 559ms/step - loss: 0.5217 - accuracy: 0.7278 - auc: 0.8146 - precision: 0.7281 - recall: 0.7247\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 8s 778ms/step - loss: 0.5195 - accuracy: 0.7273 - auc: 0.8149 - precision: 0.7313 - recall: 0.7160\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 6s 555ms/step - loss: 0.5187 - accuracy: 0.7277 - auc: 0.8156 - precision: 0.7343 - recall: 0.7110\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 8s 784ms/step - loss: 0.5193 - accuracy: 0.7301 - auc: 0.8159 - precision: 0.7396 - recall: 0.7077\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 6s 580ms/step - loss: 0.5183 - accuracy: 0.7298 - auc: 0.8169 - precision: 0.7337 - recall: 0.7187\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 8s 742ms/step - loss: 0.5153 - accuracy: 0.7300 - auc: 0.8189 - precision: 0.7311 - recall: 0.7249\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.5151 - accuracy: 0.7297 - auc: 0.8187 - precision: 0.7351 - recall: 0.7158\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 8s 750ms/step - loss: 0.5146 - accuracy: 0.7304 - auc: 0.8194 - precision: 0.7337 - recall: 0.7207\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 6s 567ms/step - loss: 0.5133 - accuracy: 0.7309 - auc: 0.8202 - precision: 0.7352 - recall: 0.7193\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 8s 759ms/step - loss: 0.5155 - accuracy: 0.7329 - auc: 0.8190 - precision: 0.7406 - recall: 0.7145\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 6s 547ms/step - loss: 0.5124 - accuracy: 0.7341 - auc: 0.8214 - precision: 0.7405 - recall: 0.7182\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 8s 738ms/step - loss: 0.5111 - accuracy: 0.7337 - auc: 0.8224 - precision: 0.7370 - recall: 0.7241\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 7s 599ms/step - loss: 0.5112 - accuracy: 0.7375 - auc: 0.8229 - precision: 0.7410 - recall: 0.7277\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 8s 738ms/step - loss: 0.5071 - accuracy: 0.7373 - auc: 0.8259 - precision: 0.7434 - recall: 0.7225\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 7s 613ms/step - loss: 0.5072 - accuracy: 0.7347 - auc: 0.8250 - precision: 0.7389 - recall: 0.7234\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 8s 726ms/step - loss: 0.5038 - accuracy: 0.7397 - auc: 0.8286 - precision: 0.7490 - recall: 0.7187\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 7s 614ms/step - loss: 0.5026 - accuracy: 0.7401 - auc: 0.8291 - precision: 0.7431 - recall: 0.7317\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 8s 692ms/step - loss: 0.5040 - accuracy: 0.7407 - auc: 0.8285 - precision: 0.7446 - recall: 0.7304\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 7s 665ms/step - loss: 0.5025 - accuracy: 0.7409 - auc: 0.8295 - precision: 0.7450 - recall: 0.7303\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 7s 621ms/step - loss: 0.4991 - accuracy: 0.7411 - auc: 0.8317 - precision: 0.7436 - recall: 0.7335\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 7s 599ms/step - loss: 0.4997 - accuracy: 0.7417 - auc: 0.8311 - precision: 0.7467 - recall: 0.7292\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 7s 636ms/step - loss: 0.4983 - accuracy: 0.7452 - auc: 0.8329 - precision: 0.7506 - recall: 0.7322\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 6s 582ms/step - loss: 0.4989 - accuracy: 0.7437 - auc: 0.8325 - precision: 0.7479 - recall: 0.7329\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 8s 672ms/step - loss: 0.4998 - accuracy: 0.7410 - auc: 0.8308 - precision: 0.7425 - recall: 0.7355\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 6s 564ms/step - loss: 0.5002 - accuracy: 0.7421 - auc: 0.8313 - precision: 0.7501 - recall: 0.7240\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 8s 695ms/step - loss: 0.4932 - accuracy: 0.7465 - auc: 0.8364 - precision: 0.7462 - recall: 0.7448\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 6s 583ms/step - loss: 0.4918 - accuracy: 0.7469 - auc: 0.8378 - precision: 0.7534 - recall: 0.7317\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 8s 700ms/step - loss: 0.4935 - accuracy: 0.7453 - auc: 0.8356 - precision: 0.7478 - recall: 0.7379\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 6s 565ms/step - loss: 0.4915 - accuracy: 0.7456 - auc: 0.8371 - precision: 0.7491 - recall: 0.7363\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 8s 673ms/step - loss: 0.4866 - accuracy: 0.7501 - auc: 0.8410 - precision: 0.7517 - recall: 0.7447\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 9s 822ms/step - loss: 0.4887 - accuracy: 0.7473 - auc: 0.8397 - precision: 0.7545 - recall: 0.7310\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 9s 772ms/step - loss: 0.4832 - accuracy: 0.7519 - auc: 0.8439 - precision: 0.7522 - recall: 0.7492\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 8s 731ms/step - loss: 0.4888 - accuracy: 0.7476 - auc: 0.8394 - precision: 0.7536 - recall: 0.7335\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 6s 544ms/step - loss: 0.4906 - accuracy: 0.7480 - auc: 0.8386 - precision: 0.7519 - recall: 0.7380\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 8s 735ms/step - loss: 0.4881 - accuracy: 0.7521 - auc: 0.8411 - precision: 0.7529 - recall: 0.7482\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 6s 577ms/step - loss: 0.4823 - accuracy: 0.7542 - auc: 0.8448 - precision: 0.7588 - recall: 0.7431\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 8s 750ms/step - loss: 0.4834 - accuracy: 0.7516 - auc: 0.8432 - precision: 0.7534 - recall: 0.7457\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 6s 557ms/step - loss: 0.4848 - accuracy: 0.7555 - auc: 0.8433 - precision: 0.7593 - recall: 0.7460\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 8s 731ms/step - loss: 0.4837 - accuracy: 0.7531 - auc: 0.8436 - precision: 0.7598 - recall: 0.7379\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 6s 554ms/step - loss: 0.4788 - accuracy: 0.7551 - auc: 0.8472 - precision: 0.7590 - recall: 0.7453\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 8s 750ms/step - loss: 0.4782 - accuracy: 0.7536 - auc: 0.8467 - precision: 0.7565 - recall: 0.7458\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.4769 - accuracy: 0.7574 - auc: 0.8487 - precision: 0.7627 - recall: 0.7453\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 8s 762ms/step - loss: 0.4721 - accuracy: 0.7601 - auc: 0.8520 - precision: 0.7646 - recall: 0.7495\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.4746 - accuracy: 0.7574 - auc: 0.8500 - precision: 0.7600 - recall: 0.7503\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 8s 728ms/step - loss: 0.4743 - accuracy: 0.7585 - auc: 0.8504 - precision: 0.7633 - recall: 0.7473\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 0.4764 - accuracy: 0.7582 - auc: 0.8491 - precision: 0.7631 - recall: 0.7468\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 8s 753ms/step - loss: 0.4746 - accuracy: 0.7599 - auc: 0.8504 - precision: 0.7682 - recall: 0.7422\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 6s 545ms/step - loss: 0.4717 - accuracy: 0.7591 - auc: 0.8522 - precision: 0.7602 - recall: 0.7550\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 8s 738ms/step - loss: 0.4734 - accuracy: 0.7584 - auc: 0.8505 - precision: 0.7611 - recall: 0.7510\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 6s 546ms/step - loss: 0.4688 - accuracy: 0.7617 - auc: 0.8543 - precision: 0.7708 - recall: 0.7430\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 8s 760ms/step - loss: 0.4677 - accuracy: 0.7630 - auc: 0.8554 - precision: 0.7657 - recall: 0.7557\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 6s 546ms/step - loss: 0.4647 - accuracy: 0.7660 - auc: 0.8572 - precision: 0.7725 - recall: 0.7520\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 8s 745ms/step - loss: 0.4666 - accuracy: 0.7631 - auc: 0.8557 - precision: 0.7657 - recall: 0.7562\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 6s 557ms/step - loss: 0.4697 - accuracy: 0.7621 - auc: 0.8538 - precision: 0.7633 - recall: 0.7576\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 8s 734ms/step - loss: 0.4630 - accuracy: 0.7642 - auc: 0.8579 - precision: 0.7700 - recall: 0.7512\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 6s 563ms/step - loss: 0.4618 - accuracy: 0.7667 - auc: 0.8591 - precision: 0.7728 - recall: 0.7534\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 8s 750ms/step - loss: 0.4631 - accuracy: 0.7632 - auc: 0.8575 - precision: 0.7667 - recall: 0.7545\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 6s 543ms/step - loss: 0.4626 - accuracy: 0.7647 - auc: 0.8584 - precision: 0.7630 - recall: 0.7660\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 8s 733ms/step - loss: 0.4611 - accuracy: 0.7656 - auc: 0.8596 - precision: 0.7722 - recall: 0.7515\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_1 (Batc  (None, None, 2)          8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, None, 528)         280368    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, None, 528)         0         \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, None, 264)         209352    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, None, 264)         0         \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, None, 128)         50304     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, None, 128)         0         \n",
            "                                                                 \n",
            " simple_rnn_7 (SimpleRNN)    (None, None, 64)          12352     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, None, 32)          2080      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, None, 16)          528       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, None, 1)           9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 555,137\n",
            "Trainable params: 555,133\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model.predict(X_test)\n",
        "trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test.flatten(), trainPredict_binary.flatten())\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqfBTF27qOvh",
        "outputId": "dc7af326-08b3-4033-cf73-40ae05809d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 128ms/step\n",
            "[[4239 3208]\n",
            " [4103 3450]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicando fourier"
      ],
      "metadata": {
        "id": "hPxPiXwFn0AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fourier_processing (sinal_1, sinal_2):\n",
        "    fft_1 = np.fft.fft(sinal_1)\n",
        "    fft_2 = np.fft.fft(sinal_2)\n",
        "    espectro_1 = np.abs(fft_1)\n",
        "    espectro_2 = np.abs(fft_2)\n",
        "    frequencias_1 = np.fft.fftfreq(len(sinal_1))\n",
        "    frequencias_2 = np.fft.fftfreq(len(sinal_2))\n",
        "    atributos1 = np.ones(len(sinal_1))\n",
        "    atributos2 = np.zeros(len(sinal_2))\n",
        "    dados1 = np.column_stack((espectro_1, frequencias_1, atributos1))\n",
        "    dados2 = np.column_stack((espectro_2, frequencias_2, atributos2))\n",
        "    conjunto = np.vstack([dados1, dados2])\n",
        "    indices = np.random.permutation(len(conjunto))\n",
        "    data = conjunto[indices]\n",
        "    return data\n",
        "\n",
        "\n",
        "def remodelar_fourier(data,feture):\n",
        "    df = pd.DataFrame(data, columns =  ['ampli','freq', 'clfq'] )\n",
        "    df_junt = df[['ampli', 'freq']].to_numpy()\n",
        "    data_dim = df_junt.reshape(len(data)//100, 100, feture)\n",
        "    data_dim = data_dim.astype(np.float32)\n",
        "    alvo = df['clfq'].values\n",
        "    alvo_dim = alvo.reshape(len(alvo)//100,100, feture-1)\n",
        "    alvo_dim = alvo_dim.astype(np.float32)\n",
        "    return data_dim,alvo_dim\n",
        "\n",
        "def processing_fourier(dados_1,dados_2,feture): \n",
        "    data = fourier_processing(dados_1, dados_2)\n",
        "    X_f , Y_f = remodelar_fourier(data,feture)\n",
        "    return X_f, Y_f"
      ],
      "metadata": {
        "id": "eLrKp7u7eJWs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_f, Y_f = processing_fourier(dados_clear,dados_lte1m,2)"
      ],
      "metadata": {
        "id": "uITqymKVe1XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm0tsNK1o3cN",
        "outputId": "9b047693-7a9c-4687-b8a0-b8aa9d39e5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 3.0670836e-04  2.8400000e-02]\n",
            "  [ 1.9541453e-04  2.4580000e-01]\n",
            "  [ 1.5259311e-04  3.2120001e-01]\n",
            "  ...\n",
            "  [ 6.8241716e-05 -4.0020001e-01]\n",
            "  [ 2.1363035e-04  1.2220000e-01]\n",
            "  [ 1.9541453e-04 -2.5299999e-01]]\n",
            "\n",
            " [[ 3.0518622e-05  1.3300000e-01]\n",
            "  [ 1.5259311e-04  4.1280001e-01]\n",
            "  [ 1.7263940e-04 -1.1220000e-01]\n",
            "  ...\n",
            "  [ 2.2217892e-04  2.6940000e-01]\n",
            "  [ 2.1579926e-04  4.7799999e-01]\n",
            "  [ 3.5590524e-04  3.3599999e-02]]\n",
            "\n",
            " [[ 1.2583150e-04  1.1140000e-01]\n",
            "  [ 4.2834927e-04  4.8559999e-01]\n",
            "  [ 2.8136780e-04  4.4880000e-01]\n",
            "  ...\n",
            "  [ 9.6508353e-05  3.9600000e-02]\n",
            "  [ 4.3159848e-04  1.6940001e-01]\n",
            "  [ 2.3835806e-04  3.3520001e-01]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 3.9082905e-04  4.6599999e-01]\n",
            "  [ 3.0518623e-04  2.5619999e-01]\n",
            "  [ 2.0472513e-04  4.5519999e-01]\n",
            "  ...\n",
            "  [ 2.0472513e-04 -2.7039999e-01]\n",
            "  [ 1.2947954e-04 -9.8600000e-02]\n",
            "  [ 1.9541453e-04 -3.4540001e-01]]\n",
            "\n",
            " [[ 1.1003645e-04 -6.9200002e-02]\n",
            "  [ 2.4604899e-04  1.2639999e-01]\n",
            "  [ 1.9541453e-04  3.6440000e-01]\n",
            "  ...\n",
            "  [ 1.3648343e-04 -1.4139999e-01]\n",
            "  [ 6.8241716e-05  3.3759999e-01]\n",
            "  [ 1.5561505e-04  1.2080000e-01]]\n",
            "\n",
            " [[ 2.1579926e-04 -4.9860001e-01]\n",
            "  [ 3.1862379e-04 -3.5220000e-01]\n",
            "  [ 2.7466760e-04 -2.4980000e-01]\n",
            "  ...\n",
            "  [ 1.8311173e-04 -2.9440001e-01]\n",
            "  [ 9.6508353e-05 -1.6240001e-01]\n",
            "  [ 3.4120856e-04  1.1760000e-01]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_simpleRNN(dados_1,dados_2):\n",
        "    X_f,Y_f = processing_fourier(dados_1, dados_2,2)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_f, Y_f, test_size=0.3, train_size=0.7,random_state=42)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(BatchNormalization(input_shape=(None, 2)))\n",
        "\n",
        "    model.add(SimpleRNN(units=528,\n",
        "                        input_shape=(None, 2),\n",
        "                        activation=\"tanh\",\n",
        "                        kernel_initializer=\"glorot_uniform\",\n",
        "                        recurrent_initializer=\"orthogonal\",\n",
        "                        dropout=0.1,recurrent_dropout=0.1,\n",
        "                        return_sequences=True))\n",
        "\n",
        "    model.add(SimpleRNN(units=256,\n",
        "                        activation=\"relu\",\n",
        "                        kernel_initializer=\"he_uniform\",\n",
        "                        recurrent_initializer=\"orthogonal\", \n",
        "                        dropout=0.1,recurrent_dropout=0.1,\n",
        "                        return_sequences=True))\n",
        "\n",
        "    model.add(SimpleRNN(units=128, \n",
        "                        activation=\"tanh\",\n",
        "                        kernel_initializer=\"glorot_uniform\",\n",
        "                        recurrent_initializer=\"orthogonal\",\n",
        "                        dropout=0.1,recurrent_dropout=0.1, \n",
        "                        return_sequences=True))\n",
        "\n",
        "    model.add(SimpleRNN(units=64,\n",
        "                        activation=\"relu\",\n",
        "                        kernel_initializer=\"he_uniform\",\n",
        "                        recurrent_initializer=\"orthogonal\",\n",
        "                        dropout=0.1, recurrent_dropout=0.0, \n",
        "                        return_sequences=True))\n",
        "\n",
        "\n",
        "    model.add(Dense(units=32,activation='tanh'))\n",
        "    model.add(Dense(units=16,activation=\"relu\"))\n",
        "    model.add(Dense(units=8, activation='tanh'))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    opt = Adamax(\n",
        "        learning_rate=0.0003,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.99,\n",
        "        epsilon=1e-07)\n",
        "\n",
        "    mc = model.compile(loss='binary_crossentropy', \n",
        "                       optimizer =opt, \n",
        "                       metrics=['accuracy','AUC', 'Precision', 'Recall'])\n",
        "    \n",
        "    mf = model.fit(X_train, y_train, \n",
        "                   epochs=100, \n",
        "                   batch_size=32)\n",
        "    \n",
        "    ms = model.summary()\n",
        "    return model,X_test,y_test"
      ],
      "metadata": {
        "id": "oryC4k4a11Az"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clear x lte1m"
      ],
      "metadata": {
        "id": "NJbUdKLMqvOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model,X_test,y_test = model_simpleRNN(dados_clear,dados_lte1m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c87WfQ3zbBPr",
        "outputId": "2011a677-9eff-4787-843f-80199ff7ae26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 8s 651ms/step - loss: 0.7019 - accuracy: 0.4943 - auc: 0.4977 - precision: 0.4926 - recall: 0.5710\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 3s 873ms/step - loss: 0.6984 - accuracy: 0.5110 - auc: 0.5090 - precision: 0.5090 - recall: 0.4649\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.6982 - accuracy: 0.5084 - auc: 0.5023 - precision: 0.5060 - recall: 0.4744\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.6970 - accuracy: 0.5079 - auc: 0.5091 - precision: 0.5052 - recall: 0.4859\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 517ms/step - loss: 0.6964 - accuracy: 0.5071 - auc: 0.5080 - precision: 0.5043 - recall: 0.5011\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.6956 - accuracy: 0.5121 - auc: 0.5111 - precision: 0.5089 - recall: 0.5333\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 2s 741ms/step - loss: 0.6969 - accuracy: 0.4949 - auc: 0.5035 - precision: 0.4926 - recall: 0.5328\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 2s 511ms/step - loss: 0.6959 - accuracy: 0.5131 - auc: 0.5115 - precision: 0.5090 - recall: 0.5842\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 3s 867ms/step - loss: 0.6947 - accuracy: 0.5103 - auc: 0.5142 - precision: 0.5066 - recall: 0.5701\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 3s 714ms/step - loss: 0.6956 - accuracy: 0.5107 - auc: 0.5085 - precision: 0.5069 - recall: 0.5764\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 2s 676ms/step - loss: 0.6944 - accuracy: 0.5123 - auc: 0.5142 - precision: 0.5086 - recall: 0.5629\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 0.6954 - accuracy: 0.5053 - auc: 0.5092 - precision: 0.5023 - recall: 0.5333\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 2s 502ms/step - loss: 0.6947 - accuracy: 0.5066 - auc: 0.5085 - precision: 0.5036 - recall: 0.5178\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 2s 510ms/step - loss: 0.6941 - accuracy: 0.5080 - auc: 0.5150 - precision: 0.5052 - recall: 0.5009\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.6950 - accuracy: 0.5063 - auc: 0.5078 - precision: 0.5034 - recall: 0.5037\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 3s 877ms/step - loss: 0.6935 - accuracy: 0.5083 - auc: 0.5183 - precision: 0.5055 - recall: 0.5037\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 3s 769ms/step - loss: 0.6948 - accuracy: 0.5103 - auc: 0.5108 - precision: 0.5076 - recall: 0.5014\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 2s 504ms/step - loss: 0.6937 - accuracy: 0.5086 - auc: 0.5151 - precision: 0.5056 - recall: 0.5155\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 501ms/step - loss: 0.6958 - accuracy: 0.5067 - auc: 0.5004 - precision: 0.5038 - recall: 0.5135\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.6947 - accuracy: 0.5157 - auc: 0.5102 - precision: 0.5131 - recall: 0.5080\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 2s 498ms/step - loss: 0.6938 - accuracy: 0.5136 - auc: 0.5141 - precision: 0.5109 - recall: 0.5055\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 2s 576ms/step - loss: 0.6931 - accuracy: 0.5131 - auc: 0.5175 - precision: 0.5106 - recall: 0.4966\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 2s 856ms/step - loss: 0.6955 - accuracy: 0.5074 - auc: 0.5023 - precision: 0.5047 - recall: 0.4891\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 3s 945ms/step - loss: 0.6926 - accuracy: 0.5184 - auc: 0.5237 - precision: 0.5167 - recall: 0.4856\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 2s 505ms/step - loss: 0.6932 - accuracy: 0.5140 - auc: 0.5177 - precision: 0.5121 - recall: 0.4727\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 2s 513ms/step - loss: 0.6943 - accuracy: 0.5050 - auc: 0.5088 - precision: 0.5022 - recall: 0.4851\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 2s 572ms/step - loss: 0.6931 - accuracy: 0.5197 - auc: 0.5211 - precision: 0.5177 - recall: 0.4960\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 2s 550ms/step - loss: 0.6936 - accuracy: 0.5144 - auc: 0.5137 - precision: 0.5124 - recall: 0.4825\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.6931 - accuracy: 0.5159 - auc: 0.5202 - precision: 0.5135 - recall: 0.4957\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 2s 714ms/step - loss: 0.6934 - accuracy: 0.5109 - auc: 0.5167 - precision: 0.5081 - recall: 0.5020\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 3s 963ms/step - loss: 0.6929 - accuracy: 0.5190 - auc: 0.5208 - precision: 0.5167 - recall: 0.5023\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 2s 565ms/step - loss: 0.6933 - accuracy: 0.5127 - auc: 0.5147 - precision: 0.5105 - recall: 0.4819\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 2s 544ms/step - loss: 0.6925 - accuracy: 0.5100 - auc: 0.5207 - precision: 0.5077 - recall: 0.4756\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 2s 549ms/step - loss: 0.6926 - accuracy: 0.5136 - auc: 0.5229 - precision: 0.5112 - recall: 0.4934\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 2s 550ms/step - loss: 0.6934 - accuracy: 0.5176 - auc: 0.5148 - precision: 0.5155 - recall: 0.4925\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.6921 - accuracy: 0.5171 - auc: 0.5263 - precision: 0.5156 - recall: 0.4744\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 2s 637ms/step - loss: 0.6930 - accuracy: 0.5131 - auc: 0.5179 - precision: 0.5109 - recall: 0.4828\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 3s 931ms/step - loss: 0.6921 - accuracy: 0.5171 - auc: 0.5260 - precision: 0.5158 - recall: 0.4693\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.6927 - accuracy: 0.5150 - auc: 0.5221 - precision: 0.5132 - recall: 0.4747\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.6931 - accuracy: 0.5120 - auc: 0.5191 - precision: 0.5098 - recall: 0.4796\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 2s 577ms/step - loss: 0.6931 - accuracy: 0.5159 - auc: 0.5189 - precision: 0.5137 - recall: 0.4894\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 2s 541ms/step - loss: 0.6928 - accuracy: 0.5164 - auc: 0.5216 - precision: 0.5139 - recall: 0.5037\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 2s 567ms/step - loss: 0.6907 - accuracy: 0.5314 - auc: 0.5415 - precision: 0.5294 - recall: 0.5175\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 2s 600ms/step - loss: 0.6926 - accuracy: 0.5221 - auc: 0.5248 - precision: 0.5199 - recall: 0.5063\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 3s 965ms/step - loss: 0.6914 - accuracy: 0.5280 - auc: 0.5339 - precision: 0.5263 - recall: 0.5069\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 2s 604ms/step - loss: 0.6906 - accuracy: 0.5261 - auc: 0.5382 - precision: 0.5241 - recall: 0.5089\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 2s 574ms/step - loss: 0.6923 - accuracy: 0.5223 - auc: 0.5266 - precision: 0.5197 - recall: 0.5147\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 2s 546ms/step - loss: 0.6917 - accuracy: 0.5203 - auc: 0.5328 - precision: 0.5171 - recall: 0.5307\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.6924 - accuracy: 0.5250 - auc: 0.5273 - precision: 0.5212 - recall: 0.5480\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 2s 563ms/step - loss: 0.6906 - accuracy: 0.5200 - auc: 0.5381 - precision: 0.5166 - recall: 0.5362\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 623ms/step - loss: 0.6928 - accuracy: 0.5151 - auc: 0.5210 - precision: 0.5119 - recall: 0.5299\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 3s 911ms/step - loss: 0.6917 - accuracy: 0.5271 - auc: 0.5333 - precision: 0.5239 - recall: 0.5362\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 2s 545ms/step - loss: 0.6929 - accuracy: 0.5181 - auc: 0.5204 - precision: 0.5156 - recall: 0.5080\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.6925 - accuracy: 0.5226 - auc: 0.5264 - precision: 0.5210 - recall: 0.4925\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 535ms/step - loss: 0.6916 - accuracy: 0.5251 - auc: 0.5315 - precision: 0.5238 - recall: 0.4931\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.6915 - accuracy: 0.5267 - auc: 0.5334 - precision: 0.5260 - recall: 0.4856\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 2s 508ms/step - loss: 0.6918 - accuracy: 0.5200 - auc: 0.5313 - precision: 0.5179 - recall: 0.4997\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 3s 878ms/step - loss: 0.6903 - accuracy: 0.5343 - auc: 0.5453 - precision: 0.5320 - recall: 0.5250\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 2s 580ms/step - loss: 0.6926 - accuracy: 0.5154 - auc: 0.5261 - precision: 0.5121 - recall: 0.5365\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 2s 508ms/step - loss: 0.6912 - accuracy: 0.5264 - auc: 0.5397 - precision: 0.5220 - recall: 0.5635\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 2s 512ms/step - loss: 0.6911 - accuracy: 0.5290 - auc: 0.5370 - precision: 0.5238 - recall: 0.5776\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 2s 541ms/step - loss: 0.6917 - accuracy: 0.5209 - auc: 0.5328 - precision: 0.5160 - recall: 0.5825\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.6920 - accuracy: 0.5240 - auc: 0.5334 - precision: 0.5185 - recall: 0.5966\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 2s 510ms/step - loss: 0.6916 - accuracy: 0.5229 - auc: 0.5326 - precision: 0.5182 - recall: 0.5733\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 3s 944ms/step - loss: 0.6940 - accuracy: 0.5040 - auc: 0.5131 - precision: 0.5011 - recall: 0.5408\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 3s 858ms/step - loss: 0.6933 - accuracy: 0.5191 - auc: 0.5217 - precision: 0.5163 - recall: 0.5190\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 2s 541ms/step - loss: 0.6916 - accuracy: 0.5233 - auc: 0.5327 - precision: 0.5223 - recall: 0.4822\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.6924 - accuracy: 0.5194 - auc: 0.5257 - precision: 0.5192 - recall: 0.4497\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 2s 503ms/step - loss: 0.6922 - accuracy: 0.5184 - auc: 0.5279 - precision: 0.5188 - recall: 0.4322\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 2s 533ms/step - loss: 0.6922 - accuracy: 0.5201 - auc: 0.5263 - precision: 0.5199 - recall: 0.4537\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.6917 - accuracy: 0.5219 - auc: 0.5314 - precision: 0.5205 - recall: 0.4848\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 2s 650ms/step - loss: 0.6914 - accuracy: 0.5270 - auc: 0.5362 - precision: 0.5250 - recall: 0.5092\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.6906 - accuracy: 0.5289 - auc: 0.5409 - precision: 0.5254 - recall: 0.5405\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 3s 802ms/step - loss: 0.6910 - accuracy: 0.5246 - auc: 0.5362 - precision: 0.5216 - recall: 0.5284\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 2s 519ms/step - loss: 0.6903 - accuracy: 0.5317 - auc: 0.5434 - precision: 0.5282 - recall: 0.5431\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 2s 511ms/step - loss: 0.6923 - accuracy: 0.5124 - auc: 0.5229 - precision: 0.5096 - recall: 0.5112\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.6904 - accuracy: 0.5249 - auc: 0.5403 - precision: 0.5224 - recall: 0.5170\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.6915 - accuracy: 0.5276 - auc: 0.5353 - precision: 0.5259 - recall: 0.5040\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 2s 709ms/step - loss: 0.6916 - accuracy: 0.5287 - auc: 0.5358 - precision: 0.5274 - recall: 0.5003\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 3s 866ms/step - loss: 0.6918 - accuracy: 0.5279 - auc: 0.5332 - precision: 0.5273 - recall: 0.4859\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.6928 - accuracy: 0.5209 - auc: 0.5244 - precision: 0.5200 - recall: 0.4713\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 2s 522ms/step - loss: 0.6915 - accuracy: 0.5241 - auc: 0.5354 - precision: 0.5233 - recall: 0.4799\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.6903 - accuracy: 0.5300 - auc: 0.5430 - precision: 0.5295 - recall: 0.4899\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.6912 - accuracy: 0.5297 - auc: 0.5347 - precision: 0.5278 - recall: 0.5126\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 2s 510ms/step - loss: 0.6912 - accuracy: 0.5264 - auc: 0.5353 - precision: 0.5242 - recall: 0.5138\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 2s 532ms/step - loss: 0.6914 - accuracy: 0.5353 - auc: 0.5340 - precision: 0.5337 - recall: 0.5158\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 3s 914ms/step - loss: 0.6904 - accuracy: 0.5336 - auc: 0.5426 - precision: 0.5332 - recall: 0.4966\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 3s 801ms/step - loss: 0.6892 - accuracy: 0.5364 - auc: 0.5514 - precision: 0.5355 - recall: 0.5092\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 2s 531ms/step - loss: 0.6903 - accuracy: 0.5269 - auc: 0.5431 - precision: 0.5255 - recall: 0.4983\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.6897 - accuracy: 0.5360 - auc: 0.5478 - precision: 0.5346 - recall: 0.5152\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 0.6917 - accuracy: 0.5217 - auc: 0.5336 - precision: 0.5204 - recall: 0.4842\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 2s 510ms/step - loss: 0.6903 - accuracy: 0.5290 - auc: 0.5402 - precision: 0.5274 - recall: 0.5069\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 2s 554ms/step - loss: 0.6899 - accuracy: 0.5334 - auc: 0.5473 - precision: 0.5316 - recall: 0.5167\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 3s 999ms/step - loss: 0.6911 - accuracy: 0.5263 - auc: 0.5352 - precision: 0.5244 - recall: 0.5057\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 3s 984ms/step - loss: 0.6910 - accuracy: 0.5273 - auc: 0.5399 - precision: 0.5255 - recall: 0.5060\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 3s 931ms/step - loss: 0.6892 - accuracy: 0.5360 - auc: 0.5508 - precision: 0.5335 - recall: 0.5307\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 2s 535ms/step - loss: 0.6905 - accuracy: 0.5314 - auc: 0.5426 - precision: 0.5289 - recall: 0.5267\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 2s 539ms/step - loss: 0.6894 - accuracy: 0.5381 - auc: 0.5516 - precision: 0.5359 - recall: 0.5296\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 2s 537ms/step - loss: 0.6913 - accuracy: 0.5207 - auc: 0.5343 - precision: 0.5182 - recall: 0.5118\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 2s 524ms/step - loss: 0.6898 - accuracy: 0.5321 - auc: 0.5457 - precision: 0.5302 - recall: 0.5172\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_3 (Batc  (None, None, 2)          8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " simple_rnn_12 (SimpleRNN)   (None, None, 528)         280368    \n",
            "                                                                 \n",
            " simple_rnn_13 (SimpleRNN)   (None, None, 256)         200960    \n",
            "                                                                 \n",
            " simple_rnn_14 (SimpleRNN)   (None, None, 128)         49280     \n",
            "                                                                 \n",
            " simple_rnn_15 (SimpleRNN)   (None, None, 64)          12352     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, None, 32)          2080      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, None, 16)          528       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, None, 1)           9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545,721\n",
            "Trainable params: 545,717\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model.predict(X_test)\n",
        "trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test.flatten(), trainPredict_binary.flatten())\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEVOvrp0sU_u",
        "outputId": "a3f31511-907f-4046-bde9-4bf816be5f73"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 827ms/step\n",
            "[[711 769]\n",
            " [748 772]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clear x wifi"
      ],
      "metadata": {
        "id": "i-mg0RXVuYWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2,X_test,y_test = model_simpleRNN(dados_clear,dados_wifi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK12_UCluNbv",
        "outputId": "6022a5d3-84fc-4776-c194-c78995b4098f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 9s 642ms/step - loss: 0.7169 - accuracy: 0.5023 - auc: 0.5073 - precision: 0.4884 - recall: 0.0604\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.7000 - accuracy: 0.4983 - auc: 0.4999 - precision: 0.4889 - recall: 0.2409\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 3s 867ms/step - loss: 0.6959 - accuracy: 0.5044 - auc: 0.5055 - precision: 0.5008 - recall: 0.4439\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.6958 - accuracy: 0.5066 - auc: 0.5026 - precision: 0.5025 - recall: 0.5786\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.6947 - accuracy: 0.5003 - auc: 0.5032 - precision: 0.4973 - recall: 0.6344\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 3s 649ms/step - loss: 0.6939 - accuracy: 0.5079 - auc: 0.5083 - precision: 0.5031 - recall: 0.6808\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 2s 551ms/step - loss: 0.6939 - accuracy: 0.5090 - auc: 0.5110 - precision: 0.5039 - recall: 0.6960\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 3s 862ms/step - loss: 0.6940 - accuracy: 0.5023 - auc: 0.5041 - precision: 0.4989 - recall: 0.6756\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 2s 651ms/step - loss: 0.6948 - accuracy: 0.4983 - auc: 0.4962 - precision: 0.4958 - recall: 0.6471\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 2s 512ms/step - loss: 0.6949 - accuracy: 0.4919 - auc: 0.4904 - precision: 0.4903 - recall: 0.6068\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 2s 497ms/step - loss: 0.6937 - accuracy: 0.4950 - auc: 0.5029 - precision: 0.4924 - recall: 0.5653\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 2s 502ms/step - loss: 0.6934 - accuracy: 0.5043 - auc: 0.5098 - precision: 0.5005 - recall: 0.5455\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 2s 501ms/step - loss: 0.6935 - accuracy: 0.5034 - auc: 0.5062 - precision: 0.4997 - recall: 0.5012\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 2s 491ms/step - loss: 0.6927 - accuracy: 0.5021 - auc: 0.5122 - precision: 0.4983 - recall: 0.4721\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 2s 682ms/step - loss: 0.6935 - accuracy: 0.5079 - auc: 0.5068 - precision: 0.5048 - recall: 0.4407\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 3s 830ms/step - loss: 0.6937 - accuracy: 0.4956 - auc: 0.4997 - precision: 0.4904 - recall: 0.4211\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 2s 489ms/step - loss: 0.6933 - accuracy: 0.5013 - auc: 0.5085 - precision: 0.4970 - recall: 0.4013\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 2s 490ms/step - loss: 0.6931 - accuracy: 0.5049 - auc: 0.5107 - precision: 0.5015 - recall: 0.3903\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 493ms/step - loss: 0.6928 - accuracy: 0.5119 - auc: 0.5147 - precision: 0.5111 - recall: 0.3794\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 2s 491ms/step - loss: 0.6935 - accuracy: 0.5031 - auc: 0.5050 - precision: 0.4992 - recall: 0.3584\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.6931 - accuracy: 0.5037 - auc: 0.5089 - precision: 0.5000 - recall: 0.3575\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 2s 489ms/step - loss: 0.6937 - accuracy: 0.5073 - auc: 0.5040 - precision: 0.5054 - recall: 0.3374\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 2s 772ms/step - loss: 0.6930 - accuracy: 0.5071 - auc: 0.5114 - precision: 0.5051 - recall: 0.3428\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 3s 849ms/step - loss: 0.6939 - accuracy: 0.4990 - auc: 0.4999 - precision: 0.4933 - recall: 0.3495\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.6930 - accuracy: 0.5073 - auc: 0.5101 - precision: 0.5047 - recall: 0.3857\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 2s 501ms/step - loss: 0.6938 - accuracy: 0.5010 - auc: 0.5011 - precision: 0.4965 - recall: 0.3929\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 2s 485ms/step - loss: 0.6926 - accuracy: 0.5167 - auc: 0.5211 - precision: 0.5158 - recall: 0.4275\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 2s 488ms/step - loss: 0.6932 - accuracy: 0.5074 - auc: 0.5104 - precision: 0.5042 - recall: 0.4444\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 2s 513ms/step - loss: 0.6931 - accuracy: 0.5074 - auc: 0.5095 - precision: 0.5041 - recall: 0.4655\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 2s 498ms/step - loss: 0.6932 - accuracy: 0.5096 - auc: 0.5102 - precision: 0.5063 - recall: 0.4738\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 2s 824ms/step - loss: 0.6931 - accuracy: 0.5084 - auc: 0.5115 - precision: 0.5049 - recall: 0.4902\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 3s 823ms/step - loss: 0.6930 - accuracy: 0.5047 - auc: 0.5131 - precision: 0.5010 - recall: 0.4847\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 2s 528ms/step - loss: 0.6930 - accuracy: 0.5114 - auc: 0.5136 - precision: 0.5083 - recall: 0.4775\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 2s 552ms/step - loss: 0.6932 - accuracy: 0.5009 - auc: 0.5044 - precision: 0.4969 - recall: 0.4542\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 2s 523ms/step - loss: 0.6933 - accuracy: 0.5069 - auc: 0.5079 - precision: 0.5035 - recall: 0.4565\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.6925 - accuracy: 0.5130 - auc: 0.5157 - precision: 0.5106 - recall: 0.4514\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 2s 523ms/step - loss: 0.6923 - accuracy: 0.5167 - auc: 0.5230 - precision: 0.5154 - recall: 0.4390\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 2s 884ms/step - loss: 0.6935 - accuracy: 0.4963 - auc: 0.5040 - precision: 0.4902 - recall: 0.3725\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 3s 860ms/step - loss: 0.6932 - accuracy: 0.5150 - auc: 0.5137 - precision: 0.5162 - recall: 0.3613\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 2s 498ms/step - loss: 0.6932 - accuracy: 0.5123 - auc: 0.5108 - precision: 0.5135 - recall: 0.3279\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.6937 - accuracy: 0.5013 - auc: 0.4972 - precision: 0.4962 - recall: 0.3175\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 0.6937 - accuracy: 0.5013 - auc: 0.5003 - precision: 0.4962 - recall: 0.3169\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 2s 508ms/step - loss: 0.6934 - accuracy: 0.5089 - auc: 0.5013 - precision: 0.5077 - recall: 0.3411\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.6929 - accuracy: 0.5153 - auc: 0.5154 - precision: 0.5166 - recall: 0.3630\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 2s 540ms/step - loss: 0.6932 - accuracy: 0.5014 - auc: 0.5016 - precision: 0.4969 - recall: 0.3676\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 3s 942ms/step - loss: 0.6927 - accuracy: 0.5074 - auc: 0.5119 - precision: 0.5048 - recall: 0.3946\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 2s 610ms/step - loss: 0.6924 - accuracy: 0.5140 - auc: 0.5215 - precision: 0.5129 - recall: 0.4128\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 2s 489ms/step - loss: 0.6930 - accuracy: 0.5067 - auc: 0.5094 - precision: 0.5037 - recall: 0.4128\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 2s 489ms/step - loss: 0.6928 - accuracy: 0.5119 - auc: 0.5147 - precision: 0.5097 - recall: 0.4303\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 2s 490ms/step - loss: 0.6929 - accuracy: 0.5103 - auc: 0.5123 - precision: 0.5082 - recall: 0.4079\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 509ms/step - loss: 0.6928 - accuracy: 0.5183 - auc: 0.5163 - precision: 0.5179 - recall: 0.4237\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 2s 495ms/step - loss: 0.6924 - accuracy: 0.5164 - auc: 0.5159 - precision: 0.5150 - recall: 0.4384\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 2s 768ms/step - loss: 0.6926 - accuracy: 0.5167 - auc: 0.5201 - precision: 0.5151 - recall: 0.4482\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 3s 846ms/step - loss: 0.6922 - accuracy: 0.5234 - auc: 0.5259 - precision: 0.5230 - recall: 0.4514\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 494ms/step - loss: 0.6928 - accuracy: 0.5060 - auc: 0.5152 - precision: 0.5029 - recall: 0.3969\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 2s 485ms/step - loss: 0.6926 - accuracy: 0.5154 - auc: 0.5181 - precision: 0.5151 - recall: 0.4036\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 2s 493ms/step - loss: 0.6924 - accuracy: 0.5171 - auc: 0.5230 - precision: 0.5179 - recall: 0.3915\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.6924 - accuracy: 0.5093 - auc: 0.5164 - precision: 0.5076 - recall: 0.3739\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 2s 494ms/step - loss: 0.6923 - accuracy: 0.5216 - auc: 0.5274 - precision: 0.5251 - recall: 0.3762\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 2s 526ms/step - loss: 0.6926 - accuracy: 0.5184 - auc: 0.5195 - precision: 0.5219 - recall: 0.3535\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 3s 866ms/step - loss: 0.6924 - accuracy: 0.5190 - auc: 0.5256 - precision: 0.5238 - recall: 0.3391\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 3s 797ms/step - loss: 0.6919 - accuracy: 0.5209 - auc: 0.5261 - precision: 0.5264 - recall: 0.3446\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 2s 514ms/step - loss: 0.6931 - accuracy: 0.5097 - auc: 0.5111 - precision: 0.5085 - recall: 0.3630\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 2s 523ms/step - loss: 0.6927 - accuracy: 0.5190 - auc: 0.5206 - precision: 0.5191 - recall: 0.4188\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 2s 527ms/step - loss: 0.6927 - accuracy: 0.5183 - auc: 0.5159 - precision: 0.5167 - recall: 0.4537\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 2s 522ms/step - loss: 0.6919 - accuracy: 0.5247 - auc: 0.5333 - precision: 0.5229 - recall: 0.4822\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 2s 507ms/step - loss: 0.6921 - accuracy: 0.5224 - auc: 0.5275 - precision: 0.5195 - recall: 0.5017\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 2s 647ms/step - loss: 0.6924 - accuracy: 0.5159 - auc: 0.5218 - precision: 0.5125 - recall: 0.5012\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 3s 855ms/step - loss: 0.6928 - accuracy: 0.5074 - auc: 0.5104 - precision: 0.5037 - recall: 0.5066\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 2s 535ms/step - loss: 0.6922 - accuracy: 0.5190 - auc: 0.5272 - precision: 0.5145 - recall: 0.5463\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.6923 - accuracy: 0.5134 - auc: 0.5235 - precision: 0.5092 - recall: 0.5417\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 2s 527ms/step - loss: 0.6922 - accuracy: 0.5270 - auc: 0.5255 - precision: 0.5228 - recall: 0.5380\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.6918 - accuracy: 0.5193 - auc: 0.5287 - precision: 0.5160 - recall: 0.5058\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 2s 523ms/step - loss: 0.6916 - accuracy: 0.5153 - auc: 0.5299 - precision: 0.5123 - recall: 0.4839\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.6924 - accuracy: 0.5099 - auc: 0.5179 - precision: 0.5067 - recall: 0.4689\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 3s 890ms/step - loss: 0.6921 - accuracy: 0.5176 - auc: 0.5260 - precision: 0.5151 - recall: 0.4752\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 3s 706ms/step - loss: 0.6925 - accuracy: 0.5104 - auc: 0.5237 - precision: 0.5072 - recall: 0.4767\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 2s 521ms/step - loss: 0.6921 - accuracy: 0.5164 - auc: 0.5245 - precision: 0.5133 - recall: 0.4940\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.6911 - accuracy: 0.5286 - auc: 0.5387 - precision: 0.5248 - recall: 0.5302\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 2s 515ms/step - loss: 0.6921 - accuracy: 0.5179 - auc: 0.5259 - precision: 0.5138 - recall: 0.5305\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 2s 519ms/step - loss: 0.6916 - accuracy: 0.5191 - auc: 0.5282 - precision: 0.5152 - recall: 0.5265\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 2s 511ms/step - loss: 0.6917 - accuracy: 0.5253 - auc: 0.5325 - precision: 0.5221 - recall: 0.5127\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 2s 847ms/step - loss: 0.6923 - accuracy: 0.5200 - auc: 0.5244 - precision: 0.5177 - recall: 0.4790\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 3s 816ms/step - loss: 0.6918 - accuracy: 0.5231 - auc: 0.5313 - precision: 0.5234 - recall: 0.4381\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 2s 525ms/step - loss: 0.6920 - accuracy: 0.5203 - auc: 0.5260 - precision: 0.5212 - recall: 0.4102\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 2s 506ms/step - loss: 0.6919 - accuracy: 0.5203 - auc: 0.5286 - precision: 0.5209 - recall: 0.4154\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 2s 487ms/step - loss: 0.6911 - accuracy: 0.5270 - auc: 0.5398 - precision: 0.5298 - recall: 0.4174\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.6911 - accuracy: 0.5176 - auc: 0.5296 - precision: 0.5175 - recall: 0.4125\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 2s 492ms/step - loss: 0.6919 - accuracy: 0.5236 - auc: 0.5328 - precision: 0.5245 - recall: 0.4283\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 0.6914 - accuracy: 0.5269 - auc: 0.5345 - precision: 0.5279 - recall: 0.4413\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 3s 838ms/step - loss: 0.6908 - accuracy: 0.5301 - auc: 0.5373 - precision: 0.5311 - recall: 0.4554\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 2s 680ms/step - loss: 0.6924 - accuracy: 0.5224 - auc: 0.5268 - precision: 0.5217 - recall: 0.4534\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 2s 518ms/step - loss: 0.6914 - accuracy: 0.5220 - auc: 0.5337 - precision: 0.5199 - recall: 0.4807\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 2s 508ms/step - loss: 0.6907 - accuracy: 0.5279 - auc: 0.5393 - precision: 0.5249 - recall: 0.5127\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 2s 498ms/step - loss: 0.6915 - accuracy: 0.5251 - auc: 0.5313 - precision: 0.5215 - recall: 0.5236\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 2s 487ms/step - loss: 0.6919 - accuracy: 0.5301 - auc: 0.5336 - precision: 0.5256 - recall: 0.5472\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 2s 481ms/step - loss: 0.6919 - accuracy: 0.5230 - auc: 0.5285 - precision: 0.5196 - recall: 0.5147\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 2s 654ms/step - loss: 0.6912 - accuracy: 0.5173 - auc: 0.5306 - precision: 0.5137 - recall: 0.5118\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 3s 838ms/step - loss: 0.6911 - accuracy: 0.5296 - auc: 0.5370 - precision: 0.5261 - recall: 0.5253\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 2s 534ms/step - loss: 0.6915 - accuracy: 0.5163 - auc: 0.5289 - precision: 0.5127 - recall: 0.5101\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_4 (Batc  (None, None, 2)          8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " simple_rnn_16 (SimpleRNN)   (None, None, 528)         280368    \n",
            "                                                                 \n",
            " simple_rnn_17 (SimpleRNN)   (None, None, 256)         200960    \n",
            "                                                                 \n",
            " simple_rnn_18 (SimpleRNN)   (None, None, 128)         49280     \n",
            "                                                                 \n",
            " simple_rnn_19 (SimpleRNN)   (None, None, 64)          12352     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, None, 32)          2080      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, None, 16)          528       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, None, 1)           9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545,721\n",
            "Trainable params: 545,717\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model_2.predict(X_test)\n",
        "trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test.flatten(), trainPredict_binary.flatten())\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhaeWbSUvTQp",
        "outputId": "317c0422-1503-4883-db84-d2a1b20de706"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 727ms/step\n",
            "[[726 748]\n",
            " [757 769]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wifi x lte1m"
      ],
      "metadata": {
        "id": "0mGqThL8vhQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3,X_test,y_test = model_simpleRNN(dados_lte1m,dados_wifi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISNyRgImvkrk",
        "outputId": "79d3ed58-a0e9-429b-8206-e09509f1ab45"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 8s 481ms/step - loss: 0.7153 - accuracy: 0.4977 - auc: 0.4965 - precision: 0.4928 - recall: 0.5215\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 2s 490ms/step - loss: 0.7094 - accuracy: 0.5076 - auc: 0.5043 - precision: 0.5024 - recall: 0.4900\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 2s 482ms/step - loss: 0.7062 - accuracy: 0.5087 - auc: 0.5067 - precision: 0.5037 - recall: 0.4736\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.7036 - accuracy: 0.5097 - auc: 0.5088 - precision: 0.5048 - recall: 0.4684\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 488ms/step - loss: 0.7026 - accuracy: 0.5003 - auc: 0.5049 - precision: 0.4947 - recall: 0.4721\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 678ms/step - loss: 0.7026 - accuracy: 0.4999 - auc: 0.5008 - precision: 0.4945 - recall: 0.4964\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 3s 811ms/step - loss: 0.6997 - accuracy: 0.5126 - auc: 0.5121 - precision: 0.5075 - recall: 0.5010\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 2s 476ms/step - loss: 0.6979 - accuracy: 0.5117 - auc: 0.5171 - precision: 0.5066 - recall: 0.5025\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 2s 479ms/step - loss: 0.6971 - accuracy: 0.5107 - auc: 0.5148 - precision: 0.5056 - recall: 0.4918\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 2s 478ms/step - loss: 0.6986 - accuracy: 0.4997 - auc: 0.5060 - precision: 0.4943 - recall: 0.4906\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.6976 - accuracy: 0.5101 - auc: 0.5102 - precision: 0.5049 - recall: 0.5013\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 2s 475ms/step - loss: 0.6978 - accuracy: 0.5043 - auc: 0.5084 - precision: 0.4990 - recall: 0.4938\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 2s 467ms/step - loss: 0.6962 - accuracy: 0.5120 - auc: 0.5143 - precision: 0.5067 - recall: 0.5120\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 2s 619ms/step - loss: 0.6975 - accuracy: 0.4939 - auc: 0.5039 - precision: 0.4885 - recall: 0.4921\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 3s 827ms/step - loss: 0.6955 - accuracy: 0.5061 - auc: 0.5140 - precision: 0.5009 - recall: 0.5097\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 2s 490ms/step - loss: 0.6962 - accuracy: 0.5039 - auc: 0.5108 - precision: 0.4986 - recall: 0.5264\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 2s 498ms/step - loss: 0.6965 - accuracy: 0.5094 - auc: 0.5064 - precision: 0.5041 - recall: 0.5111\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 2s 476ms/step - loss: 0.6957 - accuracy: 0.5139 - auc: 0.5122 - precision: 0.5089 - recall: 0.4935\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 471ms/step - loss: 0.6951 - accuracy: 0.5073 - auc: 0.5119 - precision: 0.5023 - recall: 0.4459\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 2s 670ms/step - loss: 0.6944 - accuracy: 0.5174 - auc: 0.5182 - precision: 0.5152 - recall: 0.4161\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 2s 484ms/step - loss: 0.6944 - accuracy: 0.5091 - auc: 0.5164 - precision: 0.5050 - recall: 0.3901\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 3s 815ms/step - loss: 0.6953 - accuracy: 0.5109 - auc: 0.5110 - precision: 0.5072 - recall: 0.3945\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 2s 703ms/step - loss: 0.6939 - accuracy: 0.5156 - auc: 0.5189 - precision: 0.5136 - recall: 0.3927\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 2s 480ms/step - loss: 0.6927 - accuracy: 0.5223 - auc: 0.5260 - precision: 0.5222 - recall: 0.4037\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.6948 - accuracy: 0.5109 - auc: 0.5111 - precision: 0.5072 - recall: 0.3994\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 2s 770ms/step - loss: 0.6947 - accuracy: 0.5130 - auc: 0.5141 - precision: 0.5093 - recall: 0.4282\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 2s 511ms/step - loss: 0.6917 - accuracy: 0.5240 - auc: 0.5319 - precision: 0.5203 - recall: 0.4840\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 2s 477ms/step - loss: 0.6947 - accuracy: 0.5121 - auc: 0.5130 - precision: 0.5068 - recall: 0.5172\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.6924 - accuracy: 0.5199 - auc: 0.5284 - precision: 0.5139 - recall: 0.5449\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 3s 741ms/step - loss: 0.6940 - accuracy: 0.5164 - auc: 0.5176 - precision: 0.5108 - recall: 0.5345\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 2s 488ms/step - loss: 0.6941 - accuracy: 0.5097 - auc: 0.5126 - precision: 0.5046 - recall: 0.4938\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 2s 490ms/step - loss: 0.6937 - accuracy: 0.5093 - auc: 0.5164 - precision: 0.5043 - recall: 0.4727\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 2s 469ms/step - loss: 0.6930 - accuracy: 0.5137 - auc: 0.5213 - precision: 0.5088 - recall: 0.4903\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 2s 470ms/step - loss: 0.6931 - accuracy: 0.5124 - auc: 0.5195 - precision: 0.5072 - recall: 0.5079\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.6933 - accuracy: 0.5146 - auc: 0.5195 - precision: 0.5097 - recall: 0.4938\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 495ms/step - loss: 0.6924 - accuracy: 0.5210 - auc: 0.5257 - precision: 0.5167 - recall: 0.4903\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 3s 810ms/step - loss: 0.6922 - accuracy: 0.5259 - auc: 0.5305 - precision: 0.5236 - recall: 0.4612\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 2s 681ms/step - loss: 0.6928 - accuracy: 0.5157 - auc: 0.5237 - precision: 0.5119 - recall: 0.4528\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 2s 486ms/step - loss: 0.6932 - accuracy: 0.5097 - auc: 0.5193 - precision: 0.5052 - recall: 0.4334\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 2s 487ms/step - loss: 0.6917 - accuracy: 0.5259 - auc: 0.5340 - precision: 0.5242 - recall: 0.4502\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 2s 497ms/step - loss: 0.6931 - accuracy: 0.5163 - auc: 0.5221 - precision: 0.5133 - recall: 0.4285\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 2s 473ms/step - loss: 0.6931 - accuracy: 0.5057 - auc: 0.5181 - precision: 0.5005 - recall: 0.4346\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 2s 488ms/step - loss: 0.6930 - accuracy: 0.5109 - auc: 0.5181 - precision: 0.5061 - recall: 0.4704\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 2s 472ms/step - loss: 0.6929 - accuracy: 0.5140 - auc: 0.5205 - precision: 0.5091 - recall: 0.4903\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 0.6917 - accuracy: 0.5229 - auc: 0.5314 - precision: 0.5184 - recall: 0.4993\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 2s 665ms/step - loss: 0.6924 - accuracy: 0.5183 - auc: 0.5266 - precision: 0.5138 - recall: 0.4909\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 2s 472ms/step - loss: 0.6930 - accuracy: 0.5147 - auc: 0.5223 - precision: 0.5100 - recall: 0.4877\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 2s 490ms/step - loss: 0.6913 - accuracy: 0.5196 - auc: 0.5328 - precision: 0.5154 - recall: 0.4828\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 0.6917 - accuracy: 0.5230 - auc: 0.5323 - precision: 0.5197 - recall: 0.4716\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 2s 473ms/step - loss: 0.6926 - accuracy: 0.5227 - auc: 0.5249 - precision: 0.5205 - recall: 0.4473\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 463ms/step - loss: 0.6918 - accuracy: 0.5249 - auc: 0.5312 - precision: 0.5235 - recall: 0.4407\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 2s 498ms/step - loss: 0.6913 - accuracy: 0.5264 - auc: 0.5348 - precision: 0.5250 - recall: 0.4493\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 3s 803ms/step - loss: 0.6910 - accuracy: 0.5291 - auc: 0.5377 - precision: 0.5270 - recall: 0.4701\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 2s 661ms/step - loss: 0.6924 - accuracy: 0.5210 - auc: 0.5275 - precision: 0.5182 - recall: 0.4525\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 473ms/step - loss: 0.6917 - accuracy: 0.5267 - auc: 0.5338 - precision: 0.5249 - recall: 0.4571\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 2s 481ms/step - loss: 0.6922 - accuracy: 0.5191 - auc: 0.5278 - precision: 0.5154 - recall: 0.4701\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 2s 476ms/step - loss: 0.6906 - accuracy: 0.5269 - auc: 0.5387 - precision: 0.5233 - recall: 0.4906\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 2s 482ms/step - loss: 0.6924 - accuracy: 0.5181 - auc: 0.5262 - precision: 0.5139 - recall: 0.4811\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 2s 463ms/step - loss: 0.6905 - accuracy: 0.5283 - auc: 0.5391 - precision: 0.5242 - recall: 0.5039\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 2s 473ms/step - loss: 0.6907 - accuracy: 0.5243 - auc: 0.5394 - precision: 0.5199 - recall: 0.5007\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 3s 819ms/step - loss: 0.6919 - accuracy: 0.5230 - auc: 0.5310 - precision: 0.5198 - recall: 0.4701\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 2s 644ms/step - loss: 0.6903 - accuracy: 0.5249 - auc: 0.5409 - precision: 0.5229 - recall: 0.4516\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 2s 476ms/step - loss: 0.6893 - accuracy: 0.5330 - auc: 0.5471 - precision: 0.5348 - recall: 0.4308\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 2s 480ms/step - loss: 0.6907 - accuracy: 0.5273 - auc: 0.5411 - precision: 0.5282 - recall: 0.4167\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 2s 485ms/step - loss: 0.6941 - accuracy: 0.5121 - auc: 0.5188 - precision: 0.5088 - recall: 0.4014\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 2s 478ms/step - loss: 0.6908 - accuracy: 0.5189 - auc: 0.5374 - precision: 0.5163 - recall: 0.4343\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 2s 477ms/step - loss: 0.6917 - accuracy: 0.5226 - auc: 0.5337 - precision: 0.5200 - recall: 0.4534\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 2s 480ms/step - loss: 0.6906 - accuracy: 0.5307 - auc: 0.5406 - precision: 0.5270 - recall: 0.5022\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 3s 794ms/step - loss: 0.6907 - accuracy: 0.5287 - auc: 0.5421 - precision: 0.5236 - recall: 0.5247\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 2s 659ms/step - loss: 0.6911 - accuracy: 0.5259 - auc: 0.5371 - precision: 0.5198 - recall: 0.5446\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 2s 497ms/step - loss: 0.6915 - accuracy: 0.5217 - auc: 0.5347 - precision: 0.5159 - recall: 0.5397\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 2s 472ms/step - loss: 0.6922 - accuracy: 0.5277 - auc: 0.5313 - precision: 0.5217 - recall: 0.5446\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 2s 482ms/step - loss: 0.6916 - accuracy: 0.5261 - auc: 0.5353 - precision: 0.5203 - recall: 0.5403\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 2s 481ms/step - loss: 0.6906 - accuracy: 0.5257 - auc: 0.5399 - precision: 0.5207 - recall: 0.5192\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 2s 481ms/step - loss: 0.6901 - accuracy: 0.5337 - auc: 0.5452 - precision: 0.5294 - recall: 0.5178\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 2s 488ms/step - loss: 0.6896 - accuracy: 0.5357 - auc: 0.5453 - precision: 0.5313 - recall: 0.5218\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 3s 791ms/step - loss: 0.6904 - accuracy: 0.5313 - auc: 0.5428 - precision: 0.5276 - recall: 0.5019\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 2s 628ms/step - loss: 0.6910 - accuracy: 0.5309 - auc: 0.5395 - precision: 0.5285 - recall: 0.4785\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 2s 465ms/step - loss: 0.6902 - accuracy: 0.5346 - auc: 0.5465 - precision: 0.5338 - recall: 0.4672\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 2s 487ms/step - loss: 0.6917 - accuracy: 0.5217 - auc: 0.5314 - precision: 0.5181 - recall: 0.4765\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 2s 480ms/step - loss: 0.6915 - accuracy: 0.5293 - auc: 0.5344 - precision: 0.5246 - recall: 0.5163\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 2s 476ms/step - loss: 0.6911 - accuracy: 0.5273 - auc: 0.5378 - precision: 0.5216 - recall: 0.5374\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 2s 467ms/step - loss: 0.6905 - accuracy: 0.5279 - auc: 0.5403 - precision: 0.5221 - recall: 0.5400\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 2s 481ms/step - loss: 0.6903 - accuracy: 0.5251 - auc: 0.5389 - precision: 0.5206 - recall: 0.5077\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 3s 812ms/step - loss: 0.6902 - accuracy: 0.5280 - auc: 0.5418 - precision: 0.5253 - recall: 0.4770\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 2s 667ms/step - loss: 0.6898 - accuracy: 0.5314 - auc: 0.5467 - precision: 0.5302 - recall: 0.4643\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 2s 484ms/step - loss: 0.6888 - accuracy: 0.5334 - auc: 0.5513 - precision: 0.5331 - recall: 0.4583\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 2s 479ms/step - loss: 0.6895 - accuracy: 0.5336 - auc: 0.5478 - precision: 0.5325 - recall: 0.4684\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 2s 479ms/step - loss: 0.6898 - accuracy: 0.5370 - auc: 0.5469 - precision: 0.5347 - recall: 0.4941\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 2s 476ms/step - loss: 0.6892 - accuracy: 0.5346 - auc: 0.5503 - precision: 0.5314 - recall: 0.5013\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 2s 472ms/step - loss: 0.6890 - accuracy: 0.5386 - auc: 0.5505 - precision: 0.5352 - recall: 0.5108\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 2s 483ms/step - loss: 0.6913 - accuracy: 0.5273 - auc: 0.5365 - precision: 0.5230 - recall: 0.5062\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 3s 789ms/step - loss: 0.6885 - accuracy: 0.5364 - auc: 0.5540 - precision: 0.5322 - recall: 0.5201\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 2s 660ms/step - loss: 0.6890 - accuracy: 0.5409 - auc: 0.5520 - precision: 0.5383 - recall: 0.5056\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 2s 479ms/step - loss: 0.6896 - accuracy: 0.5376 - auc: 0.5476 - precision: 0.5362 - recall: 0.4837\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 2s 471ms/step - loss: 0.6903 - accuracy: 0.5314 - auc: 0.5452 - precision: 0.5292 - recall: 0.4782\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 2s 478ms/step - loss: 0.6902 - accuracy: 0.5281 - auc: 0.5445 - precision: 0.5253 - recall: 0.4802\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 2s 494ms/step - loss: 0.6887 - accuracy: 0.5347 - auc: 0.5518 - precision: 0.5327 - recall: 0.4846\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 2s 487ms/step - loss: 0.6904 - accuracy: 0.5319 - auc: 0.5426 - precision: 0.5284 - recall: 0.4999\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 2s 478ms/step - loss: 0.6905 - accuracy: 0.5264 - auc: 0.5415 - precision: 0.5218 - recall: 0.5120\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_5 (Batc  (None, None, 2)          8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " simple_rnn_20 (SimpleRNN)   (None, None, 528)         280368    \n",
            "                                                                 \n",
            " simple_rnn_21 (SimpleRNN)   (None, None, 256)         200960    \n",
            "                                                                 \n",
            " simple_rnn_22 (SimpleRNN)   (None, None, 128)         49280     \n",
            "                                                                 \n",
            " simple_rnn_23 (SimpleRNN)   (None, None, 64)          12352     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, None, 32)          2080      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, None, 16)          528       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, None, 1)           9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 545,721\n",
            "Trainable params: 545,717\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredict = model_2.predict(X_test)\n",
        "trainPredict_binary = (trainPredict > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test.flatten(), trainPredict_binary.flatten())\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00KBcxBHxhtV",
        "outputId": "eccc0844-c9b9-4484-eca0-f4a8d6928deb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 413ms/step\n",
            "[[717 746]\n",
            " [762 775]]\n"
          ]
        }
      ]
    }
  ]
}