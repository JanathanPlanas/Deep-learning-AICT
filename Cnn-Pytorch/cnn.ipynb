{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janat\\OneDrive\\Documentos\\GitHub\\Deep-learning-AICT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "from  Data_Loader import DATA_1M\n",
    "from helper_functions import accuracy_fn, train\n",
    "from CnnModel import NeuralNetCNN\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                              f1_score, recall_score)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 133332996 into shape (500)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m500\u001b[39m, \u001b[39m1000\u001b[39m ,\u001b[39m2000\u001b[39m,\u001b[39m4000\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(columns)):\n\u001b[1;32m----> 4\u001b[0m     data \u001b[39m=\u001b[39m DATA_1M(seconds\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m,columns\u001b[39m=\u001b[39mcolumns[i], jump_time \u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, n_jumps\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m) ; data_fourier \u001b[39m=\u001b[39m data(Fourier\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, Normalizing\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m     Torch \u001b[39m=\u001b[39m NeuralNetCNN(columns\u001b[39m=\u001b[39m data_fourier\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,conv_blocks \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,groupblocks\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     data\u001b[39m.\u001b[39mSpliting(data\u001b[39m=\u001b[39m data_fourier, random_state\u001b[39m=\u001b[39m \u001b[39m30\u001b[39m, test_size \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m, shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, inplace\u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\janat\\OneDrive\\Documentos\\GitHub\\Deep-learning-AICT\\Cnn-Pytorch\\Data_Loader.py:122\u001b[0m, in \u001b[0;36mDATA_1M.__call__\u001b[1;34m(self, Fourier, Normalizing)\u001b[0m\n\u001b[0;32m    119\u001b[0m     samples_signal \u001b[39m=\u001b[39m [clear, lte, wifi]\n\u001b[0;32m    121\u001b[0m     \u001b[39m# RESHAPE DOS DADOS\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     signal_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m x: np\u001b[39m.\u001b[39;49mhstack(\n\u001b[0;32m    123\u001b[0m         x)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues_reshaped), samples_signal))\n\u001b[0;32m    124\u001b[0m     \u001b[39m# Reshaping data            # Slicing data\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39melif\u001b[39;00m Fourier \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m Normalizing \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\janat\\OneDrive\\Documentos\\GitHub\\Deep-learning-AICT\\Cnn-Pytorch\\Data_Loader.py:123\u001b[0m, in \u001b[0;36mDATA_1M.__call__.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    119\u001b[0m     samples_signal \u001b[39m=\u001b[39m [clear, lte, wifi]\n\u001b[0;32m    121\u001b[0m     \u001b[39m# RESHAPE DOS DADOS\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     signal_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39;49mhstack(\n\u001b[1;32m--> 123\u001b[0m         x)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues_reshaped), samples_signal))\n\u001b[0;32m    124\u001b[0m     \u001b[39m# Reshaping data            # Slicing data\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39melif\u001b[39;00m Fourier \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m Normalizing \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 133332996 into shape (500)"
     ]
    }
   ],
   "source": [
    "columns = [500, 1000 ,2000,4000]\n",
    "for i in range(len(columns)):\n",
    "\n",
    "    data = DATA_1M(seconds=40,columns=columns[i], jump_time =2, n_jumps=3) ; data_fourier = data(Fourier=True, Normalizing= True)\n",
    "    \n",
    "    Torch = NeuralNetCNN(columns= data_fourier.shape[1] -1,conv_blocks =1,groupblocks=1)\n",
    "\n",
    "    data.Spliting(data= data_fourier, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "\n",
    "    train_dataloader , test_dataloader = data.DataLoaders(batch_size=64, inplace=True)\n",
    "\n",
    "    writer = SummaryWriter(f\"\"\"\n",
    "                           Experiment Fourier- {data_fourier.shape[1]-1} \n",
    "                           input size - {len(list(Torch.Cnn.children()))} Layers ,\n",
    "                           {Torch.count_blocks(Torch.Cnn)} Blocks\n",
    "                           \"\"\")\n",
    "\n",
    "    train(model= Torch.Cnn,\n",
    "        train_dataloader= train_dataloader,\n",
    "        test_dataloader= test_dataloader,\n",
    "        optimizer= Torch.optimizer,\n",
    "        loss_fn= Torch.loss_fn,\n",
    "        device= Torch.device,\n",
    "        writer= writer,\n",
    "        epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de camadas: 3\n"
     ]
    }
   ],
   "source": [
    "Torch = NeuralNetCNN(columns= data_fourier.shape[1] -1,conv_blocks =1,groupblocks=3)\n",
    "model  = Torch.Cnn\n",
    "\n",
    "# Obtenha todos os módulos filhos do modelo\n",
    "layers = list(model.children())\n",
    "\n",
    "# Conte o número de camadas\n",
    "num_layers = len(layers)\n",
    "\n",
    "# Imprima a quantidade de camadas\n",
    "print(\"Número de camadas:\", num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv1d(2000, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "   (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU()\n",
       "   (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): ConvBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv1d(2000, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "       (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       "   (1): ConvBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv1d(32, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "       (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       "   (2): ConvBlock(\n",
       "     (conv1): Sequential(\n",
       "       (0): Conv1d(48, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "       (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU()\n",
       "       (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "   (2): ReLU()\n",
       "   (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (4): Linear(in_features=32, out_features=3, bias=True)\n",
       "   (5): LogSoftmax(dim=1)\n",
       " )]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourer + Normalizado , 14 segundos de captura, 15 epocas, 64 batch size - 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 0.96096 | Train accuracy: 58.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:43,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 32.60602 | Test accuracy: 76.38%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 0.68410 | Train accuracy: 89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:09<00:36,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 27.79520 | Test accuracy: 86.57%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 0.61033 | Train accuracy: 95.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:13<00:32,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 26.40515 | Test accuracy: 90.07%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.58992 | Train accuracy: 96.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:18<00:27,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 25.50709 | Test accuracy: 91.81%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.58072 | Train accuracy: 97.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:22<00:21,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 25.16285 | Test accuracy: 92.62%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.57410 | Train accuracy: 98.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:29<00:20,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 24.92139 | Test accuracy: 93.14%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.57628 | Train accuracy: 97.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:36<00:18,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 24.97611 | Test accuracy: 93.02%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.57341 | Train accuracy: 98.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:43<00:12,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 24.75427 | Test accuracy: 93.55%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.57364 | Train accuracy: 98.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:48<00:05,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 24.81820 | Test accuracy: 93.35%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.57023 | Train accuracy: 98.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:54<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 24.65441 | Test accuracy: 93.81%\n",
      "CPU times: total: 1min 30s\n",
      "Wall time: 54.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.94      0.94      0.94      1651\n",
      "        WIFI       0.96      0.93      0.95      1679\n",
      "         LTE       0.93      0.96      0.95      1670\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.95      0.95      0.95      5000\n",
      "weighted avg       0.95      0.95      0.95      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data.y_test, Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9454</td>\n",
       "      <td>0.945404</td>\n",
       "      <td>0.9454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_Score  Recall\n",
       "0    0.9454  0.945404  0.9454"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "torch_pred = Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader)\n",
    "metrics = {'Accuracy':accuracy_score(data.y_test,torch_pred),'F1_Score':f1_score(data.y_test,torch_pred,average=\"weighted\"),\n",
    "          'Recall':recall_score(data.y_test,torch_pred,average=\"weighted\")}\n",
    "#THE ACCURACY TELL US HOW GOOD FIT THE MODEL WAS\n",
    "\n",
    "pd.DataFrame([metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1,  ..., 2, 2, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948502994011976"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "recall_score(data.y_test,torch_pred, average=\"weighted\",labels=np.array([2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mesma configuração - 6 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.07098 | Train accuracy: 43.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:33<21:51, 93.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 166.62012 | Test accuracy: 44.39%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 1.03330 | Train accuracy: 49.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [03:11<20:50, 96.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 163.54989 | Test accuracy: 48.82%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 0.99601 | Train accuracy: 53.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [04:48<19:18, 96.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 161.44041 | Test accuracy: 50.57%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.96761 | Train accuracy: 56.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [06:27<17:53, 97.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 157.20325 | Test accuracy: 53.16%\n",
      " Epoch: 4\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.ExtenderClassifier, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer_extended,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem Fourier + Normalizado , 14 segundos de captura, 15 epocas, 128 batch size - 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho da memória ocupada :1068.68 MB\n",
      "X_train shape: (52501, 2000) float64\n",
      "X_Test shape: (17501, 2000) float64\n",
      "y_train shape: (52501,) float64\n",
      "y_test shape: (17501,) float64\n",
      "\n",
      "--------\n",
      "X_train device: cpu\n",
      "X_Test device: cpu\n",
      "y_train device: cpu\n",
      "y_test device: cpu\n",
      "Valor 0: 23334 ocorrência(s)- 0.33%\n",
      "Valor 1: 23334 ocorrência(s)- 0.33%\n",
      "Valor 2: 23334 ocorrência(s)- 0.33%\n",
      "Dataset :  (70002, 2001)\n",
      "CPU times: total: 40.6 s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_nofourier = data(Fourier=False, Normalizing= True)\n",
    "data.Spliting(data= data_nofourier, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([128, 2000]) y torch.Size([128])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001345FCEC150>, <torch.utils.data.dataloader.DataLoader object at 0x000001345DDF1BD0>)\n",
      "Length of train dataloader: 411 batches of 128\n",
      "Length of test dataloader: 137 batches of 128\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 60 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataloader , test_dataloader = data.DataLoaders(batch_size=128, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.13088 | Train accuracy: 33.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:37<08:39, 37.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.17614 | Test accuracy: 36.39%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 1.10038 | Train accuracy: 36.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:15<08:11, 37.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 75.27109 | Test accuracy: 38.85%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 1.07989 | Train accuracy: 40.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [01:46<06:56, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 73.79953 | Test accuracy: 42.54%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 1.01034 | Train accuracy: 50.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:15<05:56, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 64.21842 | Test accuracy: 60.43%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.85010 | Train accuracy: 68.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:47<05:22, 32.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 57.08392 | Test accuracy: 71.91%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.79072 | Train accuracy: 75.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [03:19<04:50, 32.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 54.73005 | Test accuracy: 75.73%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.76101 | Train accuracy: 78.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:48<04:09, 31.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 53.75343 | Test accuracy: 77.21%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.75157 | Train accuracy: 79.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [04:16<03:30, 30.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 53.04092 | Test accuracy: 78.29%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.74240 | Train accuracy: 80.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [04:45<02:58, 29.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 52.29510 | Test accuracy: 79.45%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.72036 | Train accuracy: 82.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [05:16<02:30, 30.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 50.95913 | Test accuracy: 81.34%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.70435 | Train accuracy: 84.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [05:42<01:55, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 51.64521 | Test accuracy: 80.31%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.70348 | Train accuracy: 84.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [06:11<01:27, 29.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 50.35984 | Test accuracy: 82.13%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.68957 | Train accuracy: 86.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [07:07<01:14, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 50.51085 | Test accuracy: 81.86%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.68546 | Train accuracy: 86.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [07:36<00:34, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 50.15611 | Test accuracy: 82.68%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.67446 | Train accuracy: 87.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [08:04<00:00, 32.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 48.61959 | Test accuracy: 84.71%\n",
      "CPU times: total: 14min 23s\n",
      "Wall time: 8min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.39</td>\n",
       "      <td>76.18</td>\n",
       "      <td>33.74</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.85</td>\n",
       "      <td>75.27</td>\n",
       "      <td>36.20</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.54</td>\n",
       "      <td>73.80</td>\n",
       "      <td>40.56</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.43</td>\n",
       "      <td>64.22</td>\n",
       "      <td>50.29</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.91</td>\n",
       "      <td>57.08</td>\n",
       "      <td>68.97</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.73</td>\n",
       "      <td>54.73</td>\n",
       "      <td>75.55</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77.21</td>\n",
       "      <td>53.75</td>\n",
       "      <td>78.56</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78.29</td>\n",
       "      <td>53.04</td>\n",
       "      <td>79.69</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79.45</td>\n",
       "      <td>52.30</td>\n",
       "      <td>80.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81.34</td>\n",
       "      <td>50.96</td>\n",
       "      <td>82.92</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80.31</td>\n",
       "      <td>51.65</td>\n",
       "      <td>84.60</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>82.13</td>\n",
       "      <td>50.36</td>\n",
       "      <td>84.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81.86</td>\n",
       "      <td>50.51</td>\n",
       "      <td>86.06</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82.68</td>\n",
       "      <td>50.16</td>\n",
       "      <td>86.49</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84.71</td>\n",
       "      <td>48.62</td>\n",
       "      <td>87.60</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
       "0           36.39       76.18           33.74        1.13\n",
       "1           38.85       75.27           36.20        1.10\n",
       "2           42.54       73.80           40.56        1.08\n",
       "3           60.43       64.22           50.29        1.01\n",
       "4           71.91       57.08           68.97        0.85\n",
       "5           75.73       54.73           75.55        0.79\n",
       "6           77.21       53.75           78.56        0.76\n",
       "7           78.29       53.04           79.69        0.75\n",
       "8           79.45       52.30           80.67        0.74\n",
       "9           81.34       50.96           82.92        0.72\n",
       "10          80.31       51.65           84.60        0.70\n",
       "11          82.13       50.36           84.66        0.70\n",
       "12          81.86       50.51           86.06        0.69\n",
       "13          82.68       50.16           86.49        0.69\n",
       "14          84.71       48.62           87.60        0.67"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch(test= True, train= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.25533333333334"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch(test= True, train= True)[\"Test Accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.78      0.85      0.81      5940\n",
      "        WIFI       0.81      0.75      0.78      5734\n",
      "         LTE       0.95      0.94      0.95      5827\n",
      "\n",
      "    accuracy                           0.85     17501\n",
      "   macro avg       0.85      0.85      0.85     17501\n",
      "weighted avg       0.85      0.85      0.85     17501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data.y_test, Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourier+ Normalizado , 32 segundos de captura, 15 epocas + 4 Layers, input size 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([128, 2000]) y torch.Size([128])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x0000023D42983A10>, <torch.utils.data.dataloader.DataLoader object at 0x0000023D42983950>)\n",
      "Length of train dataloader: 938 batches of 128\n",
      "Length of test dataloader: 313 batches of 128\n"
     ]
    }
   ],
   "source": [
    "train_dataloader , test_dataloader = data_F30sec.DataLoaders(batch_size=64, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.07160 | Train accuracy: 42.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:49<11:31, 49.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 166.09800 | Test accuracy: 45.41%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 1.00454 | Train accuracy: 53.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:40<10:52, 50.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 159.48874 | Test accuracy: 52.15%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 0.95151 | Train accuracy: 59.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [02:30<10:05, 50.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 177.24175 | Test accuracy: 40.10%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.92274 | Train accuracy: 62.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [03:22<09:18, 50.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 173.82980 | Test accuracy: 43.42%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.90449 | Train accuracy: 64.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [04:13<08:29, 50.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 196.33875 | Test accuracy: 23.84%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.89269 | Train accuracy: 65.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [05:04<07:39, 51.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.83967 | Test accuracy: 33.58%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.88054 | Train accuracy: 66.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [05:56<06:49, 51.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 173.94071 | Test accuracy: 44.23%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.86646 | Train accuracy: 68.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [06:47<05:58, 51.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 191.30008 | Test accuracy: 30.60%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.85784 | Train accuracy: 68.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [07:38<05:07, 51.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 144.26116 | Test accuracy: 62.92%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.85924 | Train accuracy: 68.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [08:30<04:16, 51.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 183.67788 | Test accuracy: 35.35%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.85273 | Train accuracy: 69.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [09:24<03:28, 52.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 178.43675 | Test accuracy: 41.92%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.85319 | Train accuracy: 69.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [10:17<02:37, 52.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 193.08496 | Test accuracy: 32.17%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.84848 | Train accuracy: 70.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [11:09<01:44, 52.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 206.69112 | Test accuracy: 23.01%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.84560 | Train accuracy: 70.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [12:00<00:52, 52.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 177.42378 | Test accuracy: 44.91%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.83859 | Train accuracy: 71.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [12:52<00:00, 51.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 194.37509 | Test accuracy: 31.32%\n",
      "CPU times: total: 1h 17min 5s\n",
      "Wall time: 12min 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch_F30sec.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch_F30sec.Cnn, \n",
    "        loss_fn=Torch_F30sec.loss_fn,\n",
    "        optimizer=Torch_F30sec.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch_F30sec.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.41</td>\n",
       "      <td>166.10</td>\n",
       "      <td>42.64</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.15</td>\n",
       "      <td>159.49</td>\n",
       "      <td>53.01</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.10</td>\n",
       "      <td>177.24</td>\n",
       "      <td>59.04</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.42</td>\n",
       "      <td>173.83</td>\n",
       "      <td>62.14</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.84</td>\n",
       "      <td>196.34</td>\n",
       "      <td>64.08</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.58</td>\n",
       "      <td>190.84</td>\n",
       "      <td>65.37</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44.23</td>\n",
       "      <td>173.94</td>\n",
       "      <td>66.65</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.60</td>\n",
       "      <td>191.30</td>\n",
       "      <td>68.05</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62.92</td>\n",
       "      <td>144.26</td>\n",
       "      <td>68.98</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.35</td>\n",
       "      <td>183.68</td>\n",
       "      <td>68.87</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41.92</td>\n",
       "      <td>178.44</td>\n",
       "      <td>69.60</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32.17</td>\n",
       "      <td>193.08</td>\n",
       "      <td>69.57</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.01</td>\n",
       "      <td>206.69</td>\n",
       "      <td>70.04</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.91</td>\n",
       "      <td>177.42</td>\n",
       "      <td>70.33</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31.32</td>\n",
       "      <td>194.38</td>\n",
       "      <td>71.06</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
       "0           45.41      166.10           42.64        1.07\n",
       "1           52.15      159.49           53.01        1.00\n",
       "2           40.10      177.24           59.04        0.95\n",
       "3           43.42      173.83           62.14        0.92\n",
       "4           23.84      196.34           64.08        0.90\n",
       "5           33.58      190.84           65.37        0.89\n",
       "6           44.23      173.94           66.65        0.88\n",
       "7           30.60      191.30           68.05        0.87\n",
       "8           62.92      144.26           68.98        0.86\n",
       "9           35.35      183.68           68.87        0.86\n",
       "10          41.92      178.44           69.60        0.85\n",
       "11          32.17      193.08           69.57        0.85\n",
       "12          23.01      206.69           70.04        0.85\n",
       "13          44.91      177.42           70.33        0.85\n",
       "14          31.32      194.38           71.06        0.84"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch_F30sec(test= True, train= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.00      0.00      0.00     13289\n",
      "        WIFI       0.14      0.02      0.03     13281\n",
      "         LTE       0.32      0.92      0.47     13431\n",
      "\n",
      "    accuracy                           0.31     40001\n",
      "   macro avg       0.15      0.31      0.17     40001\n",
      "weighted avg       0.15      0.31      0.17     40001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data_F30sec.y_test, Torch_F30sec.Making_Predictions(model = Torch_F30sec.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sem Fourier - 32 segundos de captura- 4 layers, 2000 input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho da memória ocupada :2442.66 MB\n",
      "X_train shape: (120001, 2000) float64\n",
      "X_Test shape: (40001, 2000) float64\n",
      "y_train shape: (120001,) float64\n",
      "y_test shape: (40001,) float64\n",
      "\n",
      "--------\n",
      "X_train device: cpu\n",
      "X_Test device: cpu\n",
      "y_train device: cpu\n",
      "y_test device: cpu\n",
      "Valor 0: 53334 ocorrência(s)- 0.33%\n",
      "Valor 1: 53334 ocorrência(s)- 0.33%\n",
      "Valor 2: 53334 ocorrência(s)- 0.33%\n",
      "Dataset :  (160002, 2001)\n",
      "CPU times: total: 3min\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data_F30sec(Fourier=False, Normalizing= True)\n",
    "data_F30sec.Spliting(data= data, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([128, 2000]) y torch.Size([128])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x0000023D0C20C190>, <torch.utils.data.dataloader.DataLoader object at 0x0000023D0C20C390>)\n",
      "Length of train dataloader: 938 batches of 128\n",
      "Length of test dataloader: 313 batches of 128\n",
      "CPU times: total: 672 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataloader , test_dataloader = data_F30sec.DataLoaders(batch_size=128, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.10794 | Train accuracy: 40.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:49<11:30, 49.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.83967 | Test accuracy: 33.58%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 0.88925 | Train accuracy: 64.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:39<10:47, 49.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 131.95667 | Test accuracy: 70.35%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 0.78422 | Train accuracy: 76.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [02:29<09:56, 49.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 121.48539 | Test accuracy: 77.74%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.74231 | Train accuracy: 80.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [03:19<09:08, 49.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.06547 | Test accuracy: 33.16%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.71995 | Train accuracy: 82.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [04:10<08:25, 50.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 135.46761 | Test accuracy: 62.50%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.70439 | Train accuracy: 84.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [05:01<07:35, 50.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 192.43799 | Test accuracy: 32.57%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.68786 | Train accuracy: 86.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [05:52<06:45, 50.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.83967 | Test accuracy: 33.58%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.67854 | Train accuracy: 87.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [06:43<05:54, 50.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 152.31059 | Test accuracy: 58.15%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.67079 | Train accuracy: 87.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [07:34<05:05, 50.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.83967 | Test accuracy: 33.58%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.66567 | Train accuracy: 88.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [08:26<04:15, 51.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 108.92240 | Test accuracy: 85.64%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.66238 | Train accuracy: 88.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [09:19<03:27, 51.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 152.29137 | Test accuracy: 58.29%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.65945 | Train accuracy: 89.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [10:14<02:38, 52.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.83967 | Test accuracy: 33.58%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.65970 | Train accuracy: 89.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [11:08<01:46, 53.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.83967 | Test accuracy: 33.58%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.66175 | Train accuracy: 88.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [12:05<00:54, 54.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 185.62272 | Test accuracy: 35.97%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.65394 | Train accuracy: 89.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [13:00<00:00, 52.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 190.84588 | Test accuracy: 33.58%\n",
      "CPU times: total: 1h 17min 48s\n",
      "Wall time: 13min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch_F30sec.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch_F30sec.Cnn, \n",
    "        loss_fn=Torch_F30sec.loss_fn,\n",
    "        optimizer=Torch_F30sec.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch_F30sec.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.58</td>\n",
       "      <td>190.84</td>\n",
       "      <td>40.56</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.35</td>\n",
       "      <td>131.96</td>\n",
       "      <td>64.82</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.74</td>\n",
       "      <td>121.49</td>\n",
       "      <td>76.40</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.16</td>\n",
       "      <td>190.07</td>\n",
       "      <td>80.69</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.50</td>\n",
       "      <td>135.47</td>\n",
       "      <td>82.97</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32.57</td>\n",
       "      <td>192.44</td>\n",
       "      <td>84.54</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.58</td>\n",
       "      <td>190.84</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58.15</td>\n",
       "      <td>152.31</td>\n",
       "      <td>87.18</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.58</td>\n",
       "      <td>190.84</td>\n",
       "      <td>87.96</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85.64</td>\n",
       "      <td>108.92</td>\n",
       "      <td>88.51</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>58.29</td>\n",
       "      <td>152.29</td>\n",
       "      <td>88.82</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33.58</td>\n",
       "      <td>190.84</td>\n",
       "      <td>89.12</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33.58</td>\n",
       "      <td>190.84</td>\n",
       "      <td>89.11</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35.97</td>\n",
       "      <td>185.62</td>\n",
       "      <td>88.90</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33.58</td>\n",
       "      <td>190.85</td>\n",
       "      <td>89.69</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
       "0           33.58      190.84           40.56        1.11\n",
       "1           70.35      131.96           64.82        0.89\n",
       "2           77.74      121.49           76.40        0.78\n",
       "3           33.16      190.07           80.69        0.74\n",
       "4           62.50      135.47           82.97        0.72\n",
       "5           32.57      192.44           84.54        0.70\n",
       "6           33.58      190.84           86.22        0.69\n",
       "7           58.15      152.31           87.18        0.68\n",
       "8           33.58      190.84           87.96        0.67\n",
       "9           85.64      108.92           88.51        0.67\n",
       "10          58.29      152.29           88.82        0.66\n",
       "11          33.58      190.84           89.12        0.66\n",
       "12          33.58      190.84           89.11        0.66\n",
       "13          35.97      185.62           88.90        0.66\n",
       "14          33.58      190.85           89.69        0.65"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch_F30sec(test= True, train= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.00      0.00      0.00     13289\n",
      "        WIFI       0.00      0.00      0.00     13281\n",
      "         LTE       0.34      1.00      0.50     13431\n",
      "\n",
      "    accuracy                           0.34     40001\n",
      "   macro avg       0.11      0.33      0.17     40001\n",
      "weighted avg       0.11      0.34      0.17     40001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data_F30sec.y_test, Torch_F30sec.Making_Predictions(model = Torch_F30sec.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier +Normalizado, 14 segundos captura, 15 epocas + 4 layers, input size 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho da memória ocupada :1106.60 MB\n",
      "X_train shape: (27189, 4000) float64\n",
      "X_Test shape: (9063, 4000) float64\n",
      "y_train shape: (27189,) float64\n",
      "y_test shape: (9063,) float64\n",
      "\n",
      "--------\n",
      "X_train device: cpu\n",
      "X_Test device: cpu\n",
      "y_train device: cpu\n",
      "y_test device: cpu\n",
      "Valor 0: 12084 ocorrência(s)- 0.33%\n",
      "Valor 1: 12084 ocorrência(s)- 0.33%\n",
      "Valor 2: 12084 ocorrência(s)- 0.33%\n",
      "Dataset :  (36252, 4001)\n",
      "CPU times: total: 1min 23s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_F30sec = DATA_1M(seconds=14.5,columns=4000, jump_time =2, n_jumps=3) ; data_f30sec = data_F30sec(Fourier=True, Normalizing= True)\n",
    "Torch_F30sec = NeuralNetCNN(columns= data_f30sec.shape[1] -1)\n",
    "data_F30sec.Spliting(data= data_f30sec, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([128, 4000]) y torch.Size([128])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x0000023D0C20C3D0>, <torch.utils.data.dataloader.DataLoader object at 0x0000023D4200F510>)\n",
      "Length of train dataloader: 213 batches of 128\n",
      "Length of test dataloader: 71 batches of 128\n"
     ]
    }
   ],
   "source": [
    "train_dataloader , test_dataloader = data_F30sec.DataLoaders(batch_size=128, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.06306 | Train accuracy: 42.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:14<03:21, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 37.31184 | Test accuracy: 49.07%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 0.96587 | Train accuracy: 56.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:29<03:10, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 36.57344 | Test accuracy: 53.37%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 0.86202 | Train accuracy: 68.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:45<03:03, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 32.44151 | Test accuracy: 65.13%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.82279 | Train accuracy: 72.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [01:00<02:48, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 34.82434 | Test accuracy: 53.18%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.82268 | Train accuracy: 72.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:16<02:34, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 33.13865 | Test accuracy: 62.36%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.80635 | Train accuracy: 74.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:31<02:19, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 31.43780 | Test accuracy: 67.68%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.77896 | Train accuracy: 77.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [01:48<02:05, 15.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 30.92520 | Test accuracy: 69.02%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.77565 | Train accuracy: 77.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [02:04<01:50, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 37.29613 | Test accuracy: 50.91%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.77326 | Train accuracy: 77.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [02:20<01:35, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 31.18165 | Test accuracy: 68.14%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.74627 | Train accuracy: 80.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [02:36<01:19, 15.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 30.56076 | Test accuracy: 70.03%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.73931 | Train accuracy: 81.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [02:51<01:03, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 35.45329 | Test accuracy: 53.35%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.74063 | Train accuracy: 80.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [03:07<00:47, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 37.27383 | Test accuracy: 50.80%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.72851 | Train accuracy: 82.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [03:24<00:32, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 43.82653 | Test accuracy: 33.41%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.72980 | Train accuracy: 82.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [03:40<00:15, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 43.65958 | Test accuracy: 33.61%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.73426 | Train accuracy: 81.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:55<00:00, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 31.35397 | Test accuracy: 67.64%\n",
      "CPU times: total: 23min 31s\n",
      "Wall time: 3min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch_F30sec.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch_F30sec.Cnn, \n",
    "        loss_fn=Torch_F30sec.loss_fn,\n",
    "        optimizer=Torch_F30sec.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch_F30sec.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.07</td>\n",
       "      <td>37.31</td>\n",
       "      <td>42.99</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.37</td>\n",
       "      <td>36.57</td>\n",
       "      <td>56.84</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.13</td>\n",
       "      <td>32.44</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.18</td>\n",
       "      <td>34.82</td>\n",
       "      <td>72.38</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.36</td>\n",
       "      <td>33.14</td>\n",
       "      <td>72.54</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67.68</td>\n",
       "      <td>31.44</td>\n",
       "      <td>74.15</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69.02</td>\n",
       "      <td>30.93</td>\n",
       "      <td>77.05</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.91</td>\n",
       "      <td>37.30</td>\n",
       "      <td>77.33</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68.14</td>\n",
       "      <td>31.18</td>\n",
       "      <td>77.61</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70.03</td>\n",
       "      <td>30.56</td>\n",
       "      <td>80.33</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.35</td>\n",
       "      <td>35.45</td>\n",
       "      <td>81.06</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50.80</td>\n",
       "      <td>37.27</td>\n",
       "      <td>80.88</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33.41</td>\n",
       "      <td>43.83</td>\n",
       "      <td>82.16</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33.61</td>\n",
       "      <td>43.66</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>67.64</td>\n",
       "      <td>31.35</td>\n",
       "      <td>81.60</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
       "0           49.07       37.31           42.99        1.06\n",
       "1           53.37       36.57           56.84        0.97\n",
       "2           65.13       32.44           68.00        0.86\n",
       "3           53.18       34.82           72.38        0.82\n",
       "4           62.36       33.14           72.54        0.82\n",
       "5           67.68       31.44           74.15        0.81\n",
       "6           69.02       30.93           77.05        0.78\n",
       "7           50.91       37.30           77.33        0.78\n",
       "8           68.14       31.18           77.61        0.77\n",
       "9           70.03       30.56           80.33        0.75\n",
       "10          53.35       35.45           81.06        0.74\n",
       "11          50.80       37.27           80.88        0.74\n",
       "12          33.41       43.83           82.16        0.73\n",
       "13          33.61       43.66           82.05        0.73\n",
       "14          67.64       31.35           81.60        0.73"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch_F30sec(test= True, train= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.82      0.55      0.66      3047\n",
      "        WIFI       0.61      0.73      0.66      3028\n",
      "         LTE       0.66      0.75      0.70      2988\n",
      "\n",
      "    accuracy                           0.68      9063\n",
      "   macro avg       0.70      0.68      0.68      9063\n",
      "weighted avg       0.70      0.68      0.68      9063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data_F30sec.y_test, Torch_F30sec.Making_Predictions(model = Torch_F30sec.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourier - Normalizado, input size 4000, 32 segundos de captura, 15 epocas, 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho da memória ocupada :2480.23 MB\n",
      "X_train shape: (60939, 4000) float64\n",
      "X_Test shape: (20313, 4000) float64\n",
      "y_train shape: (60939,) float64\n",
      "y_test shape: (20313,) float64\n",
      "\n",
      "--------\n",
      "X_train device: cpu\n",
      "X_Test device: cpu\n",
      "y_train device: cpu\n",
      "y_test device: cpu\n",
      "Valor 0: 27084 ocorrência(s)- 0.33%\n",
      "Valor 1: 27084 ocorrência(s)- 0.33%\n",
      "Valor 2: 27084 ocorrência(s)- 0.33%\n",
      "Dataset :  (81252, 4001)\n",
      "X torch.Size([128, 4000]) y torch.Size([128])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x0000023D427EAA90>, <torch.utils.data.dataloader.DataLoader object at 0x0000023D427EA250>)\n",
      "Length of train dataloader: 477 batches of 128\n",
      "Length of test dataloader: 159 batches of 128\n",
      "CPU times: total: 3min 16s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_F30sec = DATA_1M(seconds=32.5,columns=4000, jump_time =2, n_jumps=3) ; data_f30sec = data_F30sec(Fourier=True, Normalizing= True)\n",
    "Torch_F30sec = NeuralNetCNN(columns= data_f30sec.shape[1] -1)\n",
    "data_F30sec.Spliting(data= data_f30sec, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "train_dataloader , test_dataloader = data_F30sec.DataLoaders(batch_size=128, inplace=True)\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.06903 | Train accuracy: 42.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:35<08:15, 35.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 84.75698 | Test accuracy: 45.13%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 0.98346 | Train accuracy: 54.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:11<07:43, 35.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 82.37996 | Test accuracy: 48.93%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 0.90471 | Train accuracy: 63.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [01:46<07:08, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 85.97085 | Test accuracy: 44.66%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.86342 | Train accuracy: 68.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:22<06:33, 35.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 80.13800 | Test accuracy: 50.05%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.82502 | Train accuracy: 72.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:59<06:00, 36.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 72.37338 | Test accuracy: 63.97%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.80993 | Train accuracy: 73.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [03:35<05:23, 35.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 72.04355 | Test accuracy: 64.56%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.82163 | Train accuracy: 72.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [04:11<04:48, 36.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 83.78484 | Test accuracy: 49.15%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.81445 | Train accuracy: 73.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [04:48<04:15, 36.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 71.65690 | Test accuracy: 65.09%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.79908 | Train accuracy: 74.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [05:25<03:38, 36.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 95.16257 | Test accuracy: 35.14%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.79707 | Train accuracy: 75.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [06:01<03:02, 36.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 83.63120 | Test accuracy: 49.43%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.78384 | Train accuracy: 76.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [06:39<02:27, 36.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 69.54355 | Test accuracy: 67.71%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.77297 | Train accuracy: 77.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [07:17<01:51, 37.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 76.72891 | Test accuracy: 60.44%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.76704 | Train accuracy: 78.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [07:54<01:14, 37.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 81.73132 | Test accuracy: 50.13%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.76525 | Train accuracy: 78.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [08:31<00:37, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 109.07781 | Test accuracy: 18.95%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.76151 | Train accuracy: 78.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [09:10<00:00, 36.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 83.26748 | Test accuracy: 48.79%\n",
      "CPU times: total: 54min 51s\n",
      "Wall time: 9min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch_F30sec.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch_F30sec.Cnn, \n",
    "        loss_fn=Torch_F30sec.loss_fn,\n",
    "        optimizer=Torch_F30sec.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch_F30sec.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.13</td>\n",
       "      <td>84.76</td>\n",
       "      <td>42.45</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.93</td>\n",
       "      <td>82.38</td>\n",
       "      <td>54.88</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.66</td>\n",
       "      <td>85.97</td>\n",
       "      <td>63.65</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.05</td>\n",
       "      <td>80.14</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.97</td>\n",
       "      <td>72.37</td>\n",
       "      <td>72.17</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.56</td>\n",
       "      <td>72.04</td>\n",
       "      <td>73.76</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.15</td>\n",
       "      <td>83.78</td>\n",
       "      <td>72.60</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65.09</td>\n",
       "      <td>71.66</td>\n",
       "      <td>73.31</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35.14</td>\n",
       "      <td>95.16</td>\n",
       "      <td>74.94</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49.43</td>\n",
       "      <td>83.63</td>\n",
       "      <td>75.13</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67.71</td>\n",
       "      <td>69.54</td>\n",
       "      <td>76.51</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.44</td>\n",
       "      <td>76.73</td>\n",
       "      <td>77.66</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.13</td>\n",
       "      <td>81.73</td>\n",
       "      <td>78.27</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.95</td>\n",
       "      <td>109.08</td>\n",
       "      <td>78.45</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48.79</td>\n",
       "      <td>83.27</td>\n",
       "      <td>78.82</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
       "0           45.13       84.76           42.45        1.07\n",
       "1           48.93       82.38           54.88        0.98\n",
       "2           44.66       85.97           63.65        0.90\n",
       "3           50.05       80.14           68.00        0.86\n",
       "4           63.97       72.37           72.17        0.83\n",
       "5           64.56       72.04           73.76        0.81\n",
       "6           49.15       83.78           72.60        0.82\n",
       "7           65.09       71.66           73.31        0.81\n",
       "8           35.14       95.16           74.94        0.80\n",
       "9           49.43       83.63           75.13        0.80\n",
       "10          67.71       69.54           76.51        0.78\n",
       "11          60.44       76.73           77.66        0.77\n",
       "12          50.13       81.73           78.27        0.77\n",
       "13          18.95      109.08           78.45        0.77\n",
       "14          48.79       83.27           78.82        0.76"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch_F30sec(test= True, train= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.86      0.02      0.03      6851\n",
      "        WIFI       0.46      0.67      0.55      6777\n",
      "         LTE       0.51      0.79      0.62      6685\n",
      "\n",
      "    accuracy                           0.49     20313\n",
      "   macro avg       0.61      0.49      0.40     20313\n",
      "weighted avg       0.61      0.49      0.40     20313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data_F30sec.y_test, Torch_F30sec.Making_Predictions(model = Torch_F30sec.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem Fourier = Normalizado, 4 layers, 4000 input size , 32 seg de captura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho da memória ocupada :2480.23 MB\n",
      "X_train shape: (60939, 4000) float64\n",
      "X_Test shape: (20313, 4000) float64\n",
      "y_train shape: (60939,) float64\n",
      "y_test shape: (20313,) float64\n",
      "\n",
      "--------\n",
      "X_train device: cpu\n",
      "X_Test device: cpu\n",
      "y_train device: cpu\n",
      "y_test device: cpu\n",
      "Valor 0: 27084 ocorrência(s)- 0.33%\n",
      "Valor 1: 27084 ocorrência(s)- 0.33%\n",
      "Valor 2: 27084 ocorrência(s)- 0.33%\n",
      "Dataset :  (81252, 4001)\n",
      "X torch.Size([128, 4000]) y torch.Size([128])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x0000022EC447D510>, <torch.utils.data.dataloader.DataLoader object at 0x0000022EC402A150>)\n",
      "Length of train dataloader: 477 batches of 128\n",
      "Length of test dataloader: 159 batches of 128\n",
      "CPU times: total: 3min 2s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_F30sec = DATA_1M(seconds=32.5,columns=4000, jump_time =2, n_jumps=3) ; data_f30sec = data_F30sec(Fourier=False, Normalizing= True)\n",
    "Torch_F30sec = NeuralNetCNN(columns= data_f30sec.shape[1] -1)\n",
    "data_F30sec.Spliting(data= data_f30sec, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "train_dataloader , test_dataloader = data_F30sec.DataLoaders(batch_size=128, inplace=True)\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 0.90291 | Train accuracy: 61.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:36<08:34, 36.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 61.95080 | Test accuracy: 77.09%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 0.73611 | Train accuracy: 81.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:12<07:52, 36.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 59.50870 | Test accuracy: 80.14%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 0.69773 | Train accuracy: 84.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [01:51<07:27, 37.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 57.69745 | Test accuracy: 82.56%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.69406 | Train accuracy: 85.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:28<06:48, 37.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 58.70732 | Test accuracy: 81.53%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.68856 | Train accuracy: 86.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [03:05<06:11, 37.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 57.13972 | Test accuracy: 83.56%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.67736 | Train accuracy: 87.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [03:42<05:35, 37.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 55.94057 | Test accuracy: 84.88%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.67036 | Train accuracy: 88.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [04:21<05:01, 37.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 56.24995 | Test accuracy: 84.53%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.68692 | Train accuracy: 86.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [05:00<04:26, 38.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 55.43918 | Test accuracy: 85.76%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.66182 | Train accuracy: 88.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [05:38<03:49, 38.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 55.24490 | Test accuracy: 85.99%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.65220 | Train accuracy: 89.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [06:16<03:09, 37.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 55.41796 | Test accuracy: 85.94%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.66622 | Train accuracy: 88.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [06:53<02:31, 37.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 55.11682 | Test accuracy: 86.11%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.64905 | Train accuracy: 90.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [07:31<01:53, 37.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 55.50930 | Test accuracy: 85.94%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.66420 | Train accuracy: 88.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [08:08<01:15, 37.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 54.87770 | Test accuracy: 86.41%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.64939 | Train accuracy: 90.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [08:45<00:37, 37.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 55.73132 | Test accuracy: 85.46%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.67231 | Train accuracy: 87.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [09:21<00:00, 37.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 57.31994 | Test accuracy: 83.38%\n",
      "CPU times: total: 55min 55s\n",
      "Wall time: 9min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch_F30sec.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch_F30sec.Cnn, \n",
    "        loss_fn=Torch_F30sec.loss_fn,\n",
    "        optimizer=Torch_F30sec.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch_F30sec.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.09</td>\n",
       "      <td>61.95</td>\n",
       "      <td>61.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.14</td>\n",
       "      <td>59.51</td>\n",
       "      <td>81.14</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.56</td>\n",
       "      <td>57.70</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.53</td>\n",
       "      <td>58.71</td>\n",
       "      <td>85.49</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.56</td>\n",
       "      <td>57.14</td>\n",
       "      <td>86.12</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.88</td>\n",
       "      <td>55.94</td>\n",
       "      <td>87.22</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84.53</td>\n",
       "      <td>56.25</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>85.76</td>\n",
       "      <td>55.44</td>\n",
       "      <td>86.30</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85.99</td>\n",
       "      <td>55.24</td>\n",
       "      <td>88.86</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85.94</td>\n",
       "      <td>55.42</td>\n",
       "      <td>89.82</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.11</td>\n",
       "      <td>55.12</td>\n",
       "      <td>88.38</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>85.94</td>\n",
       "      <td>55.51</td>\n",
       "      <td>90.18</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>86.41</td>\n",
       "      <td>54.88</td>\n",
       "      <td>88.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>85.46</td>\n",
       "      <td>55.73</td>\n",
       "      <td>90.15</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>83.38</td>\n",
       "      <td>57.32</td>\n",
       "      <td>87.84</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
       "0           77.09       61.95           61.90        0.90\n",
       "1           80.14       59.51           81.14        0.74\n",
       "2           82.56       57.70           84.99        0.70\n",
       "3           81.53       58.71           85.49        0.69\n",
       "4           83.56       57.14           86.12        0.69\n",
       "5           84.88       55.94           87.22        0.68\n",
       "6           84.53       56.25           88.00        0.67\n",
       "7           85.76       55.44           86.30        0.69\n",
       "8           85.99       55.24           88.86        0.66\n",
       "9           85.94       55.42           89.82        0.65\n",
       "10          86.11       55.12           88.38        0.67\n",
       "11          85.94       55.51           90.18        0.65\n",
       "12          86.41       54.88           88.61        0.66\n",
       "13          85.46       55.73           90.15        0.65\n",
       "14          83.38       57.32           87.84        0.67"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch_F30sec(test= True, train= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.77      0.82      0.80      6851\n",
      "        WIFI       0.79      0.80      0.79      6777\n",
      "         LTE       0.96      0.88      0.92      6685\n",
      "\n",
      "    accuracy                           0.83     20313\n",
      "   macro avg       0.84      0.83      0.84     20313\n",
      "weighted avg       0.84      0.83      0.84     20313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data_F30sec.y_test, Torch_F30sec.Making_Predictions(model = Torch_F30sec.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sem Fourier - Normalizado 4 lyers, 4000 input size, 14 segundos de captura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_F30sec = DATA_1M(seconds=14,columns=4000, jump_time =2, n_jumps=3) ; data_f30sec = data_F30sec(Fourier=False, Normalizing= True)\n",
    "Torch_F30sec = NeuralNetCNN(columns= data_f30sec.shape[1] -1)\n",
    "data_F30sec.Spliting(data= data_f30sec, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "train_dataloader , test_dataloader = data_F30sec.DataLoaders(batch_size=64, inplace=True)\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Torch_F30sec(test= True, train= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data_F30sec.y_test, Torch_F30sec.Making_Predictions(model = Torch_F30sec.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(log_lrs, losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Rate Finder')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m math\u001b[39m.\u001b[39;49mlog10(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "math.log10(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "lrs = []\n",
    "for lr in log_lrs:\n",
    "    if lr > 0:\n",
    "        lrs.append(math.log10(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.8646131412461038,\n",
       " -1.4578309752178644,\n",
       " -1.2515282985032574,\n",
       " -1.1122370815163471,\n",
       " -1.0069378716703796,\n",
       " -0.9222525255350779,\n",
       " -0.8514165108066893,\n",
       " -0.7905303323532206,\n",
       " -0.7371400004962164,\n",
       " -0.6896005277313332,\n",
       " -0.6467552761037594,\n",
       " -0.6077599433883797,\n",
       " -0.5719793351003387,\n",
       " -0.5389235470786153,\n",
       " -0.5082067770951068,\n",
       " -0.47951977105591026,\n",
       " -0.45261082234828914,\n",
       " -0.42727232368398355,\n",
       " -0.40333103138665416,\n",
       " -0.3806408763955414,\n",
       " -0.35907756215467795,\n",
       " -0.33853444155916473,\n",
       " -0.3189193259200089,\n",
       " -0.3001519840256547,\n",
       " -0.2821621596113391,\n",
       " -0.2648879834030811,\n",
       " -0.2482746890961745,\n",
       " -0.2322735660266937,\n",
       " -0.2168410980347567,\n",
       " -0.20193825015868344,\n",
       " -0.18752987371457505,\n",
       " -0.17358420693911436,\n",
       " -0.16007245334690962,\n",
       " -0.14696842372584784,\n",
       " -0.13424823058160978,\n",
       " -0.12189002607240623,\n",
       " -0.10987377621103034,\n",
       " -0.09818106547322424,\n",
       " -0.08679492702747293,\n",
       " -0.07569969465739948,\n",
       " -0.0648808731333184,\n",
       " -0.054325024341554125,\n",
       " -0.04401966692734127,\n",
       " -0.033953187571375554,\n",
       " -0.024114762318294226,\n",
       " -0.014494286620709926,\n",
       " -0.005082312965216266,\n",
       " 0.004130004884849438,\n",
       " 0.013150961854719454,\n",
       " 0.02198834643889528,\n",
       " 0.030649481105778698,\n",
       " 0.039141258751467664,\n",
       " 0.04747017565742075,\n",
       " 0.05564236134678983,\n",
       " 0.06366360568316472,\n",
       " 0.07153938351183145,\n",
       " 0.07927487710621771,\n",
       " 0.08687499665001894,\n",
       " 0.0943443989577415,\n",
       " 0.1016875046124007,\n",
       " 0.10890851367830452,\n",
       " 0.11601142012876986,\n",
       " 0.1230000251128639,\n",
       " 0.12987794917150228,\n",
       " 0.1366486435011955,\n",
       " 0.1433154003531696,\n",
       " 0.149881362646304,\n",
       " 0.1563495328641472,\n",
       " 0.1627227812990554,\n",
       " 0.16900385370011387,\n",
       " 0.17519537837584698,\n",
       " 0.1812998727977025,\n",
       " 0.18731974974583376,\n",
       " 0.1932573230347295,\n",
       " 0.1991148128526946,\n",
       " 0.20489435074601767,\n",
       " 0.2105979842758264,\n",
       " 0.21622768137308998,\n",
       " 0.2217853344149479,\n",
       " 0.227272764043493,\n",
       " 0.2326917227462919,\n",
       " 0.2380438982162626,\n",
       " 0.24333091650702582,\n",
       " 0.24855434499849163,\n",
       " 0.2537156951862137,\n",
       " 0.2588164253069302,\n",
       " 0.26385794281170344,\n",
       " 0.2688416066971504,\n",
       " 0.273768729704426,\n",
       " 0.27864058039486006,\n",
       " 0.283458385110459,\n",
       " 0.2882233298268516,\n",
       " 0.2929365619056833,\n",
       " 0.2975991917529363,\n",
       " 0.30221229438917147,\n",
       " 0.30677691093724696,\n",
       " 0.3112940500326637,\n",
       " 0.31576468916131656,\n",
       " 0.32018977592909054,\n",
       " 0.32457022926742507,\n",
       " 0.32890694057868497,\n",
       " 0.3332007748249079,\n",
       " 0.3374525715632539,\n",
       " 0.34166314593125996,\n",
       " 0.3458332895847886,\n",
       " 0.3499637715913722,\n",
       " 0.35405533928147465,\n",
       " 0.3581087190600247,\n",
       " 0.3621246171804285,\n",
       " 0.3661037204831215,\n",
       " 0.3700466971005926,\n",
       " 0.37395419713069133,\n",
       " 0.3778268532799124,\n",
       " 0.38166528147825357,\n",
       " 0.38547008146713774,\n",
       " 0.38924183736180507,\n",
       " 0.392981118189493,\n",
       " 0.3966884784046446,\n",
       " 0.40036445838231244,\n",
       " 0.4040095848908547,\n",
       " 0.40762437154495995,\n",
       " 0.41120931923997206,\n",
       " 0.4147649165684366,\n",
       " 0.41829164021973336,\n",
       " 0.42178995536361225,\n",
       " 0.42526031601840647,\n",
       " 0.42870316540464853,\n",
       " 0.4321189362847811,\n",
       " 0.4355080512896123,\n",
       " 0.4388709232321304,\n",
       " 0.4422079554092634,\n",
       " 0.44551954189213205,\n",
       " 0.44880606780532073,\n",
       " 0.45206790959566084,\n",
       " 0.4553054352909946,\n",
       " 0.4585190047493659,\n",
       " 0.4617089698990586,\n",
       " 0.4648756749698835,\n",
       " 0.46801945671609413,\n",
       " 0.4711406446312914,\n",
       " 0.47423956115566207,\n",
       " 0.477316521875874,\n",
       " 0.4803718357179413,\n",
       " 0.4834058051333518,\n",
       " 0.48641872627873817,\n",
       " 0.48941088918936004,\n",
       " 0.4923825779466496,\n",
       " 0.49533407084006514,\n",
       " 0.49826564052348066,\n",
       " 0.5011775541663331,\n",
       " 0.5040700735997362,\n",
       " 0.5069434554577598,\n",
       " 0.5097979513140671,\n",
       " 0.5126338078140906,\n",
       " 0.5154512668029193,\n",
       " 0.5182505654490668,\n",
       " 0.5210319363642728,\n",
       " 0.523795607719496,\n",
       " 0.5265418033572371,\n",
       " 0.5292707429003339,\n",
       " 0.5319826418573599,\n",
       " 0.5346777117247508,\n",
       " 0.5373561600857844,\n",
       " 0.5400181907065242,\n",
       " 0.5426640036288425,\n",
       " 0.5452937952606255,\n",
       " 0.547907758463265,\n",
       " 0.5505060826365316,\n",
       " 0.553088953800925,\n",
       " 0.5556565546775897,\n",
       " 0.5582090647658813,\n",
       " 0.5607466604186683,\n",
       " 0.5632695149154452,\n",
       " 0.5657777985333353,\n",
       " 0.5682716786160539,\n",
       " 0.5707513196409035,\n",
       " 0.5732168832838671,\n",
       " 0.5756685284828635,\n",
       " 0.5781064114992283,\n",
       " 0.5805306859774779,\n",
       " 0.5829415030034155,\n",
       " 0.5853390111606328,\n",
       " 0.58772335658546,\n",
       " 0.5900946830204175,\n",
       " 0.592453131866214,\n",
       " 0.5947988422323418,\n",
       " 0.5971319509863127,\n",
       " 0.5994525928015781,\n",
       " 0.6017609002041759,\n",
       " 0.6040570036181444,\n",
       " 0.606341031409741,\n",
       " 0.6086131099305063,\n",
       " 0.6108733635592053,\n",
       " 0.6131219147426838,\n",
       " 0.6153588840356732,\n",
       " 0.617584390139574,\n",
       " 0.6197985499402521,\n",
       " 0.6220014785448756,\n",
       " 0.6241932893178219,\n",
       " 0.6263740939156841,\n",
       " 0.6285440023214021,\n",
       " 0.6307031228775453,\n",
       " 0.6328515623187732,\n",
       " 0.634989425803495,\n",
       " 0.6371168169447559,\n",
       " 0.6392338378403684,\n",
       " 0.6413405891023153,\n",
       " 0.6434371698854408,\n",
       " 0.6455236779154532,\n",
       " 0.6476002095162585,\n",
       " 0.6496668596366432,\n",
       " 0.651723721876325,\n",
       " 0.6537708885113902,\n",
       " 0.6558084505191338,\n",
       " 0.6578364976023199,\n",
       " 0.6598551182128779,\n",
       " 0.6618643995750514,\n",
       " 0.6638644277080129,\n",
       " 0.6658552874479611,\n",
       " 0.6678370624697134,\n",
       " 0.6698098353078087,\n",
       " 0.6717736873771317,\n",
       " 0.6737286989930751,\n",
       " 0.675674949391248,\n",
       " 0.6776125167467455,\n",
       " 0.6795414781929906,\n",
       " 0.6814619098401593,\n",
       " 0.6833738867931998,\n",
       " 0.685277483169457,\n",
       " 0.6871727721159129,\n",
       " 0.6890598258260514,\n",
       " 0.6909387155563594,\n",
       " 0.6928095116424721,\n",
       " 0.694672283514971,\n",
       " 0.6965270997148465,\n",
       " 0.6983740279086302,\n",
       " 0.7002131349032075,\n",
       " 0.7020444866603172,\n",
       " 0.7038681483107476,\n",
       " 0.7056841841682354,\n",
       " 0.7074926577430747,\n",
       " 0.709293631755444,\n",
       " 0.7110871681484596,\n",
       " 0.7128733281009576,\n",
       " 0.7146521720400167,\n",
       " 0.7164237596532246,\n",
       " 0.7181881499006947,\n",
       " 0.719945401026841,\n",
       " 0.7216955705719146,\n",
       " 0.7234387153833087,\n",
       " 0.7251748916266388,\n",
       " 0.726904154796601,\n",
       " 0.7286265597276155,\n",
       " 0.7303421606042598,\n",
       " 0.7320510109714972,\n",
       " 0.7337531637447033,\n",
       " 0.7354486712194991,\n",
       " 0.7371375850813908,\n",
       " 0.7388199564152238,\n",
       " 0.7404958357144542,\n",
       " 0.7421652728902425,\n",
       " 0.7438283172803721,\n",
       " 0.7454850176579992,\n",
       " 0.7471354222402349,\n",
       " 0.7487795786965656,\n",
       " 0.7504175341571155,\n",
       " 0.7520493352207515,\n",
       " 0.7536750279630391,\n",
       " 0.7552946579440482,\n",
       " 0.756908270216014,\n",
       " 0.7585159093308574,\n",
       " 0.7601176193475652,\n",
       " 0.7617134438394352,\n",
       " 0.7633034259011892,\n",
       " 0.7648876081559557,\n",
       " 0.7664660327621258,\n",
       " 0.7680387414200853,\n",
       " 0.7696057753788248,\n",
       " 0.7711671754424312,\n",
       " 0.7727229819764633,\n",
       " 0.774273234914213,\n",
       " 0.7758179737628556,\n",
       " 0.7773572376094909,\n",
       " 0.7788910651270777,\n",
       " 0.7804194945802636,\n",
       " 0.7819425638311133,\n",
       " 0.7834603103447355,\n",
       " 0.7849727711948138,\n",
       " 0.7864799830690393,\n",
       " 0.787981982274451,\n",
       " 0.7894788047426837,\n",
       " 0.7909704860351251,\n",
       " 0.792457061347986,\n",
       " 0.7939385655172823,\n",
       " 0.795415033023734,\n",
       " 0.7968864979975798,\n",
       " 0.7983529942233119,\n",
       " 0.7998145551443292,\n",
       " 0.8012712138675144,\n",
       " 0.8027230031677334,\n",
       " 0.8041699554922598,\n",
       " 0.8056121029651266,\n",
       " 0.8070494773914059,\n",
       " 0.8084821102614164,\n",
       " 0.8099100327548642,\n",
       " 0.8113332757449135,\n",
       " 0.8127518698021928,\n",
       " 0.814165845198734,\n",
       " 0.815575231911849,\n",
       " 0.8169800596279427,\n",
       " 0.8183803577462655,\n",
       " 0.8197761553826042,\n",
       " 0.821167481372915,\n",
       " 0.8225543642768977,\n",
       " 0.8239368323815134,\n",
       " 0.8253149137044462,\n",
       " 0.8266886359975104,\n",
       " 0.8280580267500036,\n",
       " 0.8294231131920073,\n",
       " 0.8307839222976362,\n",
       " 0.8321404807882357,\n",
       " 0.8334928151355306,\n",
       " 0.8348409515647249,\n",
       " 0.836184916057553,\n",
       " 0.8375247343552839,\n",
       " 0.8388604319616801,\n",
       " 0.84019203414591,\n",
       " 0.8415195659454168,\n",
       " 0.8428430521687424,\n",
       " 0.8441625173983102,\n",
       " 0.8454779859931636,\n",
       " 0.8467894820916654,\n",
       " 0.8480970296141546,\n",
       " 0.8494006522655647,\n",
       " 0.8507003735380022,\n",
       " 0.8519962167132863,\n",
       " 0.853288204865452,\n",
       " 0.8545763608632145,\n",
       " 0.855860707372399,\n",
       " 0.8571412668583327,\n",
       " 0.858418061588203,\n",
       " 0.8596911136333807,\n",
       " 0.8609604448717098,\n",
       " 0.8622260769897623,\n",
       " 0.8634880314850625,\n",
       " 0.8647463296682774,\n",
       " 0.8660009926653758,\n",
       " 0.8672520414197574,\n",
       " 0.8684994966943492,\n",
       " 0.869743379073674,\n",
       " 0.8709837089658883,\n",
       " 0.872220506604791,\n",
       " 0.8734537920518044,\n",
       " 0.8746835851979264,\n",
       " 0.8759099057656554,\n",
       " 0.8771327733108883,\n",
       " 0.8783522072247917,\n",
       " 0.8795682267356463,\n",
       " 0.8807808509106672,\n",
       " 0.8819900986577965,\n",
       " 0.8831959887274736,\n",
       " 0.8843985397143787,\n",
       " 0.8855977700591535,\n",
       " 0.8867936980500983,\n",
       " 0.8879863418248449,\n",
       " 0.8891757193720072,\n",
       " 0.8903618485328094,\n",
       " 0.891544747002692,\n",
       " 0.8927244323328951,\n",
       " 0.8939009219320215,\n",
       " 0.8950742330675777,\n",
       " 0.8962443828674953,\n",
       " 0.8974113883216303,\n",
       " 0.8985752662832438,\n",
       " 0.8997360334704624,\n",
       " 0.9008937064677186,\n",
       " 0.9020483017271732,\n",
       " 0.9031998355701177,\n",
       " 0.9043483241883585,\n",
       " 0.9054937836455836,\n",
       " 0.9066362298787102,\n",
       " 0.9077756786992153,\n",
       " 0.9089121457944485,\n",
       " 0.9100456467289283,\n",
       " 0.9111761969456209,\n",
       " 0.9123038117672024,\n",
       " 0.9134285063973053,\n",
       " 0.9145502959217481,\n",
       " 0.9156691953097493,\n",
       " 0.9167852194151269,\n",
       " 0.9178983829774802,\n",
       " 0.9190087006233586,\n",
       " 0.9201161868674148,\n",
       " 0.9212208561135432,\n",
       " 0.9223227226560037,\n",
       " 0.9234218006805317,\n",
       " 0.9245181042654339,\n",
       " 0.9256116473826704,\n",
       " 0.926702443898923,\n",
       " 0.9277905075766503,\n",
       " 0.9288758520751295,\n",
       " 0.9299584909514851,\n",
       " 0.9310384376617057,\n",
       " 0.9321157055616465,\n",
       " 0.9331903079080209,\n",
       " 0.9342622578593797,\n",
       " 0.9353315684770768,\n",
       " 0.936398252726225,\n",
       " 0.9374623234766394,\n",
       " 0.938523793503768,\n",
       " 0.939582675489613,\n",
       " 0.9406389820236396,\n",
       " 0.941692725603674,\n",
       " 0.9427439186367909,\n",
       " 0.9437925734401896,\n",
       " 0.9448387022420607,\n",
       " 0.9458823171824406,\n",
       " 0.946923430314058,\n",
       " 0.9479620536031682,\n",
       " 0.9489981989303785,\n",
       " 0.9500318780914643,\n",
       " 0.9510631027981735,\n",
       " 0.9520918846790243,\n",
       " 0.9531182352800904,\n",
       " 0.9541421660657801,\n",
       " 0.955163688419603,\n",
       " 0.9561828136449307,\n",
       " 0.9571995529657465,\n",
       " 0.9582139175273879,\n",
       " 0.9592259183972782,\n",
       " 0.9602355665656527,\n",
       " 0.9612428729462734,\n",
       " 0.9622478483771382,\n",
       " 0.9632505036211791,\n",
       " 0.9642508493669555,\n",
       " 0.9652488962293362,\n",
       " 0.9662446547501763,\n",
       " 0.9672381353989848,\n",
       " 0.9682293485735858,\n",
       " 0.9692183046007703,\n",
       " 0.9702050137369427,\n",
       " 0.9711894861687586,\n",
       " 0.9721717320137557,\n",
       " 0.9731517613209785,\n",
       " 0.9741295840715937,\n",
       " 0.9751052101795017,\n",
       " 0.9760786494919383,\n",
       " 0.9770499117900725,\n",
       " 0.9780190067895947,\n",
       " 0.9789859441413011,\n",
       " 0.9799507334316694,\n",
       " 0.9809133841834298,\n",
       " 0.9818739058561283,\n",
       " 0.9828323078466853,\n",
       " 0.9837885994899462,\n",
       " 0.9847427900592276,\n",
       " 0.9856948887668566,\n",
       " 0.9866449047647048,\n",
       " 0.9875928471447156,\n",
       " 0.9885387249394265,\n",
       " 0.9894825471224858,\n",
       " 0.9904243226091631,\n",
       " 0.9913640602568545,\n",
       " 0.9923017688655827,\n",
       " 0.9932374571784914,\n",
       " 0.9941711338823342,\n",
       " 0.9951028076079589,\n",
       " 0.9960324869307857,\n",
       " 0.9969601803712812,\n",
       " 0.9978858963954268,\n",
       " 0.9988096434151821,\n",
       " 0.9997314297889439,\n",
       " 1.0006512638219995,\n",
       " 1.0015691537669766,\n",
       " 1.002485107824286,\n",
       " 1.003399134142563,\n",
       " 1.0043112408191008,\n",
       " 1.005221435900282,\n",
       " 1.006129727382004,\n",
       " 1.0070361232101004,\n",
       " 1.0079406312807582,\n",
       " 1.008843259440931,\n",
       " 1.0097440154887465,\n",
       " 1.0106429071739114,\n",
       " 1.0115399421981113,\n",
       " 1.012435128215407,\n",
       " 1.0133284728326253,\n",
       " 1.014219983609748,\n",
       " 1.0151096680602953,\n",
       " 1.015997533651706,\n",
       " 1.0168835878057123,\n",
       " 1.017767837898714,\n",
       " 1.0186502912621458,\n",
       " 1.0195309551828422,\n",
       " 1.0204098369033983,\n",
       " 1.0212869436225276,\n",
       " 1.022162282495416,\n",
       " 1.023035860634071,\n",
       " 1.0239076851076694,\n",
       " 1.0247777629429005,\n",
       " 1.0256461011243048,\n",
       " 1.0265127065946118,\n",
       " 1.0273775862550723,\n",
       " 1.0282407469657886,\n",
       " 1.0291021955460402,\n",
       " 1.0299619387746082,\n",
       " 1.030819983390094,\n",
       " 1.0316763360912375,\n",
       " 1.0325310035372302,\n",
       " 1.033383992348026,\n",
       " 1.0342353091046483,\n",
       " 1.0350849603494965,\n",
       " 1.0359329525866452,\n",
       " 1.0367792922821448,\n",
       " 1.0376239858643164,\n",
       " 1.038467039724045,\n",
       " 1.03930846021507,\n",
       " 1.0401482536542717,\n",
       " 1.0409864263219568,\n",
       " 1.0418229844621392,\n",
       " 1.04265793428282,\n",
       " 1.0434912819562634,\n",
       " 1.0443230336192706,\n",
       " 1.0451531953734507,\n",
       " 1.0459817732854901,\n",
       " 1.0468087733874174,\n",
       " 1.0476342016768676,\n",
       " 1.0484580641173429,\n",
       " 1.0492803666384711,\n",
       " 1.0501011151362618,\n",
       " 1.0509203154733602,\n",
       " 1.051737973479298,\n",
       " 1.0525540949507426,\n",
       " 1.0533686856517432,\n",
       " 1.054181751313976,\n",
       " 1.0549932976369853,\n",
       " 1.0558033302884235,\n",
       " 1.0566118549042889,\n",
       " 1.0574188770891602,\n",
       " 1.0582244024164305,\n",
       " 1.0590284364285378,\n",
       " 1.0598309846371938,\n",
       " 1.0606320525236108,\n",
       " 1.061431645538726,\n",
       " 1.0622297691034241,\n",
       " 1.0630264286087587,\n",
       " 1.0638216294161693,\n",
       " 1.0646153768576985,\n",
       " 1.065407676236207,\n",
       " 1.0661985328255854,\n",
       " 1.0669879518709653,\n",
       " 1.067775938588928,\n",
       " 1.0685624981677109,\n",
       " 1.0693476357674128,\n",
       " 1.0701313565201973,\n",
       " 1.0709136655304934,\n",
       " 1.0716945678751957,\n",
       " 1.0724740686038614,\n",
       " 1.0732521727389066,\n",
       " 1.0740288852758009,\n",
       " 1.0748042111832585,\n",
       " 1.0755781554034303,\n",
       " 1.0763507228520925,\n",
       " 1.0771219184188332,\n",
       " 1.0778917469672393,\n",
       " 1.0786602133350796,\n",
       " 1.0794273223344877,\n",
       " 1.0801930787521423,\n",
       " 1.0809574873494472,\n",
       " 1.0817205528627085,\n",
       " 1.08248228000331,\n",
       " 1.0832426734578893,\n",
       " 1.0840017378885092,\n",
       " 1.0847594779328302,\n",
       " 1.0855158982042805,\n",
       " 1.0862710032922238,\n",
       " 1.0870247977621272,\n",
       " 1.0877772861557264,\n",
       " 1.0885284729911897,\n",
       " 1.0892783627632812,\n",
       " 1.090026959943522,\n",
       " 1.0907742689803501,\n",
       " 1.0915202942992792,\n",
       " 1.0922650403030558,\n",
       " 1.0930085113718149,\n",
       " 1.093750711863235,\n",
       " 1.0944916461126915,\n",
       " 1.0952313184334075,\n",
       " 1.0959697331166056,\n",
       " 1.0967068944316574,\n",
       " 1.0974428066262305,\n",
       " 1.098177473926436,\n",
       " 1.0989109005369746,\n",
       " 1.0996430906412802,\n",
       " 1.100374048401663,\n",
       " 1.1011037779594526,\n",
       " 1.1018322834351373,\n",
       " 1.102559568928505,\n",
       " 1.1032856385187808,\n",
       " 1.1040104962647643,\n",
       " 1.1047341462049665,\n",
       " 1.1054565923577437,\n",
       " 1.1061778387214323,\n",
       " 1.1068978892744812,\n",
       " 1.1076167479755834,\n",
       " 1.1083344187638071,\n",
       " 1.1090509055587239,\n",
       " 1.1097662122605392,\n",
       " 1.1104803427502175,\n",
       " 1.1111933008896107,\n",
       " 1.111905090521582,\n",
       " 1.1126157154701304,\n",
       " 1.1133251795405148,\n",
       " 1.1140334865193753,\n",
       " 1.1147406401748552,\n",
       " 1.1154466442567201,\n",
       " 1.116151502496479,\n",
       " 1.1168552186075011,\n",
       " 1.117557796285134,\n",
       " 1.1182592392068196,\n",
       " 1.11895955103221,\n",
       " 1.1196587354032816,\n",
       " 1.12035679594445,\n",
       " 1.1210537362626807,\n",
       " 1.1217495599476026,\n",
       " 1.1224442705716184,\n",
       " 1.1231378716900142,\n",
       " 1.1238303668410696,\n",
       " 1.1245217595461647,\n",
       " 1.1252120533098893,\n",
       " 1.1259012516201476,\n",
       " 1.1265893579482653,\n",
       " 1.127276375749094,\n",
       " 1.1279623084611152,\n",
       " 1.128647159506544,\n",
       " 1.1293309322914307,\n",
       " 1.1300136302057633,\n",
       " 1.1306952566235677,\n",
       " 1.1313758149030089,\n",
       " 1.1320553083864884,\n",
       " 1.132733740400744,\n",
       " 1.1334111142569478,\n",
       " 1.134087433250802,\n",
       " 1.1347627006626357,\n",
       " 1.1354369197575007,\n",
       " 1.136110093785266,\n",
       " 1.136782225980711,\n",
       " 1.1374533195636205,\n",
       " 1.1381233777388753,\n",
       " 1.138792403696545,\n",
       " 1.1394604006119802,\n",
       " 1.1401273716459002,\n",
       " 1.140793319944485,\n",
       " 1.1414582486394644,\n",
       " 1.1421221608482044,\n",
       " 1.1427850596737967,\n",
       " 1.1434469482051455,\n",
       " 1.1441078295170526,\n",
       " 1.144767706670305,\n",
       " 1.1454265827117582,\n",
       " 1.146084460674422,\n",
       " 1.146741343577543,\n",
       " 1.147397234426689,\n",
       " 1.1480521362138305,\n",
       " 1.1487060519174233,\n",
       " 1.1493589845024892,\n",
       " 1.1500109369206968,\n",
       " 1.1506619121104422,\n",
       " 1.1513119129969276,\n",
       " 1.1519609424922406,\n",
       " 1.1526090034954324,\n",
       " 1.1532560988925955,\n",
       " 1.153902231556941,\n",
       " 1.1545474043488744,\n",
       " 1.155191620116073,\n",
       " 1.1558348816935597,\n",
       " 1.156477191903779,\n",
       " 1.157118553556671,\n",
       " 1.1577589694497448,\n",
       " 1.158398442368152,\n",
       " 1.1590369750847596,\n",
       " 1.1596745703602216,\n",
       " 1.1603112309430514,\n",
       " 1.160946959569692,\n",
       " 1.1615817589645872,\n",
       " 1.1622156318402512,\n",
       " 1.1628485808973388,\n",
       " 1.1634806088247134,\n",
       " 1.1641117182995169,\n",
       " 1.1647419119872362,\n",
       " 1.1653711925417725,\n",
       " 1.1659995626055062,\n",
       " 1.1666270248093658,\n",
       " 1.1672535817728924,\n",
       " 1.1678792361043056,\n",
       " 1.168503990400569,\n",
       " 1.1691278472474549,\n",
       " 1.1697508092196083,\n",
       " 1.17037287888061,\n",
       " 1.1709940587830416,\n",
       " 1.1716143514685466,\n",
       " 1.1722337594678938,\n",
       " 1.1728522853010388,\n",
       " 1.173469931477186,\n",
       " 1.1740867004948488,\n",
       " 1.1747025948419114,\n",
       " 1.1753176169956883,\n",
       " 1.1759317694229836,\n",
       " 1.1765450545801517,\n",
       " 1.1771574749131553,\n",
       " 1.1777690328576238,\n",
       " 1.1783797308389123,\n",
       " 1.1789895712721585,\n",
       " 1.1795985565623401,\n",
       " 1.1802066891043324,\n",
       " 1.1808139712829635,\n",
       " 1.1814204054730721,\n",
       " 1.1820259940395619,\n",
       " 1.182630739337457,\n",
       " 1.1832346437119583,\n",
       " 1.183837709498496,\n",
       " 1.1844399390227849,\n",
       " 1.1850413346008781,\n",
       " 1.1856418985392214,\n",
       " 1.1862416331347039,\n",
       " 1.1868405406747133,\n",
       " 1.1874386234371865,\n",
       " 1.188035883690663,\n",
       " 1.188632323694335,\n",
       " 1.1892279456980999,\n",
       " 1.1898227519426106,\n",
       " 1.1904167446593261,\n",
       " 1.1910099260705624,\n",
       " 1.1916022983895413,\n",
       " 1.1921938638204408,\n",
       " 1.1927846245584441,\n",
       " 1.1933745827897881,\n",
       " 1.1939637406918124,\n",
       " 1.1945521004330075,\n",
       " 1.1951396641730623,\n",
       " 1.1957264340629117,\n",
       " 1.1963124122447848,\n",
       " 1.1968976008522505,\n",
       " 1.1974820020102646,\n",
       " 1.1980656178352167,\n",
       " 1.1986484504349753,\n",
       " 1.1992305019089338,\n",
       " 1.1998117743480563,\n",
       " 1.2003922698349219,\n",
       " 1.20097199044377,\n",
       " 1.2015509382405447,\n",
       " 1.202129115282939,\n",
       " 1.2027065236204384,\n",
       " 1.2032831652943647,\n",
       " 1.2038590423379196,\n",
       " 1.2044341567762267,\n",
       " 1.2050085106263755,\n",
       " 1.2055821058974634,\n",
       " 1.206154944590637,\n",
       " 1.2067270286991356,\n",
       " 1.2072983602083314,\n",
       " 1.2078689410957715,\n",
       " 1.2084387733312187,\n",
       " 1.209007858876693,\n",
       " 1.209576199686511,\n",
       " 1.210143797707327,\n",
       " 1.2107106548781728,\n",
       " 1.2112767731304974,\n",
       " 1.211842154388206,\n",
       " 1.212406800567701,\n",
       " 1.212970713577918,\n",
       " 1.2135338953203674,\n",
       " 1.2140963476891715,\n",
       " 1.214658072571103,\n",
       " 1.215219071845622,\n",
       " 1.2157793473849157,\n",
       " 1.2163389010539343,\n",
       " 1.216897734710429,\n",
       " 1.2174558502049886,\n",
       " 1.2180132493810765,\n",
       " 1.2185699340750669,\n",
       " 1.2191259061162816,\n",
       " 1.219681167327026,\n",
       " 1.2202357195226246,\n",
       " 1.2207895645114566,\n",
       " 1.2213427040949918,\n",
       " 1.2218951400678253,\n",
       " 1.2224468742177121,\n",
       " 1.2229979083256033,\n",
       " 1.2235482441656786,\n",
       " 1.224097883505382,\n",
       " 1.224646828105455,\n",
       " 1.2251950797199715,\n",
       " 1.2257426400963705,\n",
       " 1.226289510975489,\n",
       " 1.2268356940915974,\n",
       " 1.2273811911724297,\n",
       " 1.227926003939219,\n",
       " 1.2284701341067277,\n",
       " 1.2290135833832814,\n",
       " 1.2295563534708005,\n",
       " 1.2300984460648328,\n",
       " 1.2306398628545838,\n",
       " 1.2311806055229504,\n",
       " 1.2317206757465504,\n",
       " 1.2322600751957549,\n",
       " 1.2327988055347183,\n",
       " 1.2333368684214103,\n",
       " 1.2338742655076453,\n",
       " 1.234410998439114,\n",
       " 1.2349470688554125,\n",
       " 1.2354824783900729,\n",
       " 1.2360172286705937,\n",
       " 1.2365513213184682,\n",
       " 1.2370847579492157,\n",
       " 1.2376175401724085,\n",
       " 1.2381496695917038,\n",
       " 1.2386811478048705,\n",
       " 1.2392119764038185,\n",
       " 1.2397421569746283,\n",
       " 1.2402716910975782,\n",
       " 1.240800580347173,\n",
       " 1.241328826292173,\n",
       " 1.2418564304956192,\n",
       " 1.242383394514865,\n",
       " 1.2429097199016002,\n",
       " 1.2434354082018808,\n",
       " 1.2439604609561552,\n",
       " 1.2444848796992907,\n",
       " 1.245008665960602,\n",
       " 1.2455318212638768,\n",
       " 1.2460543471274028,\n",
       " 1.246576245063994,\n",
       " 1.2470975165810168,\n",
       " 1.2476181631804169,\n",
       " 1.2481381863587442,\n",
       " 1.2486575876071793,\n",
       " 1.249176368411559,\n",
       " 1.2496945302524023,\n",
       " 1.2502120746049343,\n",
       " 1.2507290029391127,\n",
       " 1.251245316719653,\n",
       " 1.251761017406052,\n",
       " 1.2522761064526144,\n",
       " 1.2527905853084755,\n",
       " 1.2533044554176276,\n",
       " 1.2538177182189425,\n",
       " 1.254330375146197,\n",
       " 1.2548424276280963,\n",
       " 1.2553538770882977,\n",
       " 1.2558647249454353,\n",
       " 1.2563749726131428,\n",
       " 1.2568846215000766,\n",
       " 1.2573936730099404,\n",
       " 1.2579021285415075,\n",
       " 1.2584099894886436,\n",
       " 1.258917257240331,\n",
       " 1.25942393318069,\n",
       " 1.2599300186890021,\n",
       " 1.2604355151397326,\n",
       " 1.2609404239025535,\n",
       " 1.2614447463423644,\n",
       " 1.261948483819316,\n",
       " 1.2624516376888313,\n",
       " 1.2629542093016282,\n",
       " 1.2634562000037401,\n",
       " 1.2639576111365391,\n",
       " 1.2644584440367557,\n",
       " 1.264958700036502,\n",
       " 1.2654583804632913,\n",
       " 1.2659574866400607,\n",
       " 1.2664560198851913,\n",
       " 1.2669539815125286,\n",
       " 1.267451372831405,\n",
       " 1.2679481951466582,\n",
       " 1.268444449758654,\n",
       " 1.2689401379633047,\n",
       " 1.2694352610520911,\n",
       " 1.2699298203120815,\n",
       " 1.2704238170259519,\n",
       " 1.270917252472007,\n",
       " 1.2714101279241987,\n",
       " 1.2719024446521467,\n",
       " 1.272394203921158,\n",
       " 1.272885406992246,\n",
       " 1.2733760551221502,\n",
       " 1.2738661495633554,\n",
       " 1.2743556915641114,\n",
       " 1.2748446823684512,\n",
       " 1.2753331232162102,\n",
       " 1.275821015343046,\n",
       " 1.2763083599804557,\n",
       " 1.2767951583557955,\n",
       " 1.2772814116922993,\n",
       " 1.2777671212090964,\n",
       " 1.2782522881212304,\n",
       " 1.2787369136396776,\n",
       " 1.2792209989713645,\n",
       " 1.2797045453191864,\n",
       " 1.2801875538820253,\n",
       " 1.2806700258547674,\n",
       " 1.2811519624283205,\n",
       " 1.281633364789633,\n",
       " 1.28211423412171,\n",
       " 1.2825945716036318,\n",
       " 1.2830743784105703,\n",
       " 1.283553655713807,\n",
       " 1.2840324046807496,\n",
       " 1.2845106264749497,\n",
       " 1.2849883222561191,\n",
       " 1.2854654931801472,\n",
       " 1.2859421403991176,\n",
       " 1.2864182650613245,\n",
       " 1.2868938683112894,\n",
       " 1.2873689512897784,\n",
       " 1.2878435151338175,\n",
       " 1.2883175609767095,\n",
       " 1.2887910899480501,\n",
       " 1.2892641031737442,\n",
       " 1.2897366017760215,\n",
       " 1.2902085868734536,\n",
       " 1.2906800595809682,\n",
       " 1.2911510210098667,\n",
       " 1.291621472267838,\n",
       " 1.2920914144589764,\n",
       " 1.2925608486837947,\n",
       " 1.2930297760392417,\n",
       " 1.2934981976187165,\n",
       " 1.2939661145120842,\n",
       " 1.2944335278056907,\n",
       " 1.294900438582378,\n",
       " 1.2953668479214997,\n",
       " 1.2958327568989356,\n",
       " 1.2962981665871065,\n",
       " 1.296763078054989,\n",
       " 1.2972274923681306,\n",
       " 1.297691410588664,\n",
       " 1.2981548337753221,\n",
       " 1.2986177629834512,\n",
       " 1.2990801992650276,\n",
       " 1.29954214366867,\n",
       " 1.300003597239655,\n",
       " 1.3004645610199301,\n",
       " 1.3009250360481293,\n",
       " 1.3013850233595858,\n",
       " 1.3018445239863472,\n",
       " 1.3023035389571875,\n",
       " 1.3027620692976236,\n",
       " 1.3032201160299266,\n",
       " 1.303677680173137,\n",
       " 1.304134762743077,\n",
       " 1.304591364752366,\n",
       " 1.3050474872104316,\n",
       " 1.3055031311235252,\n",
       " 1.305958297494734,\n",
       " 1.3064129873239942,\n",
       " 1.3068672016081055,\n",
       " 1.3073209413407427,\n",
       " 1.3077742075124694,\n",
       " 1.308227001110751,\n",
       " 1.3086793231199678,\n",
       " 1.309131174521427,\n",
       " 1.3095825562933763,\n",
       " 1.3100334694110165,\n",
       " 1.3104839148465142,\n",
       " 1.3109338935690134,\n",
       " 1.3113834065446497,\n",
       " 1.3118324547365612,\n",
       " 1.3122810391049016,\n",
       " 1.3127291606068527,\n",
       " 1.3131768201966363,\n",
       " 1.3136240188255262,\n",
       " 1.314070757441861,\n",
       " 1.3145170369910555,\n",
       " 1.3149628584156128,\n",
       " 1.3154082226551371,\n",
       " 1.3158531306463441,\n",
       " 1.3162975833230743,\n",
       " 1.3167415816163035,\n",
       " 1.3171851264541556,\n",
       " 1.3176282187619133,\n",
       " 1.3180708594620303,\n",
       " 1.3185130494741428,\n",
       " 1.3189547897150804,\n",
       " 1.3193960810988783,\n",
       " 1.3198369245367878,\n",
       " 1.3202773209372882,\n",
       " 1.3207172712060984,\n",
       " 1.3211567762461869,\n",
       " 1.3215958369577834,\n",
       " 1.3220344542383908,\n",
       " 1.322472628982795,\n",
       " 1.322910362083076,\n",
       " 1.3233476544286198,\n",
       " 1.3237845069061278,\n",
       " 1.3242209203996287,\n",
       " 1.3246568957904887,\n",
       " 1.3250924339574228,\n",
       " 1.3255275357765042,\n",
       " 1.3259622021211759,\n",
       " ...]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "logs,losses= find_lr(model= Torch.Cnn, loss_fn= Torch.loss_fn, optimizer= Torch.optimizer)\n",
    "plt.plot(logs,losses)\n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('loss')\n",
    "plt.title('learning rate vs loss')\n",
    "plt.show()\n",
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.0827, dtype=torch.float64, grad_fn=<NllLossBackward0>)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_lr(model= Torch.Cnn, loss_fn= Torch.loss_fn, optimizer= Torch.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim  as optim\n",
    "\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "{ 'params': Torch.Cnn.parameters(), 'lr': 0.0125},\n",
    "], lr=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas 100000000 equivalente a 40 segundos\n",
      " Pulando em 0 segundos , em 1 vezes\n",
      "Tamanho da memoria ocupada :4577.87 MB\n",
      "CPU times: total: 14min 1s\n",
      "Wall time: 34min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 20001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = DATA_1M(seconds=40,columns=20000, jump_time =0, n_jumps=1)\n",
    "print(data)\n",
    "data_fourier = data(Fourier=True)\n",
    "data_fourier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (21750, 20000) float64\n",
      "X_Test shape: (8250, 20000) float64\n",
      "y_train shape: (21750,) float64\n",
      "y_test shape: (8250,) float64\n",
      "\n",
      "--------\n",
      "Valor 0: 10000 ocorrência(s)- 0.33%\n",
      "Valor 1: 10000 ocorrência(s)- 0.33%\n",
      "Valor 2: 10000 ocorrência(s)- 0.33%\n",
      "Dataset :  (30000, 20001)\n"
     ]
    }
   ],
   "source": [
    "data.Spliting(data= data_fourier, random_state= 38, test_size = 0.275, shuffle = True, inplace= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape , Y shape torch.Size([64, 20000]) torch.Size([64])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001E0EE4EFFD0>, <torch.utils.data.dataloader.DataLoader object at 0x000001E0EE1D94D0>)\n",
      "Length of train dataloader: 340 batches of 64\n",
      "Length of test dataloader: 129 batches of 64\n"
     ]
    }
   ],
   "source": [
    "train_dataloader , test_dataloader = data.DataLoaders(batch_size=64, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.34507 | Train accuracy: 38.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [13:47<3:13:01, 827.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 84.69437 | Test accuracy: 41.67%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 1.23940 | Train accuracy: 48.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [27:15<2:56:50, 816.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 90.13758 | Test accuracy: 30.20%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 1.08449 | Train accuracy: 65.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [41:02<2:44:14, 821.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 85.79268 | Test accuracy: 40.52%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.99929 | Train accuracy: 74.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [54:35<2:29:58, 818.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.04421 | Test accuracy: 39.24%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.95456 | Train accuracy: 79.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [1:08:34<2:17:34, 825.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.70774 | Test accuracy: 38.63%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.92030 | Train accuracy: 82.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [1:22:22<2:03:55, 826.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.27540 | Test accuracy: 39.31%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.88564 | Train accuracy: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [1:35:11<1:47:41, 807.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.88641 | Test accuracy: 38.86%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.85450 | Train accuracy: 89.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [1:48:31<1:33:56, 805.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.64834 | Test accuracy: 37.73%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.83719 | Train accuracy: 90.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [2:02:30<1:21:34, 815.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.55235 | Test accuracy: 38.43%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.82399 | Train accuracy: 92.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [2:16:19<1:08:19, 819.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.34147 | Test accuracy: 38.42%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.81576 | Train accuracy: 92.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [2:30:09<54:51, 822.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.66981 | Test accuracy: 38.00%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.81025 | Train accuracy: 93.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [2:43:41<40:58, 819.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.86864 | Test accuracy: 37.72%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.80280 | Train accuracy: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [2:57:12<27:13, 816.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.00118 | Test accuracy: 39.11%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.79937 | Train accuracy: 94.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [3:10:39<13:34, 814.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.97332 | Test accuracy: 39.22%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.79809 | Train accuracy: 94.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [3:24:08<00:00, 816.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.60427 | Test accuracy: 38.22%\n",
      "CPU times: total: 20h 14min 1s\n",
      "Wall time: 3h 24min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
      "0       38.215467   87.604266       38.984375    1.345068\n",
      "1       38.215467   87.604266       48.654684    1.239400\n",
      "2       38.215467   87.604266       65.315564    1.084490\n",
      "3       38.215467   87.604266       74.356447    0.999285\n",
      "4       38.215467   87.604266       79.091605    0.954565\n",
      "5       38.215467   87.604266       82.588848    0.920301\n",
      "6       38.215467   87.604266       85.979541    0.885640\n",
      "7       38.215467   87.604266       89.214495    0.854497\n",
      "8       38.215467   87.604266       90.866353    0.837193\n",
      "9       38.215467   87.604266       92.227158    0.823987\n",
      "10      38.215467   87.604266       92.979133    0.815760\n",
      "11      38.215467   87.604266       93.506774    0.810251\n",
      "12      38.215467   87.604266       94.273046    0.802804\n",
      "13      38.215467   87.604266       94.605971    0.799371\n",
      "14      38.215467   87.604266       94.717967    0.798092\n"
     ]
    }
   ],
   "source": [
    "print(Torch(test= True, train= True))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.39      0.55      0.45      2716\n",
      "        WIFI       0.41      0.34      0.37      2809\n",
      "         LTE       0.35      0.25      0.29      2725\n",
      "\n",
      "    accuracy                           0.38      8250\n",
      "   macro avg       0.38      0.38      0.37      8250\n",
      "weighted avg       0.38      0.38      0.37      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data.y_test, Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
