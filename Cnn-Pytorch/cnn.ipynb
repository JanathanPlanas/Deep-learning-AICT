{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from  Data_Loader import DATA_1M\n",
    "from helper_functions import accuracy_fn\n",
    "from CnnModel import NeuralNetCNN\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, recall_score)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas 23334000, equivalente a 14 segundos \n",
      " Pulando em 2 segundos em 3 vezes\n",
      "tamanho da memória ocupada :1068.68 MB\n",
      "CPU times: total: 26.5 s\n",
      "Wall time: 2min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70002, 2001)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = DATA_1M(seconds=14,columns=2000, jump_time =2, n_jumps=3)\n",
    "print(data)\n",
    "data_fourier = data(Fourier=True, Normalizing= True)\n",
    "data_fourier.shape\n",
    "\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape array (100000000, 1),\n",
      "\n",
      "                Clear array \n",
      " [[ 0.0000000e+00-6.1037244e-05j]\n",
      " [-3.0518622e-05+3.0518622e-05j]\n",
      " [-6.1037244e-05-3.0518622e-05j]\n",
      " ...\n",
      " [-6.1037244e-05+6.1037244e-05j]\n",
      " [ 0.0000000e+00-3.0518622e-05j]\n",
      " [ 9.1555863e-05-1.8311173e-04j]] \n",
      "  \n",
      "                memory usage 762.94 MB\n"
     ]
    }
   ],
   "source": [
    "data.clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape array (100000000, 1),\n",
      "\n",
      "               WIFI array \n",
      " [[ 0.0000000e+00+6.1037244e-05j]\n",
      " [ 1.5259311e-04-3.0518622e-05j]\n",
      " [ 6.1037244e-05-1.5259311e-04j]\n",
      " ...\n",
      " [-2.1363035e-04-1.2207449e-04j]\n",
      " [-9.1555863e-05-2.4414898e-04j]\n",
      " [-6.1037244e-05+1.8311173e-04j]] \n",
      "  \n",
      "                memory usage 762.94 MB\n"
     ]
    }
   ],
   "source": [
    "data.wifi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape array (100000000, 1),\n",
      "\n",
      "                LTE array \n",
      "[[-3.0518622e-05+0.0000000e+00j]\n",
      " [-9.1555863e-05+1.2207449e-04j]\n",
      " [-6.1037244e-05+6.1037244e-05j]\n",
      " ...\n",
      " [-9.1555863e-05+1.5259311e-04j]\n",
      " [-2.7466760e-04+6.1037244e-05j]\n",
      " [-3.0518623e-04+6.1037244e-05j]] \n",
      "  \n",
      "                memory usage 762.94 MB\n"
     ]
    }
   ],
   "source": [
    "data.lte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 92.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch = NeuralNetCNN(columns= data_fourier.shape[1] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(2000, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(512, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(256, 128, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(128, 128, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(128, 128, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=64, out_features=4, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Torch.Cnn\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (52501, 2000) float64\n",
      "X_Test shape: (17501, 2000) float64\n",
      "y_train shape: (52501,) float64\n",
      "y_test shape: (17501,) float64\n",
      "\n",
      "--------\n",
      "X_train device: cpu\n",
      "X_Test device: cpu\n",
      "y_train device: cpu\n",
      "y_test device: cpu\n",
      "Valor 0: 23334 ocorrência(s)- 0.33%\n",
      "Valor 1: 23334 ocorrência(s)- 0.33%\n",
      "Valor 2: 23334 ocorrência(s)- 0.33%\n",
      "Dataset :  (70002, 2001)\n"
     ]
    }
   ],
   "source": [
    "data.Spliting(data= data_fourier, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([128, 2000]) y torch.Size([128])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001D610266410>, <torch.utils.data.dataloader.DataLoader object at 0x000001D43C723010>)\n",
      "Length of train dataloader: 411 batches of 128\n",
      "Length of test dataloader: 137 batches of 128\n"
     ]
    }
   ],
   "source": [
    "train_dataloader , test_dataloader = data.DataLoaders(batch_size=128, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourer + Normalizado , 14 segundos de captura, 25 epocas, 128 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [01:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\janat\\OneDrive\\Documentos\\GitHub\\Deep-learning-AICT\\Cnn-Pytorch\\CnnModel.py:101\u001b[0m, in \u001b[0;36mNeuralNetCNN.training_loop\u001b[1;34m(self, model, data_loader_train, data_loader_test, loss_fn, optimizer, accuracy_fn, device, epochs, inplace)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[39m# retropropagando os gradientes e atualizando os pesos\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 101\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    103\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    105\u001b[0m training_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_loader_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
      "0          35.63      168.45           34.93        1.10\n",
      "1          37.64      167.59           36.77        1.09\n",
      "2          39.40      166.70           38.78        1.09\n",
      "3          40.88      165.66           41.02        1.08\n",
      "4          42.77      164.06           43.25        1.07\n",
      "5          44.41      162.35           45.48        1.05\n",
      "6          45.92      161.18           47.34        1.04\n",
      "7          47.50      159.52           49.15        1.03\n",
      "8          48.19      158.74           50.45        1.02\n",
      "9          48.99      157.82           51.84        1.01\n"
     ]
    }
   ],
   "source": [
    "print(Torch(test= True, train= True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.48      0.49      0.48     26234\n",
      "        WIFI       0.56      0.49      0.52     25879\n",
      "         LTE       0.45      0.49      0.47     26012\n",
      "\n",
      "    accuracy                           0.49     78125\n",
      "   macro avg       0.49      0.49      0.49     78125\n",
      "weighted avg       0.49      0.49      0.49     78125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data.y_test, Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = DATA_1M(seconds=28,columns=2000, jump_time =2, n_jumps=3) ; data_fourier = data(Fourier=True, Normalizing= True)\n",
    "Torch = NeuralNetCNN(columns= data_fourier.shape[1] -1)\n",
    "data.Spliting(data= data_fourier, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n",
    "\n",
    "# 14 segundos ,  (70002, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader , test_dataloader = data.DataLoaders(batch_size=128, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [Parameter containing:\n",
       "  tensor([[[ 3.1562e+71,  7.9105e+71],\n",
       "           [-1.3420e+72, -3.7677e+71],\n",
       "           [-1.4976e+72, -4.9873e+71],\n",
       "           ...,\n",
       "           [ 1.0824e+72,  9.2557e+71],\n",
       "           [ 1.1066e+71,  1.1151e+72],\n",
       "           [-9.3122e+71, -1.2459e+72]],\n",
       "  \n",
       "          [[ 4.4548e+71,  3.7407e+71],\n",
       "           [ 4.8837e+70,  5.3196e+71],\n",
       "           [-1.3483e+72, -1.3468e+72],\n",
       "           ...,\n",
       "           [ 6.2752e+71, -5.8780e+71],\n",
       "           [-1.5791e+71, -6.9617e+70],\n",
       "           [ 4.5421e+71, -1.1246e+72]],\n",
       "  \n",
       "          [[ 6.6986e+70,  1.6525e+72],\n",
       "           [-8.2572e+71,  7.5852e+70],\n",
       "           [ 6.5247e+71,  5.3949e+70],\n",
       "           ...,\n",
       "           [-7.9375e+71, -9.5663e+71],\n",
       "           [ 5.6863e+71,  9.4202e+71],\n",
       "           [-1.2139e+71,  2.0171e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-2.2853e+70, -1.1650e+72],\n",
       "           [ 2.1425e+70, -1.7550e+72],\n",
       "           [-5.7133e+71,  6.8838e+71],\n",
       "           ...,\n",
       "           [-3.2067e+69,  1.8814e+71],\n",
       "           [-1.0508e+71,  5.1100e+71],\n",
       "           [-4.6968e+71,  5.8809e+71]],\n",
       "  \n",
       "          [[-6.1156e+71, -3.8226e+71],\n",
       "           [-7.5771e+71,  1.0082e+72],\n",
       "           [-2.7677e+71,  4.7564e+70],\n",
       "           ...,\n",
       "           [-3.0743e+71, -4.7316e+70],\n",
       "           [-6.0270e+71, -1.0418e+72],\n",
       "           [-1.2188e+72, -6.1432e+71]],\n",
       "  \n",
       "          [[ 1.2980e+72,  2.4964e+71],\n",
       "           [-2.4061e+71,  7.3707e+71],\n",
       "           [-1.6261e+71, -6.5688e+71],\n",
       "           ...,\n",
       "           [-3.3547e+71,  3.7934e+71],\n",
       "           [-7.8675e+71, -1.2991e+71],\n",
       "           [-1.2494e+71, -1.7576e+71]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 6.3437e+56,  1.4868e+56, -3.8963e+56, -3.2900e+56,  5.9219e+56,\n",
       "           2.3821e+56, -3.1161e+55, -6.2459e+56, -5.7718e+56, -7.6480e+56,\n",
       "          -6.4061e+56,  1.4831e+56,  2.9612e+56,  5.5397e+56,  6.8964e+55,\n",
       "           1.4904e+56,  1.5644e+56, -5.4140e+56, -4.8301e+56,  3.5771e+56,\n",
       "           1.2062e+57,  3.2077e+55,  5.2575e+56, -5.2405e+56, -1.3693e+56,\n",
       "          -1.3724e+56, -2.3189e+56,  7.5673e+56,  4.9799e+56,  5.5578e+54,\n",
       "          -2.4169e+56,  1.3488e+56], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.8337e+71,  2.8894e+71,  1.9392e+71, -4.7973e+70,  3.4874e+71,\n",
       "          -4.2194e+71, -2.9465e+71,  8.5394e+71, -1.1581e+71, -8.3827e+70,\n",
       "           8.6339e+70,  4.0474e+71, -1.5675e+71,  3.2413e+71,  5.1515e+71,\n",
       "          -1.1056e+71,  2.3753e+71, -1.5039e+71, -2.5695e+71,  2.9945e+71,\n",
       "          -4.8255e+71, -2.2529e+70,  2.4964e+71, -8.6797e+71, -1.3839e+70,\n",
       "           5.2244e+71, -5.2448e+70, -8.4842e+71, -2.3920e+71, -5.1001e+70,\n",
       "          -2.6818e+71,  1.0609e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.3823e+71,  2.3298e+71, -1.5389e+71, -2.2172e+71,  2.1202e+71,\n",
       "           1.0952e+71, -3.0175e+71,  6.5504e+71, -1.1620e+71,  2.8666e+71,\n",
       "           3.3269e+71, -5.3573e+70,  1.6125e+70,  4.7875e+71,  6.1833e+71,\n",
       "          -1.7601e+71,  1.6638e+71,  5.4797e+70,  3.5706e+71, -8.2414e+70,\n",
       "           3.5165e+69,  3.2428e+70,  2.8036e+70, -6.5378e+71, -7.0513e+70,\n",
       "           1.7943e+71,  2.0663e+71, -5.2286e+71,  3.7291e+71, -2.7441e+70,\n",
       "           3.6320e+71, -4.0682e+69], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-4.0180e+71, -1.2548e+72],\n",
       "           [-4.3506e+71, -1.2558e+72],\n",
       "           [-6.8297e+70, -1.0462e+72],\n",
       "           ...,\n",
       "           [-6.4730e+69,  2.1944e+71],\n",
       "           [-6.7144e+71, -1.2888e+72],\n",
       "           [-3.3272e+71,  6.1739e+70]],\n",
       "  \n",
       "          [[-4.1918e+71, -6.9510e+71],\n",
       "           [-9.4608e+70,  7.9117e+70],\n",
       "           [ 6.4593e+71, -1.2312e+72],\n",
       "           ...,\n",
       "           [-4.2114e+71, -1.3479e+72],\n",
       "           [ 5.6054e+71, -4.1754e+71],\n",
       "           [ 6.1216e+71,  3.1801e+71]],\n",
       "  \n",
       "          [[-1.1061e+72, -1.3777e+72],\n",
       "           [ 1.2008e+71,  2.9245e+71],\n",
       "           [-4.9525e+71,  7.0167e+71],\n",
       "           ...,\n",
       "           [-2.2014e+71, -8.7097e+71],\n",
       "           [-4.0332e+71, -4.8599e+71],\n",
       "           [-4.1454e+71, -2.5945e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 1.2746e+72,  3.5783e+71],\n",
       "           [ 8.9026e+71,  3.2253e+71],\n",
       "           [ 9.8001e+71,  6.0154e+69],\n",
       "           ...,\n",
       "           [ 6.0347e+71,  7.5320e+71],\n",
       "           [ 6.8096e+69, -4.0486e+71],\n",
       "           [ 3.7162e+71,  8.9298e+71]],\n",
       "  \n",
       "          [[-9.2101e+71, -3.1890e+71],\n",
       "           [ 7.6831e+71, -1.1487e+72],\n",
       "           [-6.9621e+71, -2.9403e+71],\n",
       "           ...,\n",
       "           [-1.8369e+71,  5.9654e+71],\n",
       "           [ 6.9538e+71,  7.7783e+71],\n",
       "           [ 6.8316e+71, -1.3562e+71]],\n",
       "  \n",
       "          [[-1.1451e+71, -1.2112e+71],\n",
       "           [ 1.3616e+72,  6.8666e+71],\n",
       "           [ 3.2948e+71, -3.2883e+71],\n",
       "           ...,\n",
       "           [-5.4682e+71,  7.5251e+71],\n",
       "           [ 1.5092e+72, -9.0506e+70],\n",
       "           [ 6.5834e+71, -2.6063e+71]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 5.8914e+56, -4.7890e+56,  4.7956e+56, -5.4088e+56, -1.2007e+56,\n",
       "          -4.4830e+55, -3.7228e+56,  1.0955e+56,  6.5819e+56,  2.4543e+56,\n",
       "          -6.3065e+56, -1.0564e+56,  2.7762e+56,  2.4972e+56,  9.0716e+56,\n",
       "          -5.8839e+56,  1.4301e+57,  8.1952e+55,  3.5762e+56, -1.0438e+57,\n",
       "          -8.2490e+55,  2.5878e+56,  1.1154e+56,  5.6677e+56, -2.7934e+56,\n",
       "          -2.4491e+56, -7.1909e+56,  1.9406e+56,  1.2192e+56,  7.6389e+56,\n",
       "          -8.0780e+56, -4.5956e+56], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-5.7587e+71, -3.0666e+71,  5.3758e+71, -1.8551e+71,  2.8832e+71,\n",
       "          -2.3120e+71,  2.1516e+71,  2.1894e+71,  4.0330e+70, -2.7462e+71,\n",
       "           4.1573e+71,  2.8634e+71,  2.1357e+71, -2.5452e+71,  2.2603e+71,\n",
       "           2.9957e+71, -4.0301e+70, -2.9749e+71,  2.7149e+71,  1.0945e+71,\n",
       "          -6.3498e+71, -3.8162e+71, -2.1917e+71,  5.3552e+70,  1.3629e+71,\n",
       "           1.8957e+70, -1.9978e+71,  1.0417e+71, -1.7725e+71, -4.4893e+71,\n",
       "           2.5130e+71,  5.9543e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.4327e+71, -2.2104e+71,  4.9512e+71, -2.6019e+71,  4.3800e+71,\n",
       "          -2.1577e+71, -3.3471e+70, -3.8751e+71,  2.4289e+70,  1.5026e+70,\n",
       "           6.9052e+70,  5.4534e+71,  2.3029e+70, -3.3033e+71,  2.3060e+71,\n",
       "           4.4665e+70, -2.8915e+71, -3.5775e+70, -6.0844e+71,  5.6766e+71,\n",
       "          -2.3479e+71, -4.4592e+71,  6.3524e+70,  2.5953e+71, -1.7164e+71,\n",
       "           1.9572e+70, -1.2601e+71, -1.7881e+71, -3.1235e+71, -5.8624e+71,\n",
       "           2.8859e+71,  2.7634e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 4.7237e+71,  6.5521e+71],\n",
       "           [-9.6065e+71, -2.8253e+71],\n",
       "           [ 5.7397e+71,  6.1206e+71],\n",
       "           ...,\n",
       "           [ 1.9335e+71, -5.9890e+70],\n",
       "           [-5.7742e+71,  9.9017e+71],\n",
       "           [ 3.2520e+71,  1.8131e+72]],\n",
       "  \n",
       "          [[-3.8734e+71, -6.6933e+71],\n",
       "           [-2.4879e+71,  9.4403e+71],\n",
       "           [ 7.6608e+71,  9.2214e+71],\n",
       "           ...,\n",
       "           [-6.8639e+71,  1.2279e+72],\n",
       "           [ 3.7471e+70,  8.6145e+71],\n",
       "           [ 4.9672e+70,  5.4444e+71]],\n",
       "  \n",
       "          [[ 7.2864e+70, -8.3539e+70],\n",
       "           [-5.3522e+71, -3.1122e+71],\n",
       "           [ 3.8379e+71, -2.6032e+71],\n",
       "           ...,\n",
       "           [ 1.2756e+71, -6.5014e+70],\n",
       "           [ 2.4841e+71,  5.5320e+71],\n",
       "           [ 3.7577e+70,  7.9159e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 6.6206e+71, -5.9135e+71],\n",
       "           [-2.5616e+71,  6.4948e+71],\n",
       "           [-1.2518e+71,  1.5356e+72],\n",
       "           ...,\n",
       "           [-5.0075e+71,  7.8332e+71],\n",
       "           [ 8.6862e+71, -1.4595e+71],\n",
       "           [-6.8091e+71,  7.3532e+71]],\n",
       "  \n",
       "          [[-8.7273e+71,  8.1384e+71],\n",
       "           [ 6.4526e+71,  3.8902e+71],\n",
       "           [-2.4372e+71, -2.4535e+71],\n",
       "           ...,\n",
       "           [-9.7344e+70,  2.5992e+71],\n",
       "           [ 2.3350e+71, -8.7829e+71],\n",
       "           [-9.4173e+71,  8.6331e+70]],\n",
       "  \n",
       "          [[ 6.6774e+71,  2.0457e+71],\n",
       "           [ 1.2265e+71, -1.1097e+71],\n",
       "           [ 4.3553e+71,  1.0375e+71],\n",
       "           ...,\n",
       "           [ 4.2390e+71,  3.4550e+71],\n",
       "           [ 2.9652e+71, -4.3692e+70],\n",
       "           [-2.6223e+71,  9.3238e+71]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 3.3969e+56, -6.5611e+56,  3.6519e+56,  1.4641e+56,  1.9232e+57,\n",
       "           4.7206e+56,  1.9257e+56,  5.7566e+55, -1.1447e+55, -2.7243e+56,\n",
       "           4.2472e+56,  4.9579e+56, -1.4969e+56,  9.9800e+55,  3.1554e+56,\n",
       "           1.2677e+56, -6.5468e+56,  3.2133e+55, -1.5336e+55,  3.8786e+56,\n",
       "          -1.6389e+56, -1.9300e+56,  7.9274e+55,  6.6494e+56, -1.6606e+56,\n",
       "          -2.7059e+56,  2.2448e+56, -1.6040e+56, -1.3339e+57,  3.6855e+55,\n",
       "           6.1382e+56,  5.0414e+56], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 8.4977e+70,  9.8104e+70, -1.2075e+69,  1.1083e+71,  1.4980e+71,\n",
       "          -1.7202e+69,  7.0919e+70, -1.4845e+71,  2.2393e+71, -1.3523e+71,\n",
       "          -1.3740e+71,  4.0308e+71,  5.1071e+70,  4.8755e+70, -4.0773e+71,\n",
       "          -1.9399e+71,  5.5959e+69, -3.6044e+70, -1.8419e+71,  2.2530e+71,\n",
       "          -5.4065e+70, -2.8887e+70, -1.3647e+70, -3.6051e+71, -2.9179e+70,\n",
       "          -2.3146e+71,  2.4297e+70,  4.8117e+70, -2.3572e+71,  2.8602e+71,\n",
       "           2.2392e+71, -1.7780e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-3.7739e+70,  1.4493e+71,  4.4117e+71,  5.3434e+70, -2.6395e+71,\n",
       "          -4.7944e+71, -1.9820e+71,  2.6102e+70,  1.3497e+71,  1.5309e+71,\n",
       "           2.9910e+70, -3.0261e+71,  4.9971e+70, -2.3347e+71,  2.6760e+71,\n",
       "          -4.1760e+71, -2.7240e+71,  8.0505e+70, -6.6851e+70,  3.0485e+71,\n",
       "          -5.3809e+71, -2.1647e+71, -1.0437e+71, -2.7717e+71, -2.7151e+71,\n",
       "          -3.7795e+71, -3.3443e+71, -1.7059e+71,  2.0003e+71,  8.6882e+70,\n",
       "          -4.0950e+70, -3.9674e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-5.0686e+71,  3.9478e+71],\n",
       "           [-9.0332e+71, -9.9147e+70],\n",
       "           [ 1.4856e+71, -1.7709e+71],\n",
       "           ...,\n",
       "           [-2.2404e+71,  7.8317e+71],\n",
       "           [ 6.2637e+70,  1.2522e+71],\n",
       "           [ 3.8293e+70,  1.0455e+69]],\n",
       "  \n",
       "          [[-2.3713e+71,  1.1091e+71],\n",
       "           [ 3.3456e+71,  1.0007e+72],\n",
       "           [-3.8097e+71, -3.2220e+71],\n",
       "           ...,\n",
       "           [ 1.8116e+71, -9.1184e+71],\n",
       "           [ 1.2463e+71, -6.9194e+71],\n",
       "           [ 2.4554e+71, -1.6081e+71]],\n",
       "  \n",
       "          [[ 4.5964e+71, -1.0362e+72],\n",
       "           [ 1.3757e+72, -4.0350e+71],\n",
       "           [ 1.2752e+71, -3.6157e+71],\n",
       "           ...,\n",
       "           [ 3.1026e+71,  2.8987e+71],\n",
       "           [ 2.7396e+71, -1.5363e+71],\n",
       "           [-2.8349e+71, -2.3455e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 1.8576e+71, -1.5599e+70],\n",
       "           [-5.7548e+71, -9.6422e+71],\n",
       "           [-1.1554e+71,  3.1722e+71],\n",
       "           ...,\n",
       "           [-3.7841e+71,  9.9707e+71],\n",
       "           [ 5.2602e+71,  1.1304e+71],\n",
       "           [-9.2551e+71,  2.5439e+71]],\n",
       "  \n",
       "          [[-3.7093e+71,  1.7916e+71],\n",
       "           [-8.4227e+70, -2.6517e+71],\n",
       "           [-7.3219e+71, -6.0661e+71],\n",
       "           ...,\n",
       "           [ 3.8930e+71, -7.2743e+70],\n",
       "           [ 5.5187e+70,  1.8458e+71],\n",
       "           [ 6.7242e+71,  2.2249e+71]],\n",
       "  \n",
       "          [[ 3.6379e+71,  1.7440e+71],\n",
       "           [ 4.8440e+71,  9.0421e+71],\n",
       "           [-7.8196e+71, -2.4172e+71],\n",
       "           ...,\n",
       "           [ 1.3558e+71,  4.8130e+71],\n",
       "           [-7.6307e+70, -9.8655e+70],\n",
       "           [ 4.7729e+71, -8.9520e+71]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 6.7935e+56,  5.1200e+56,  1.1393e+57,  2.6238e+56,  7.1761e+56,\n",
       "           5.0978e+56, -3.7838e+55,  2.9296e+56, -7.7086e+54,  5.9961e+55,\n",
       "           1.3166e+56,  8.2936e+55,  7.3224e+56,  3.7349e+56,  3.1525e+56,\n",
       "          -5.7398e+56,  5.4069e+56,  6.1769e+56,  3.5405e+56,  9.0461e+55,\n",
       "           1.1997e+56,  7.2234e+56,  4.2191e+56, -4.4939e+56,  1.0048e+56,\n",
       "           3.2378e+56, -8.8353e+56,  7.2629e+55,  2.5677e+56,  3.0965e+56,\n",
       "          -1.3623e+56, -6.4932e+55], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.0681e+70,  4.5165e+70,  4.4061e+70, -1.9125e+71,  2.1055e+70,\n",
       "          -6.5517e+70, -1.7796e+71,  7.8564e+70, -1.6157e+70,  1.9446e+71,\n",
       "          -2.3086e+70,  4.4884e+70,  3.6289e+70,  4.0125e+70,  2.4236e+71,\n",
       "          -4.8696e+70, -9.6311e+70, -2.4146e+71,  7.4464e+70, -2.1068e+71,\n",
       "           1.2084e+71,  5.0337e+70,  1.7482e+70,  2.5241e+71, -1.6052e+70,\n",
       "           3.5556e+70, -4.3692e+70, -1.8764e+71, -1.9864e+71, -1.9680e+71,\n",
       "           1.3167e+71, -2.1001e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.8552e+71, -8.2448e+70, -2.2149e+71, -1.8530e+71,  2.3577e+71,\n",
       "           5.1631e+70, -1.4514e+71, -8.6692e+69, -2.0199e+71,  2.3664e+71,\n",
       "           3.8558e+70, -1.3383e+71, -2.5388e+70, -3.2576e+70, -1.2204e+71,\n",
       "          -1.3284e+71, -1.3915e+71,  1.6487e+71,  3.9722e+70, -6.4522e+70,\n",
       "           1.1262e+71, -2.0875e+71, -1.4476e+71,  3.5552e+71,  1.4361e+71,\n",
       "          -1.3069e+71,  5.7126e+70, -3.2618e+71, -9.4913e+70,  1.3317e+71,\n",
       "          -1.0819e+71, -1.7705e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 2.3308e+70,  1.6661e+71],\n",
       "           [-1.9655e+71,  3.0159e+71],\n",
       "           [ 1.8005e+71,  2.9010e+70],\n",
       "           ...,\n",
       "           [-2.7887e+71,  2.0631e+71],\n",
       "           [-2.9874e+71, -4.3178e+70],\n",
       "           [-1.8297e+71,  4.0720e+71]],\n",
       "  \n",
       "          [[-5.3978e+70,  2.8903e+71],\n",
       "           [-3.6957e+71, -1.3853e+71],\n",
       "           [ 5.4445e+70,  6.1102e+71],\n",
       "           ...,\n",
       "           [-6.7736e+71,  2.5955e+71],\n",
       "           [-6.3269e+71, -2.2396e+71],\n",
       "           [-1.3837e+71,  9.0254e+70]],\n",
       "  \n",
       "          [[ 9.7713e+69, -6.4167e+70],\n",
       "           [ 2.0717e+71, -4.9047e+69],\n",
       "           [ 5.1482e+70, -4.1226e+71],\n",
       "           ...,\n",
       "           [ 3.6906e+71, -1.2972e+72],\n",
       "           [ 3.7963e+71, -8.5439e+71],\n",
       "           [ 2.1585e+71, -1.6736e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-1.6194e+71, -6.8928e+70],\n",
       "           [ 6.0075e+70, -7.9652e+70],\n",
       "           [-1.1968e+71, -8.6048e+70],\n",
       "           ...,\n",
       "           [ 3.7702e+70, -2.5433e+71],\n",
       "           [ 6.0938e+70, -4.6657e+70],\n",
       "           [ 1.9645e+70,  5.8779e+71]],\n",
       "  \n",
       "          [[ 9.2138e+70,  4.0935e+70],\n",
       "           [-1.6656e+70,  2.9073e+71],\n",
       "           [ 1.3677e+71, -4.3073e+71],\n",
       "           ...,\n",
       "           [ 3.2163e+71,  8.8622e+69],\n",
       "           [ 3.6518e+71, -2.2091e+71],\n",
       "           [ 4.4245e+70, -7.4394e+70]],\n",
       "  \n",
       "          [[-1.4970e+71,  9.5836e+70],\n",
       "           [-9.6986e+69,  5.7020e+71],\n",
       "           [ 2.9988e+71, -2.7070e+71],\n",
       "           ...,\n",
       "           [ 7.4300e+71, -2.8730e+71],\n",
       "           [ 2.8174e+71, -6.0552e+71],\n",
       "           [-2.0431e+71, -4.3493e+71]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-3.8474e+56, -3.1950e+55,  2.2310e+56,  7.0445e+56, -1.6249e+56,\n",
       "          -4.1120e+56,  6.4691e+55,  4.1195e+56,  1.3577e+56, -9.1176e+56,\n",
       "          -1.0424e+56,  1.5983e+56,  1.2432e+56,  2.2982e+56, -5.4396e+55,\n",
       "           5.7326e+56,  2.2767e+56, -4.2022e+55,  8.2324e+55, -3.3094e+56,\n",
       "          -2.1010e+56,  2.6353e+56,  7.6500e+55, -2.4678e+56, -2.0501e+56,\n",
       "           4.9323e+56, -9.9448e+55, -8.0055e+56,  1.1656e+56,  4.8851e+56,\n",
       "           1.1975e+56,  1.0621e+57, -1.3699e+56,  3.5445e+56, -1.1812e+55,\n",
       "           1.1911e+56, -4.5183e+56,  3.7847e+56, -3.5786e+56, -4.7747e+56,\n",
       "          -5.9243e+56, -5.1684e+55, -3.5252e+56,  2.7731e+56,  1.6841e+56,\n",
       "           2.5542e+56, -4.0347e+56, -1.8150e+55], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-3.0577e+70, -1.3533e+71, -2.2872e+71,  6.3683e+70,  1.4253e+70,\n",
       "          -1.2484e+71,  2.2810e+71, -1.8367e+71,  3.1710e+70,  1.4693e+71,\n",
       "           3.2414e+70,  8.0013e+70,  7.4625e+70,  7.1293e+70, -8.9522e+70,\n",
       "          -2.3097e+70,  1.5306e+71, -1.2450e+70,  3.9938e+71,  1.1058e+71,\n",
       "           9.7402e+70,  9.4383e+70, -1.7811e+71,  6.7696e+70,  1.9983e+71,\n",
       "          -1.7408e+71,  2.4958e+70, -6.6520e+69, -9.7834e+70, -1.8989e+71,\n",
       "           4.1084e+70, -2.5330e+71, -4.4865e+71,  2.3061e+71,  1.9408e+71,\n",
       "          -1.4761e+71, -8.8569e+70, -8.1791e+70, -6.8620e+70,  1.1229e+71,\n",
       "           2.2093e+71, -3.0585e+70,  1.0164e+71,  3.5589e+70, -5.4306e+70,\n",
       "           4.0471e+70, -1.4906e+71, -8.8791e+70], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.5593e+71, -1.5952e+70, -3.2738e+70,  3.8821e+71,  8.7789e+67,\n",
       "          -6.9621e+70,  1.0260e+71, -2.4660e+71,  6.5914e+70,  2.4906e+71,\n",
       "           1.4709e+71,  1.6210e+71,  1.2342e+71,  9.8949e+70, -5.0993e+70,\n",
       "           8.7641e+70,  5.9337e+70,  7.1798e+70,  4.9994e+71,  1.5030e+71,\n",
       "          -6.3124e+69, -1.8922e+71, -2.2130e+70, -7.5413e+70,  7.2548e+70,\n",
       "          -1.9681e+71,  4.6813e+70,  8.0599e+70, -5.3945e+70, -1.8731e+71,\n",
       "          -7.0012e+70, -1.4507e+71, -3.6400e+71,  3.4536e+71,  3.4044e+70,\n",
       "          -1.6743e+71, -7.0424e+70, -1.1401e+71, -2.2489e+71,  2.7543e+70,\n",
       "           1.9546e+71, -8.4782e+70,  1.2259e+71, -4.2503e+70,  8.9476e+70,\n",
       "          -1.5103e+70, -9.1010e+70, -2.4586e+71], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-2.2155e+70, -3.7839e+71],\n",
       "           [-1.7508e+71,  1.3311e+71],\n",
       "           [ 6.2637e+70,  2.7309e+71],\n",
       "           ...,\n",
       "           [-1.1655e+71, -2.6703e+71],\n",
       "           [-2.7662e+70,  1.0455e+71],\n",
       "           [ 1.6486e+71, -4.0079e+71]],\n",
       "  \n",
       "          [[ 1.0951e+71, -1.7090e+71],\n",
       "           [ 4.1348e+71, -1.1040e+71],\n",
       "           [-2.9101e+70, -8.9251e+70],\n",
       "           ...,\n",
       "           [-3.7242e+71, -1.6194e+71],\n",
       "           [-2.1134e+71, -1.4247e+71],\n",
       "           [ 7.0919e+71, -2.5946e+71]],\n",
       "  \n",
       "          [[-9.5229e+70, -3.7435e+71],\n",
       "           [-2.6051e+71,  4.9086e+71],\n",
       "           [-2.3590e+71, -1.6826e+71],\n",
       "           ...,\n",
       "           [-3.1584e+71, -1.7805e+71],\n",
       "           [-6.4493e+70,  1.9302e+71],\n",
       "           [-2.6858e+71, -3.3591e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 1.6956e+71, -2.9629e+71],\n",
       "           [ 1.8970e+71,  1.6390e+70],\n",
       "           [-1.7950e+71, -4.1906e+70],\n",
       "           ...,\n",
       "           [ 1.4170e+71, -1.1562e+71],\n",
       "           [-2.0675e+71,  7.9818e+69],\n",
       "           [-1.2445e+71,  2.6791e+70]],\n",
       "  \n",
       "          [[ 1.1584e+71, -3.6889e+70],\n",
       "           [ 1.3589e+71, -1.0785e+71],\n",
       "           [ 1.3555e+71, -1.7812e+70],\n",
       "           ...,\n",
       "           [-1.8280e+71,  1.3215e+71],\n",
       "           [ 9.8511e+70,  3.8488e+70],\n",
       "           [ 1.0996e+70, -2.7943e+71]],\n",
       "  \n",
       "          [[ 4.6697e+70, -1.7615e+71],\n",
       "           [ 3.0647e+71, -2.0483e+71],\n",
       "           [ 2.6720e+71, -2.6956e+71],\n",
       "           ...,\n",
       "           [ 3.2818e+71, -7.2859e+70],\n",
       "           [-8.0468e+70, -1.9109e+71],\n",
       "           [ 7.7880e+70, -9.2969e+70]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.8749e+56, -8.8605e+55, -1.2941e+56, -3.8682e+55,  1.8530e+56,\n",
       "          -1.1749e+56, -1.7716e+56,  1.0116e+56, -4.8306e+56,  2.7308e+56,\n",
       "           9.0995e+55,  9.3333e+55, -1.5715e+56, -2.0417e+56,  1.6216e+56,\n",
       "          -2.0322e+56,  7.2208e+55, -2.2779e+56, -9.9238e+55,  2.1326e+56,\n",
       "           1.9014e+55,  2.9192e+55,  2.9038e+56,  4.1870e+56,  8.5723e+55,\n",
       "          -2.3114e+56, -1.2474e+53, -1.8523e+56,  5.0305e+55,  1.6338e+56,\n",
       "           1.0652e+56,  4.7376e+56,  2.0059e+55, -1.1756e+56, -2.4275e+56,\n",
       "           8.4395e+55,  1.2240e+56,  7.0748e+56,  1.4666e+56,  1.8671e+56,\n",
       "          -1.1188e+56, -4.7287e+56, -2.0755e+56, -1.8009e+55, -2.3075e+54,\n",
       "           2.5874e+56, -4.8420e+56,  4.6778e+56], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.3325e+71, -2.2946e+70,  1.6638e+71,  5.3165e+70,  1.3220e+71,\n",
       "           3.3793e+70, -5.9639e+70,  4.1810e+70, -1.4570e+70,  7.2690e+69,\n",
       "          -8.4912e+70, -2.8578e+70, -4.0471e+71,  2.0708e+71,  2.3143e+70,\n",
       "           3.8703e+70, -6.2298e+70,  1.1944e+71, -1.6916e+71,  3.0334e+70,\n",
       "          -9.2987e+70, -9.4050e+70, -1.1325e+71,  1.3182e+69,  6.7376e+70,\n",
       "          -2.5363e+71,  1.1052e+71,  1.5505e+71,  4.0448e+70, -5.3702e+70,\n",
       "          -1.8412e+71,  5.4284e+70,  4.9030e+70,  8.1036e+70,  1.3826e+71,\n",
       "           1.3198e+69, -1.6877e+71,  1.7082e+71, -1.1949e+71,  1.8475e+71,\n",
       "           1.9017e+71,  1.3439e+71,  1.4605e+71, -6.3674e+70, -1.4510e+70,\n",
       "           9.3432e+70, -9.5221e+67, -1.1567e+71], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.4873e+71,  9.1687e+70,  5.6326e+70, -2.9942e+70,  6.6239e+70,\n",
       "           1.2172e+71, -1.3580e+71, -7.6270e+70,  1.1347e+71, -9.9238e+70,\n",
       "           8.7921e+70, -6.4530e+70, -2.9775e+71,  8.4044e+70, -1.7180e+70,\n",
       "           7.2285e+70, -9.6647e+70,  1.4458e+71, -3.6876e+70,  3.1300e+70,\n",
       "          -1.0947e+71, -8.0718e+70, -3.0202e+70,  7.7018e+69, -3.1793e+70,\n",
       "          -2.3292e+71,  1.7756e+71,  1.5024e+71,  2.3304e+71, -2.9345e+70,\n",
       "          -1.0495e+71,  1.6237e+71, -6.3153e+69, -6.2923e+70, -2.5719e+70,\n",
       "           2.4518e+70, -1.2370e+71,  6.8219e+70,  4.7251e+70,  1.8964e+71,\n",
       "           7.4684e+70,  1.3368e+71,  8.7652e+70, -8.8807e+70, -1.3456e+70,\n",
       "          -8.0708e+69,  5.1593e+70, -5.6624e+70], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[ 9.6106e+70,  3.4825e+71],\n",
       "           [ 8.4609e+70,  6.7735e+69],\n",
       "           [ 1.1058e+71,  4.6369e+71],\n",
       "           ...,\n",
       "           [-4.4778e+70,  1.7302e+70],\n",
       "           [-3.1433e+70,  4.5777e+71],\n",
       "           [-3.7291e+70,  6.9836e+70]],\n",
       "  \n",
       "          [[ 4.4125e+71, -1.1499e+71],\n",
       "           [ 6.4175e+71,  9.3458e+70],\n",
       "           [-2.6148e+71, -7.1819e+70],\n",
       "           ...,\n",
       "           [-9.0670e+69,  4.7135e+71],\n",
       "           [ 1.4458e+71, -1.8288e+70],\n",
       "           [ 5.8468e+70, -2.2407e+70]],\n",
       "  \n",
       "          [[-1.4622e+71,  1.4864e+71],\n",
       "           [ 2.1688e+70,  2.3342e+70],\n",
       "           [-3.6861e+71,  1.1296e+71],\n",
       "           ...,\n",
       "           [ 4.0405e+70, -1.8828e+71],\n",
       "           [ 2.0722e+71, -2.4914e+71],\n",
       "           [-3.7942e+70, -1.5039e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 5.8638e+71, -3.7251e+70],\n",
       "           [ 2.1672e+71,  3.5498e+70],\n",
       "           [ 3.8959e+71, -4.4295e+71],\n",
       "           ...,\n",
       "           [ 3.5710e+71,  2.7783e+70],\n",
       "           [ 2.7704e+71, -9.1188e+70],\n",
       "           [ 2.7024e+71,  9.6901e+70]],\n",
       "  \n",
       "          [[-1.5230e+71, -6.1697e+70],\n",
       "           [-1.7098e+70, -2.7634e+71],\n",
       "           [-3.0421e+71,  2.7541e+70],\n",
       "           ...,\n",
       "           [ 3.7736e+71, -1.9995e+71],\n",
       "           [-9.2214e+70, -2.5345e+71],\n",
       "           [ 5.1914e+70, -1.3463e+71]],\n",
       "  \n",
       "          [[-6.7402e+70,  9.7055e+70],\n",
       "           [-4.2862e+71,  3.6887e+71],\n",
       "           [ 3.1951e+71,  7.7949e+70],\n",
       "           ...,\n",
       "           [ 3.5028e+70, -2.3668e+71],\n",
       "           [-8.3821e+70, -9.6150e+70],\n",
       "           [-1.2275e+71, -7.7030e+70]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-4.2874e+56,  2.0550e+56,  3.0912e+56,  1.1476e+56,  1.0868e+55,\n",
       "          -2.4385e+56, -2.8735e+56,  1.1682e+55,  2.5137e+56, -6.4407e+56,\n",
       "           4.4755e+56, -3.1356e+56, -3.5482e+56, -1.3097e+56,  4.5684e+56,\n",
       "          -1.6952e+56, -2.4525e+56, -1.8491e+56,  1.5759e+55, -2.4746e+56,\n",
       "          -1.0600e+56,  2.4191e+56,  1.3221e+56,  6.0649e+55, -2.3327e+56,\n",
       "          -2.0432e+55,  2.1847e+56,  1.7674e+56, -6.8203e+55,  1.2809e+56,\n",
       "           3.4188e+56,  2.9677e+56, -3.5381e+56, -1.2583e+56, -3.3419e+55,\n",
       "          -3.1917e+56,  2.0038e+56, -1.7409e+55, -1.9787e+56, -6.6468e+55,\n",
       "          -3.5465e+56, -6.8974e+55, -2.0602e+56,  2.9446e+56,  9.2320e+55,\n",
       "           5.0733e+56, -6.5259e+55,  4.5696e+56], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 5.5850e+70, -1.4963e+71,  3.5112e+70,  3.8343e+70, -1.2316e+71,\n",
       "           6.7584e+70, -1.8925e+70, -1.0907e+71, -8.0486e+70,  7.7687e+69,\n",
       "           9.0229e+70, -4.6378e+70, -2.9459e+69, -1.3345e+70, -7.7078e+70,\n",
       "           2.6227e+70,  1.6734e+71, -2.8697e+70,  1.3160e+71,  3.2700e+70,\n",
       "          -7.7140e+70, -3.2049e+70,  2.9576e+70,  6.0958e+70, -5.0640e+70,\n",
       "          -7.4865e+70, -2.7188e+70,  7.9378e+70,  1.7023e+70,  2.9367e+70,\n",
       "           1.3503e+71,  1.3976e+70, -1.3872e+70,  1.4278e+71,  2.2952e+70,\n",
       "          -1.1810e+70, -1.6083e+70, -1.0007e+70,  2.0843e+70, -1.0279e+71,\n",
       "           1.9947e+70, -7.4754e+70,  3.9854e+70, -5.0122e+70,  1.0067e+71,\n",
       "           5.6464e+70, -1.4307e+70,  3.0056e+70], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.7255e+71, -5.8258e+70,  1.3798e+71, -1.6960e+71,  2.7291e+70,\n",
       "           3.9081e+70,  1.0109e+71,  1.6367e+71,  4.7720e+70, -4.6965e+70,\n",
       "           6.1268e+70, -6.9116e+70, -1.1080e+71,  1.2964e+71,  1.9774e+70,\n",
       "          -1.2702e+71,  1.9463e+71,  1.6252e+71,  7.6346e+70, -8.8366e+69,\n",
       "           5.8872e+70, -1.5613e+71,  5.5055e+70, -9.3334e+70, -1.2403e+71,\n",
       "           6.4079e+69,  2.0151e+71, -6.8892e+70,  6.6721e+70, -3.1158e+70,\n",
       "           6.0308e+70,  2.4437e+71,  2.6865e+70,  5.0320e+70, -4.2652e+70,\n",
       "          -8.1405e+70,  4.5701e+70,  1.2323e+71,  8.9186e+70,  1.2384e+71,\n",
       "          -4.5159e+70,  1.0362e+71,  7.2513e+70,  1.1362e+71,  8.9081e+70,\n",
       "          -6.5994e+70,  1.6961e+71,  1.3411e+71], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-1.3871e+71, -2.3091e+71],\n",
       "           [-4.7973e+70,  2.0191e+71],\n",
       "           [-5.1534e+70, -3.6678e+70],\n",
       "           ...,\n",
       "           [ 2.0739e+71, -4.2268e+70],\n",
       "           [ 1.3755e+71, -7.4186e+70],\n",
       "           [ 2.9541e+70,  1.9844e+71]],\n",
       "  \n",
       "          [[-6.4164e+70, -2.1064e+71],\n",
       "           [ 2.9608e+70,  1.3938e+71],\n",
       "           [ 2.6434e+71, -2.6297e+70],\n",
       "           ...,\n",
       "           [-3.9181e+70,  5.8807e+70],\n",
       "           [-8.4604e+70,  2.7301e+70],\n",
       "           [-1.0283e+71, -3.9900e+70]],\n",
       "  \n",
       "          [[-1.7042e+71,  5.9120e+69],\n",
       "           [-1.5784e+71,  3.3162e+71],\n",
       "           [ 1.9355e+69, -2.1601e+71],\n",
       "           ...,\n",
       "           [-2.6561e+70,  1.3638e+71],\n",
       "           [-1.3468e+71, -5.3799e+70],\n",
       "           [ 1.8190e+70,  1.4015e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 1.4162e+71,  3.3901e+70],\n",
       "           [ 1.6102e+71, -6.6655e+70],\n",
       "           [-5.2488e+70, -4.7609e+70],\n",
       "           ...,\n",
       "           [ 3.1740e+71, -5.0493e+70],\n",
       "           [ 2.3744e+71, -1.6551e+71],\n",
       "           [ 1.6217e+71, -1.2628e+71]],\n",
       "  \n",
       "          [[-7.6096e+70, -1.3804e+71],\n",
       "           [ 2.0123e+70, -1.1765e+71],\n",
       "           [ 1.6543e+71,  6.8515e+70],\n",
       "           ...,\n",
       "           [-1.4983e+71, -8.3915e+70],\n",
       "           [ 1.4123e+71, -3.2862e+71],\n",
       "           [ 1.4501e+71, -8.5839e+70]],\n",
       "  \n",
       "          [[ 2.8277e+70,  6.2796e+69],\n",
       "           [-1.1230e+71,  2.8820e+70],\n",
       "           [-6.4157e+70, -7.4800e+69],\n",
       "           ...,\n",
       "           [ 9.8397e+70,  7.8117e+70],\n",
       "           [ 1.2577e+70, -1.3289e+71],\n",
       "           [ 2.3493e+71,  9.5073e+70]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-2.6162e+56, -1.1754e+56, -5.3039e+55, -1.3955e+56,  2.2986e+55,\n",
       "           8.4576e+55, -1.8559e+56, -6.9737e+55,  3.0006e+56,  3.6773e+56,\n",
       "          -4.6102e+56,  8.5072e+55,  7.6397e+55, -6.1551e+55,  3.7171e+56,\n",
       "           3.1270e+56,  6.6489e+55,  4.7794e+55,  1.5066e+56, -1.5211e+56,\n",
       "          -7.4277e+55, -2.5767e+56, -2.4890e+55, -9.9610e+55,  1.6422e+56,\n",
       "          -1.9621e+54, -1.8712e+56,  9.8029e+55, -2.3609e+56, -8.9413e+55,\n",
       "           5.0335e+55,  3.4539e+56,  1.2301e+56,  1.9078e+56,  1.6897e+56,\n",
       "          -3.9916e+56,  5.3515e+55, -8.0538e+55,  3.2221e+56, -5.6106e+55,\n",
       "          -3.1276e+55, -6.6108e+55, -2.8627e+56, -7.0603e+55,  7.4609e+53,\n",
       "          -1.6967e+56,  2.1130e+56, -2.1613e+55], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 7.7594e+70, -1.5371e+70, -3.3386e+70, -2.1421e+69,  1.2673e+71,\n",
       "           2.9408e+70,  3.9488e+70, -9.2603e+70,  7.1383e+69, -9.7092e+69,\n",
       "           7.4679e+70,  2.9717e+70,  2.8376e+70, -2.6603e+70,  3.1286e+70,\n",
       "          -4.1371e+70,  1.3341e+70,  6.5652e+68,  1.5706e+70,  2.5072e+70,\n",
       "          -2.3074e+70,  4.5595e+70, -4.5505e+70, -1.8041e+70, -1.0551e+70,\n",
       "          -7.9390e+68, -1.1735e+70, -2.3209e+70,  2.3280e+69, -4.5233e+70,\n",
       "           2.3092e+70, -6.6738e+69,  4.0605e+70,  1.1585e+70, -3.8689e+70,\n",
       "          -8.4342e+70,  1.8534e+70,  1.6696e+69,  2.0071e+70,  1.3317e+70,\n",
       "          -2.0976e+70,  4.0276e+70, -2.5109e+70,  7.1043e+69, -5.4971e+70,\n",
       "           8.5193e+70, -1.5794e+70, -1.7076e+70], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-7.1426e+70, -7.2735e+70,  1.0291e+71,  2.3328e+70,  5.4304e+70,\n",
       "           4.1098e+70, -3.1121e+70,  5.1559e+69,  9.7303e+70,  6.4797e+69,\n",
       "          -2.0468e+70,  6.2360e+70,  3.5299e+70,  4.1364e+70,  8.6561e+70,\n",
       "          -1.0403e+71,  4.0671e+70,  1.0410e+71,  4.4671e+70,  5.4253e+70,\n",
       "          -1.5411e+71, -5.5079e+70,  3.9000e+70, -1.0011e+71,  1.0057e+71,\n",
       "           8.3566e+70,  2.4172e+70, -1.5507e+71,  1.5470e+71, -2.4205e+70,\n",
       "           1.0215e+71,  8.7862e+70,  1.0981e+70,  3.1372e+70,  5.2544e+70,\n",
       "          -6.2980e+70, -1.8838e+70,  1.0347e+71,  2.9118e+69,  8.5946e+70,\n",
       "          -1.0195e+70,  8.0754e+70,  7.4854e+70,  8.7168e+70,  1.1027e+71,\n",
       "          -8.1646e+69, -9.6689e+70, -5.5509e+70], dtype=torch.float64,\n",
       "         requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-7.2434e+69,  3.6590e+70],\n",
       "           [-1.1355e+70, -9.9528e+68],\n",
       "           [-1.6962e+70,  1.5917e+71],\n",
       "           ...,\n",
       "           [-2.0137e+70,  1.7350e+71],\n",
       "           [-4.0857e+70,  4.4759e+69],\n",
       "           [-2.7255e+70,  1.3838e+71]],\n",
       "  \n",
       "          [[-9.4717e+70, -1.3655e+70],\n",
       "           [-1.5249e+70,  2.6302e+70],\n",
       "           [-1.1191e+71, -9.9807e+70],\n",
       "           ...,\n",
       "           [-1.1907e+71,  2.8421e+70],\n",
       "           [ 3.2082e+69,  1.7433e+71],\n",
       "           [-1.1247e+71,  8.3929e+70]],\n",
       "  \n",
       "          [[-3.1259e+70,  1.8755e+71],\n",
       "           [ 4.4998e+70,  3.2215e+69],\n",
       "           [-1.1137e+71, -3.9161e+70],\n",
       "           ...,\n",
       "           [-1.5567e+71, -2.3020e+71],\n",
       "           [ 7.3986e+70,  1.0961e+71],\n",
       "           [-7.2433e+70,  1.7810e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 4.9230e+70, -1.2547e+71],\n",
       "           [-1.8420e+71,  4.5070e+70],\n",
       "           [-1.8446e+71,  2.4276e+71],\n",
       "           ...,\n",
       "           [ 1.4836e+71,  1.4583e+71],\n",
       "           [-3.8706e+71,  2.1815e+70],\n",
       "           [-1.7438e+71,  1.6208e+71]],\n",
       "  \n",
       "          [[ 4.2647e+70,  2.7584e+71],\n",
       "           [-6.1014e+70,  2.0534e+70],\n",
       "           [-1.1753e+71,  2.9677e+71],\n",
       "           ...,\n",
       "           [-3.1772e+70,  8.5587e+70],\n",
       "           [-1.2395e+71, -1.6948e+71],\n",
       "           [-3.9063e+70,  3.5280e+70]],\n",
       "  \n",
       "          [[ 2.4823e+69,  2.9334e+70],\n",
       "           [ 7.2310e+70, -1.1915e+71],\n",
       "           [ 1.4587e+71, -5.0235e+71],\n",
       "           ...,\n",
       "           [ 1.7409e+70,  3.4770e+71],\n",
       "           [ 2.3196e+71, -3.3435e+71],\n",
       "           [ 6.0575e+70, -4.7648e+70]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.1810e+56,  8.9205e+55, -7.3192e+55,  1.0700e+56,  1.2219e+56,\n",
       "          -7.2308e+55, -2.5107e+56, -5.4183e+55, -2.6620e+56,  1.1991e+56,\n",
       "           9.0192e+55, -1.6396e+56,  4.5207e+54, -3.1985e+55, -7.0235e+55,\n",
       "           2.7869e+55,  3.7165e+55,  4.6273e+55, -6.8886e+55,  8.3630e+55,\n",
       "           1.0692e+56,  6.3650e+55,  2.1231e+54,  1.0835e+56,  1.1179e+56,\n",
       "          -3.0980e+56,  1.9899e+56,  1.3734e+56, -1.8868e+56,  1.4828e+56,\n",
       "          -2.7297e+56,  5.9420e+55,  9.6556e+54,  4.2968e+55, -1.6075e+56,\n",
       "           1.4771e+55, -6.1157e+55,  1.8506e+55, -5.3231e+54, -3.2691e+54,\n",
       "          -2.1394e+55, -7.5731e+56, -1.8129e+55,  1.5802e+56, -2.3955e+56,\n",
       "          -1.6076e+56,  2.5504e+55, -1.0769e+56,  5.8819e+56, -1.6942e+56,\n",
       "           2.5568e+56,  6.5236e+55,  1.3022e+56,  2.9983e+55, -2.1224e+55,\n",
       "           3.9397e+55, -7.3792e+55,  1.6574e+56,  3.3953e+55,  1.1494e+56,\n",
       "           7.9172e+55, -8.1652e+55,  1.8352e+55,  3.8440e+56],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 9.1355e+67,  9.4280e+70,  3.7856e+70,  5.7453e+70,  1.6063e+71,\n",
       "           3.8536e+70,  2.5250e+69, -7.5201e+70, -5.1091e+70,  4.5851e+70,\n",
       "          -1.5579e+71,  5.3797e+70, -6.4258e+70,  2.0013e+70,  4.3308e+69,\n",
       "           5.9671e+70,  1.7196e+70,  4.3421e+69,  5.6903e+70,  7.0884e+69,\n",
       "          -1.2471e+71,  3.1732e+70,  1.0402e+71,  7.4719e+70,  4.3418e+70,\n",
       "          -1.2534e+71, -8.1284e+70, -1.2825e+71,  1.8226e+70, -6.4445e+69,\n",
       "           4.7714e+70, -3.9434e+70,  6.7449e+70,  5.6598e+70, -8.2665e+70,\n",
       "           7.2012e+70, -2.4564e+69, -8.1268e+70, -6.2258e+70, -4.1145e+70,\n",
       "           7.7552e+70, -7.2921e+70, -1.4038e+70,  7.5158e+70,  1.2820e+71,\n",
       "          -5.3930e+70, -4.4606e+70, -5.0405e+70, -2.0603e+70,  8.2869e+70,\n",
       "          -3.4231e+70,  2.2650e+71, -1.1862e+71, -1.2504e+70, -4.0337e+70,\n",
       "           3.9692e+70, -3.6170e+70, -5.2969e+68, -6.1083e+70, -3.9333e+70,\n",
       "          -4.4204e+70,  3.0412e+70, -2.7316e+70, -1.5268e+70],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.0263e+70,  1.0123e+71,  3.3460e+70,  4.7423e+69,  1.5133e+71,\n",
       "           3.6184e+70,  6.2298e+70, -4.5207e+70, -5.9121e+70,  1.0616e+71,\n",
       "          -6.8859e+70,  1.4114e+71, -3.6333e+70, -1.2887e+69, -4.5345e+70,\n",
       "           6.4164e+70,  2.0320e+70, -2.1193e+70,  7.9278e+70,  3.4397e+70,\n",
       "          -8.7140e+70,  2.9400e+70,  3.2885e+70,  1.1814e+71,  3.4703e+70,\n",
       "          -1.0528e+71, -7.4362e+70, -1.4031e+71, -4.8906e+70,  1.4487e+70,\n",
       "           1.0749e+71, -4.5436e+70,  4.0466e+70,  2.9923e+70, -6.1916e+70,\n",
       "           4.0483e+70,  7.1966e+70, -1.2948e+71, -3.3910e+70, -3.3739e+70,\n",
       "           2.0458e+70, -7.9028e+70, -1.7938e+70,  8.0155e+70,  8.7954e+70,\n",
       "          -6.4198e+70, -1.9035e+70,  1.7118e+69,  2.4687e+70,  7.9079e+70,\n",
       "          -4.2761e+70,  9.5799e+70, -1.2869e+71,  1.8721e+70, -1.7215e+70,\n",
       "           3.3951e+70,  2.2822e+68, -4.2443e+70,  7.3400e+69,  7.1211e+69,\n",
       "          -3.6624e+70,  1.4216e+70,  7.3581e+70, -2.6003e+70],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-6.8929e+70,  2.3431e+70],\n",
       "           [-1.4960e+71, -7.9098e+70],\n",
       "           [ 6.8974e+70,  5.0070e+70],\n",
       "           ...,\n",
       "           [-2.1322e+71,  8.7881e+70],\n",
       "           [-5.8596e+70,  1.3760e+70],\n",
       "           [-2.1702e+71, -9.9546e+70]],\n",
       "  \n",
       "          [[ 2.8936e+71, -1.4896e+71],\n",
       "           [ 8.0591e+70,  8.1098e+70],\n",
       "           [ 2.3624e+70,  2.8777e+70],\n",
       "           ...,\n",
       "           [ 6.2224e+70, -8.1761e+70],\n",
       "           [ 1.1794e+71, -1.5602e+71],\n",
       "           [ 2.3651e+71, -5.1587e+70]],\n",
       "  \n",
       "          [[ 3.0417e+69, -3.2098e+69],\n",
       "           [ 3.9263e+70, -2.8067e+70],\n",
       "           [ 4.2158e+70,  6.8453e+70],\n",
       "           ...,\n",
       "           [ 5.1405e+70,  1.0313e+69],\n",
       "           [-1.4341e+71,  1.1500e+71],\n",
       "           [-8.6948e+70, -5.9550e+69]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 1.5237e+71,  3.3474e+70],\n",
       "           [-5.9653e+70,  9.8091e+70],\n",
       "           [ 1.4137e+71,  2.1853e+71],\n",
       "           ...,\n",
       "           [-1.3145e+71,  1.2306e+70],\n",
       "           [ 2.0162e+71,  2.4884e+70],\n",
       "           [ 1.0087e+71,  1.5770e+71]],\n",
       "  \n",
       "          [[ 1.2425e+69, -1.3626e+71],\n",
       "           [ 5.6128e+70,  2.6846e+71],\n",
       "           [-1.4738e+71, -4.2884e+70],\n",
       "           ...,\n",
       "           [ 9.7565e+70,  7.3825e+70],\n",
       "           [-3.8382e+70,  1.6456e+70],\n",
       "           [ 8.4446e+70,  4.5720e+70]],\n",
       "  \n",
       "          [[ 1.0513e+71, -8.1946e+70],\n",
       "           [ 2.4408e+70,  2.0819e+70],\n",
       "           [-4.4946e+70,  1.3135e+71],\n",
       "           ...,\n",
       "           [ 9.4289e+70, -9.7338e+70],\n",
       "           [ 8.1802e+70,  2.5963e+70],\n",
       "           [ 1.5223e+71,  2.2765e+70]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.4049e+56,  3.6061e+55,  2.4298e+56,  1.7551e+56, -1.0198e+56,\n",
       "          -1.1977e+56,  2.1200e+55, -2.5412e+56, -3.1534e+54,  9.8199e+55,\n",
       "           1.8877e+56,  6.6413e+55, -1.1865e+56,  9.4754e+55,  6.8155e+55,\n",
       "           1.5096e+56, -7.8644e+55, -4.4325e+55, -1.6085e+55, -1.1577e+56,\n",
       "          -9.7969e+55, -1.5358e+56,  6.1489e+55, -2.8758e+55,  8.2922e+55,\n",
       "           1.0840e+55,  1.9544e+56,  6.5659e+55,  1.9251e+56, -6.3289e+55,\n",
       "          -1.8800e+56,  4.4459e+55, -6.6804e+55,  2.1760e+56,  2.3160e+56,\n",
       "           2.8379e+55, -5.1570e+55, -5.6535e+55, -4.8155e+55,  5.0598e+55,\n",
       "           4.7853e+55,  1.6854e+55,  2.0140e+56, -1.3056e+56, -8.7631e+55,\n",
       "          -4.1728e+55, -8.2258e+55,  4.6711e+55,  8.5735e+55, -2.0705e+55,\n",
       "           2.6234e+55,  1.4732e+56, -9.7587e+55, -1.2068e+56,  4.4594e+55,\n",
       "           1.5451e+56, -5.2060e+55,  9.0999e+54,  3.2848e+55, -2.8532e+56,\n",
       "           2.2484e+56, -1.2712e+55, -6.9602e+55,  3.4773e+55],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 8.5531e+70,  2.7347e+70,  1.0467e+71,  1.3251e+70,  4.4425e+70,\n",
       "          -1.8300e+68,  5.4979e+70, -3.3537e+70,  1.4586e+71, -1.1714e+71,\n",
       "           7.5602e+68, -6.6282e+68, -8.2082e+70,  3.9728e+70, -5.5065e+69,\n",
       "          -2.5044e+70,  9.6536e+69,  1.6846e+70,  9.7479e+69, -1.7332e+70,\n",
       "          -4.8354e+69, -6.0369e+70, -1.8237e+70,  1.2150e+70,  5.9042e+69,\n",
       "          -3.1092e+70,  5.4231e+69,  9.9736e+70,  3.6418e+70, -4.0211e+68,\n",
       "           1.0454e+71, -6.2843e+70,  3.5905e+69,  3.0818e+70, -6.4641e+70,\n",
       "           6.0814e+70, -1.4425e+71,  1.8737e+70,  6.6565e+69, -3.7989e+70,\n",
       "          -1.1166e+71,  7.7062e+70, -4.8314e+70,  3.6582e+70,  1.8562e+69,\n",
       "           9.4126e+70,  3.5312e+70,  6.8147e+70,  6.4551e+69, -2.7505e+70,\n",
       "           2.0080e+69, -4.3614e+70, -4.4067e+70, -4.3522e+70, -1.7540e+70,\n",
       "          -3.1221e+70,  3.7068e+70, -2.0354e+70, -4.6815e+70, -2.9364e+70,\n",
       "          -7.5454e+69,  6.5227e+70, -9.5221e+70,  3.3239e+70],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.0078e+71, -3.3816e+70,  1.1234e+70,  1.8487e+70,  6.3431e+70,\n",
       "          -4.0982e+70,  1.2046e+70,  2.0131e+70,  1.0664e+71, -1.6000e+71,\n",
       "          -2.7507e+70,  4.4547e+70, -7.2757e+70,  5.5870e+70,  5.3816e+70,\n",
       "           2.2153e+70,  2.8501e+69,  7.5419e+70,  3.6907e+70, -7.9630e+70,\n",
       "          -4.7657e+69, -3.6845e+70, -4.0181e+70, -5.2201e+69,  4.6132e+70,\n",
       "          -6.6352e+69,  8.9229e+69,  6.2282e+70,  9.4759e+70,  6.6061e+70,\n",
       "           7.4879e+70, -1.0584e+71, -4.1083e+70,  9.2477e+69, -3.3982e+70,\n",
       "           4.2049e+70, -9.6620e+70,  3.9774e+70,  3.1374e+70, -4.1007e+70,\n",
       "          -5.6046e+70,  3.0145e+70, -2.6728e+70, -4.6455e+70, -1.4878e+70,\n",
       "           9.9093e+70,  7.1225e+70,  8.0186e+70,  5.8305e+70, -3.6879e+70,\n",
       "           4.4420e+70, -1.4366e+70, -6.6925e+70,  1.0361e+71,  1.4760e+70,\n",
       "          -1.4681e+70,  3.6242e+69, -6.6932e+70, -3.9153e+70, -1.1943e+70,\n",
       "          -2.8616e+70,  5.5535e+70, -1.0127e+71, -3.1614e+70],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-1.3925e+70,  4.4214e+70],\n",
       "           [ 1.0645e+71,  2.2948e+71],\n",
       "           [ 6.7091e+70, -5.0817e+70],\n",
       "           ...,\n",
       "           [ 9.7946e+70,  8.8893e+70],\n",
       "           [-5.4676e+70,  9.7045e+70],\n",
       "           [ 1.0805e+71,  3.2193e+70]],\n",
       "  \n",
       "          [[-1.6511e+71,  3.9715e+69],\n",
       "           [-1.4698e+71,  5.3688e+71],\n",
       "           [-3.1531e+71, -8.6815e+70],\n",
       "           ...,\n",
       "           [-1.5287e+71, -7.7579e+70],\n",
       "           [-9.0451e+70, -1.0359e+71],\n",
       "           [-1.5016e+71,  1.8026e+71]],\n",
       "  \n",
       "          [[ 4.8785e+70,  8.2336e+70],\n",
       "           [ 2.5075e+71,  4.5906e+70],\n",
       "           [ 1.7712e+71, -2.1571e+71],\n",
       "           ...,\n",
       "           [ 1.0485e+71,  2.3406e+70],\n",
       "           [-7.4339e+69, -9.4964e+70],\n",
       "           [ 1.0394e+71, -8.6720e+70]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-7.4270e+70,  1.6726e+70],\n",
       "           [-4.5302e+70, -1.2611e+71],\n",
       "           [-5.0027e+70,  8.4387e+70],\n",
       "           ...,\n",
       "           [ 3.2184e+70, -5.7343e+70],\n",
       "           [-6.7432e+70, -2.5408e+70],\n",
       "           [ 8.8044e+70, -1.4163e+71]],\n",
       "  \n",
       "          [[-5.5127e+70, -1.1702e+70],\n",
       "           [-6.7769e+70, -1.8239e+71],\n",
       "           [ 1.0036e+70,  4.1267e+70],\n",
       "           ...,\n",
       "           [-2.0608e+70, -1.1281e+71],\n",
       "           [-8.3707e+70, -9.8644e+70],\n",
       "           [-7.5665e+70, -1.3707e+71]],\n",
       "  \n",
       "          [[-1.1160e+71,  1.7094e+70],\n",
       "           [-1.5455e+70,  1.3549e+69],\n",
       "           [-2.0280e+71,  3.7488e+71],\n",
       "           ...,\n",
       "           [ 1.9014e+71,  4.1435e+70],\n",
       "           [ 5.7588e+70, -4.8382e+70],\n",
       "           [ 1.4334e+70,  7.8970e+70]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 6.4177e+55, -7.9823e+55,  1.5374e+55,  6.4636e+55, -2.1288e+56,\n",
       "          -1.9349e+56,  8.3278e+55,  9.6539e+55,  1.0390e+56,  5.1120e+55,\n",
       "          -2.0159e+56, -4.7936e+55, -5.0747e+55, -1.0794e+56,  1.9065e+55,\n",
       "           5.7074e+55,  1.9184e+56,  1.8603e+56, -1.4865e+56, -1.2048e+56,\n",
       "           3.9641e+55, -7.5718e+55,  1.1521e+56,  1.5397e+56, -4.2746e+54,\n",
       "          -8.5911e+55, -2.9216e+55,  2.1929e+53, -2.2658e+55,  3.4987e+55,\n",
       "          -1.0629e+56, -5.3071e+55, -2.8597e+55, -2.5026e+55, -7.4510e+55,\n",
       "           1.2630e+56, -3.6983e+55, -2.1416e+56,  4.6773e+55, -8.7224e+55,\n",
       "          -1.3442e+56, -1.0992e+56, -6.2026e+55,  2.4180e+55,  2.6482e+55,\n",
       "          -7.8461e+55,  1.0589e+56, -8.7251e+55, -2.1547e+56, -2.5380e+55,\n",
       "          -1.5400e+56, -2.4467e+55,  4.5359e+54,  1.0992e+56,  3.6198e+56,\n",
       "          -8.8903e+55, -5.3616e+55,  1.0207e+56,  1.9727e+55,  7.5691e+55,\n",
       "           2.3370e+55, -4.0573e+55,  9.7838e+55, -6.5690e+54],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 6.4818e+70,  4.6622e+69, -4.5283e+70, -1.8123e+70, -5.5768e+70,\n",
       "          -3.5085e+69, -1.3607e+70, -1.6201e+70,  3.9915e+70, -2.1024e+70,\n",
       "          -6.5553e+69,  5.0028e+70,  2.4112e+69, -1.7067e+69, -4.4090e+69,\n",
       "          -2.5056e+70, -1.3977e+70,  3.2656e+70, -1.2928e+70, -1.5820e+70,\n",
       "          -2.4906e+70, -2.6762e+70, -4.8288e+70, -6.0902e+70, -2.7029e+70,\n",
       "          -6.8486e+70,  1.0472e+70,  6.0404e+70,  5.2104e+70, -3.2030e+69,\n",
       "          -3.5669e+70, -2.4984e+70,  3.7049e+70,  1.1151e+70, -8.6754e+69,\n",
       "           6.7823e+69, -2.1899e+70,  9.9480e+69, -4.6381e+70, -3.3791e+70,\n",
       "           9.7489e+69,  5.5578e+69,  1.9984e+70,  9.8004e+69,  1.2365e+70,\n",
       "           9.8377e+70,  4.4792e+69,  3.1262e+70,  1.4998e+69, -6.2398e+70,\n",
       "          -2.4801e+70, -4.8604e+69, -2.0529e+68, -2.1588e+70,  8.0175e+70,\n",
       "           2.0523e+71,  4.9325e+70, -2.4278e+70,  2.6726e+69, -3.2463e+70,\n",
       "          -7.0695e+69,  8.4059e+69, -7.9237e+69, -1.1369e+71],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 1.1040e+71,  6.9708e+70, -6.6063e+70, -1.8908e+70,  1.1082e+69,\n",
       "           8.6991e+68,  1.1388e+70, -5.5796e+70, -2.2031e+70,  6.1008e+70,\n",
       "          -3.3524e+70, -4.5219e+70,  3.2252e+70, -2.4051e+70,  2.7024e+70,\n",
       "           1.0520e+69,  1.4519e+70,  9.5051e+70,  1.1439e+71,  6.1845e+70,\n",
       "          -8.9132e+69,  4.5915e+70,  5.0974e+70,  1.5571e+70, -8.4494e+70,\n",
       "          -1.6507e+70,  4.6155e+70, -6.0566e+70, -4.8330e+69, -3.7934e+70,\n",
       "          -4.7218e+69,  2.5498e+70,  1.7191e+70, -1.2563e+70, -1.0964e+70,\n",
       "          -2.1194e+70,  1.9069e+70, -2.1331e+70,  3.8608e+70, -2.2203e+70,\n",
       "          -9.0909e+69,  3.6906e+70, -2.6948e+70,  6.0331e+70, -4.1720e+69,\n",
       "          -1.4342e+71, -2.0513e+70,  2.5789e+70, -3.7326e+70, -1.2971e+70,\n",
       "          -5.2431e+70,  2.6496e+70,  4.7908e+70, -1.1938e+70,  3.4570e+70,\n",
       "           6.3890e+69,  1.1526e+70, -1.1634e+70,  1.3586e+70, -1.0205e+70,\n",
       "          -5.3887e+69,  8.3549e+69,  6.4686e+70, -1.5880e+71],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[[-6.5058e+70,  1.2355e+70],\n",
       "           [-1.8747e+70, -3.6438e+70],\n",
       "           [-8.3559e+69,  8.0850e+69],\n",
       "           ...,\n",
       "           [-3.2951e+70, -6.3449e+70],\n",
       "           [-6.5580e+70,  4.4547e+70],\n",
       "           [-1.9915e+70,  1.2649e+71]],\n",
       "  \n",
       "          [[ 4.4885e+70, -1.1166e+71],\n",
       "           [-5.0301e+70,  1.6555e+70],\n",
       "           [-2.1339e+70, -1.7263e+71],\n",
       "           ...,\n",
       "           [ 3.3824e+70, -9.2132e+70],\n",
       "           [ 1.1613e+70,  8.5336e+69],\n",
       "           [-5.2379e+70, -6.3071e+70]],\n",
       "  \n",
       "          [[-4.8132e+70,  7.5166e+70],\n",
       "           [ 1.9890e+70,  1.3477e+71],\n",
       "           [ 2.3701e+70, -1.7031e+71],\n",
       "           ...,\n",
       "           [-3.1685e+69,  1.4766e+71],\n",
       "           [-3.9319e+70, -2.5326e+70],\n",
       "           [-2.3473e+70, -1.0244e+71]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-7.7342e+70, -9.1711e+70],\n",
       "           [-3.7230e+70, -3.2189e+69],\n",
       "           [ 5.5490e+70,  5.1031e+70],\n",
       "           ...,\n",
       "           [-1.9156e+70,  4.7193e+70],\n",
       "           [ 7.1607e+69, -1.7851e+71],\n",
       "           [ 3.1756e+70,  1.4423e+70]],\n",
       "  \n",
       "          [[ 6.3324e+70,  5.5574e+70],\n",
       "           [-4.0904e+70, -1.6807e+71],\n",
       "           [ 1.1447e+70,  1.1581e+71],\n",
       "           ...,\n",
       "           [ 3.4251e+70, -4.9757e+70],\n",
       "           [ 7.5117e+70,  1.2565e+71],\n",
       "           [ 6.4541e+70, -1.5989e+71]],\n",
       "  \n",
       "          [[ 1.1909e+71,  1.1161e+71],\n",
       "           [-9.7083e+70, -1.2102e+71],\n",
       "           [ 4.0753e+70, -2.5274e+70],\n",
       "           ...,\n",
       "           [-3.5575e+70, -6.1330e+70],\n",
       "           [-2.2573e+70, -2.1624e+70],\n",
       "           [ 1.0322e+71, -7.8026e+69]]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 8.6577e+55,  1.1943e+56, -1.8577e+56, -1.0859e+56, -1.9474e+56,\n",
       "           3.0955e+54,  6.5442e+55,  1.3560e+56,  8.7540e+55,  1.7630e+56,\n",
       "           3.0971e+55,  1.4423e+56,  8.7513e+55, -1.6464e+56,  5.3955e+55,\n",
       "           9.4488e+55,  4.7222e+55,  6.2876e+55,  1.6165e+56,  3.3023e+55,\n",
       "           1.3414e+55, -2.9681e+55,  1.3073e+56, -2.5218e+55,  8.7679e+55,\n",
       "           3.3963e+54,  1.4719e+55,  7.8733e+55,  1.2770e+56, -1.1674e+56,\n",
       "           2.7958e+56, -1.2980e+55, -1.1202e+56,  3.0935e+55, -6.5613e+54,\n",
       "          -1.0191e+55,  2.6238e+56,  7.6519e+54,  9.0891e+55, -3.1753e+56,\n",
       "          -4.4379e+55, -2.4742e+56,  1.5053e+56,  5.5186e+55, -5.4184e+55,\n",
       "           1.6204e+56,  2.2589e+56,  2.0439e+56,  6.6086e+55, -2.7636e+56,\n",
       "           8.7423e+55,  6.5598e+55, -9.7797e+55, -5.6028e+55, -9.1066e+54,\n",
       "           1.1105e+54, -1.7357e+56,  1.2171e+56, -2.6930e+56, -2.2156e+55,\n",
       "           8.4163e+55,  2.4968e+56,  6.3924e+55,  3.9479e+55],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 2.3590e+70,  7.9141e+69,  2.7928e+69, -1.5862e+69, -4.1460e+69,\n",
       "          -3.9405e+69, -8.9414e+69, -2.0811e+69, -9.9958e+69,  1.0474e+70,\n",
       "           2.1153e+70,  2.6863e+70,  4.1111e+69, -6.3754e+69,  3.7159e+68,\n",
       "          -9.3814e+69, -8.8119e+69, -3.4374e+69,  9.0962e+69, -3.6020e+69,\n",
       "          -1.4321e+70, -2.1881e+68, -4.5395e+69, -3.2348e+69, -7.1633e+69,\n",
       "           5.2742e+69, -1.6596e+70, -3.7758e+69, -1.7683e+70,  1.5598e+69,\n",
       "          -1.9077e+70, -8.1392e+69, -2.4777e+70,  2.0689e+70, -7.4331e+68,\n",
       "           1.8701e+69, -6.4194e+69,  4.7346e+70,  4.6356e+69,  2.4545e+69,\n",
       "          -1.4028e+70,  1.2616e+69,  1.8638e+70,  1.5304e+70, -3.6293e+68,\n",
       "          -3.9700e+70, -7.0726e+68, -1.0919e+70, -4.6379e+69,  1.9952e+70,\n",
       "           3.6251e+70,  7.2094e+69,  1.2383e+70, -2.2067e+69,  1.5484e+70,\n",
       "           1.0569e+70,  1.8485e+70, -5.8521e+69,  1.7927e+70,  1.0794e+70,\n",
       "           1.7777e+69,  1.1590e+70,  7.4960e+69, -9.0215e+69],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 2.0922e+70,  1.6941e+70,  9.8531e+69,  2.3331e+69, -3.0373e+68,\n",
       "           1.5792e+70, -3.3872e+69,  8.2776e+68, -8.5759e+69,  1.0016e+70,\n",
       "           1.4955e+70,  1.7629e+70, -1.0696e+70,  6.9734e+68,  1.3233e+69,\n",
       "           9.3291e+69, -1.4036e+68, -1.6252e+70,  1.0343e+70,  4.8835e+69,\n",
       "          -2.9759e+70,  8.1423e+69,  4.8326e+69, -4.1771e+69, -1.0614e+68,\n",
       "          -1.1845e+69, -1.5825e+70,  4.0382e+68, -1.6455e+70, -2.9033e+69,\n",
       "          -8.7192e+69,  5.1296e+69, -2.3704e+70,  2.3792e+70, -3.0068e+69,\n",
       "          -4.9049e+69, -1.6671e+70,  3.9335e+69,  1.1771e+70,  5.5649e+68,\n",
       "          -2.7690e+70,  6.8359e+69,  8.8216e+69,  1.9501e+70, -1.7945e+70,\n",
       "          -3.4154e+70, -3.0979e+69, -1.0368e+70,  4.0855e+68,  8.0758e+69,\n",
       "           2.1383e+70, -1.0095e+70,  1.5893e+70,  2.4934e+69,  1.5146e+70,\n",
       "           6.3302e+69,  1.8811e+70,  6.6034e+69,  8.1919e+69,  3.6004e+70,\n",
       "          -7.1015e+69,  1.1653e+70,  1.3609e+70, -1.6650e+70],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 5.5145e+69, -4.2974e+70,  7.2932e+69,  5.8928e+70,  2.4790e+70,\n",
       "           4.2866e+70,  5.2120e+69, -4.9623e+69, -2.4406e+69, -5.0590e+70,\n",
       "          -1.5745e+71, -1.1777e+69, -5.5054e+69,  5.5786e+69,  2.2373e+70,\n",
       "          -3.0307e+70,  5.7671e+70, -5.9995e+69, -8.2181e+70, -1.1815e+70,\n",
       "          -7.1829e+69,  1.9438e+70,  2.3558e+70, -5.9364e+69,  2.6182e+70,\n",
       "          -6.1066e+70, -1.6714e+70,  7.4840e+70,  4.2598e+70, -4.7782e+69,\n",
       "           2.1392e+70,  1.3299e+70, -3.4649e+70, -5.4729e+70,  8.3465e+68,\n",
       "           4.3166e+70,  3.7228e+70,  3.0751e+70, -1.0425e+70,  1.9661e+70,\n",
       "           7.6137e+70,  1.2880e+70,  3.7600e+70, -8.4759e+70, -3.7035e+70,\n",
       "           3.1998e+70, -3.9952e+70,  1.5008e+70,  6.3173e+70, -3.3344e+70,\n",
       "          -1.4565e+69, -1.3673e+70, -1.3867e+70,  1.3451e+70,  2.6907e+70,\n",
       "          -3.0143e+70, -2.8863e+70,  2.5781e+69,  3.4957e+70, -7.5149e+70,\n",
       "           1.8898e+70,  5.0678e+69,  1.5229e+70,  2.9909e+70],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-6.3502e+70,  2.7211e+70,  2.4303e+70,  2.6062e+70,  1.2230e+70,\n",
       "          -5.2676e+70, -4.7323e+70,  3.0332e+70, -4.0103e+70, -2.4966e+70,\n",
       "          -1.3255e+69, -4.0705e+69, -1.8309e+70,  1.3817e+70,  2.8975e+69,\n",
       "           4.4314e+70, -1.4817e+70,  3.3819e+69, -2.5410e+70,  1.2884e+70,\n",
       "          -1.5836e+69, -1.1353e+70, -1.3236e+70,  1.4477e+70, -8.2231e+69,\n",
       "           2.9914e+70, -2.9321e+69, -3.6344e+70, -2.8895e+70, -1.6123e+70,\n",
       "          -1.5907e+70,  2.6763e+70,  6.6170e+69,  3.3909e+69,  5.1571e+69,\n",
       "           2.4413e+70, -2.1374e+69,  4.6156e+69,  2.1480e+70,  1.2750e+70,\n",
       "          -1.2698e+70,  3.1261e+69, -4.0667e+69,  7.2890e+69, -6.3683e+69,\n",
       "           2.9110e+70,  1.2459e+70,  4.1165e+70,  1.2112e+70,  1.3766e+70,\n",
       "          -1.5000e+68, -1.7480e+69, -6.6181e+70,  1.0874e+70, -1.8883e+70,\n",
       "           1.6517e+70, -1.3172e+70,  2.9125e+69,  1.2528e+70, -9.6319e+69,\n",
       "           1.9091e+70, -1.1784e+70, -2.1676e+70, -1.7949e+70],\n",
       "         dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 9.2860e+68,  2.5382e+70, -1.1206e+70,  ..., -6.4427e+70,\n",
       "           -2.1170e+68, -1.4817e+70],\n",
       "          [-1.2561e+71,  2.3901e+71,  3.0404e+70,  ..., -7.9503e+70,\n",
       "            9.1705e+70, -2.6374e+70],\n",
       "          [-7.1026e+70,  4.9080e+70,  7.5432e+70,  ...,  3.3319e+70,\n",
       "           -1.2539e+71, -8.0886e+70],\n",
       "          ...,\n",
       "          [-2.1564e+71, -2.9841e+70,  8.1304e+70,  ..., -8.9747e+70,\n",
       "           -7.0060e+70, -7.5511e+70],\n",
       "          [ 4.4664e+70, -4.6417e+69,  3.6590e+70,  ...,  7.7409e+69,\n",
       "            6.6071e+70,  4.6900e+70],\n",
       "          [-1.4433e+71,  5.0934e+70,  1.3976e+71,  ..., -1.7704e+71,\n",
       "            2.8577e+70,  1.3722e+71]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 6.9061e+69, -7.5178e+70, -6.1062e+70, -2.5620e+70, -2.7808e+70,\n",
       "           3.0043e+70, -7.8530e+69, -3.7676e+70,  3.9543e+70, -2.2262e+70,\n",
       "           5.1159e+70,  1.6296e+70,  4.3972e+70,  9.4140e+69,  5.6348e+70,\n",
       "           9.9107e+70,  1.7970e+70,  6.4298e+70,  1.7698e+70,  3.2860e+70,\n",
       "          -1.2839e+70,  1.5159e+70,  1.5114e+70,  2.5058e+70,  5.8538e+69,\n",
       "           9.3305e+69,  7.1739e+70,  2.0314e+70,  6.9691e+69,  7.2681e+70,\n",
       "           2.8401e+70,  5.2839e+70], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.0780e+70, -8.4595e+70, -1.1749e+71, -1.9876e+71, -1.6321e+71,\n",
       "          -3.4882e+70, -2.6891e+71, -1.7692e+70, -1.0390e+71, -2.1403e+70,\n",
       "          -2.1583e+71, -3.4268e+71, -2.5555e+70, -2.4663e+71, -2.8165e+71,\n",
       "          -2.3413e+71, -6.1294e+69, -4.3916e+70, -1.6337e+71, -9.0886e+70,\n",
       "          -1.9202e+71, -2.7972e+71,  2.3075e+68, -1.1798e+71, -1.3557e+71,\n",
       "          -4.6471e+70, -1.7785e+71, -3.4105e+70, -2.1205e+71, -3.6331e+71,\n",
       "          -4.9815e+70, -1.3347e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.0257e+71,  5.3188e+70,  4.5087e+70,  2.6548e+71,  1.2301e+71,\n",
       "           8.0967e+69,  3.3074e+70,  1.6248e+70, -2.3134e+71, -2.6193e+71,\n",
       "           1.4327e+71,  3.4065e+71,  5.6514e+70, -3.5961e+71, -2.3677e+71,\n",
       "           1.6193e+71,  8.5780e+68,  1.5027e+71,  1.3229e+71, -1.5478e+71,\n",
       "           4.6500e+70,  2.2991e+71, -1.2173e+71,  8.4062e+70,  3.1193e+71,\n",
       "           5.5406e+70, -4.7016e+70,  5.4388e+70,  2.6543e+71,  2.1648e+71,\n",
       "           8.5124e+70,  1.6715e+71], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.3965e+71, -2.7692e+71, -3.6929e+71, -6.1616e+71, -4.1140e+71,\n",
       "           -4.5737e+69, -8.0305e+71,  6.2216e+70,  3.8959e+71,  2.3617e+71,\n",
       "           -7.2746e+71, -4.3494e+71, -3.6181e+70,  7.7314e+71, -6.6135e+70,\n",
       "           -7.9341e+71,  2.2890e+70, -5.6128e+71,  1.8198e+71,  3.8816e+71,\n",
       "           -6.6880e+71, -5.9032e+71, -4.9069e+70, -3.5657e+71, -6.1441e+71,\n",
       "           -6.4610e+70,  8.0769e+71, -1.8247e+70, -7.0419e+71, -1.6241e+71,\n",
       "           -7.3504e+70, -5.3321e+71],\n",
       "          [ 2.1891e+70,  2.3043e+71,  4.1887e+71, -4.1897e+70,  1.7632e+71,\n",
       "            1.3620e+70,  8.8251e+71, -8.9843e+70,  2.5036e+71,  4.7157e+71,\n",
       "            4.2433e+71, -4.2240e+71, -1.1893e+71,  1.7804e+71,  8.2440e+71,\n",
       "            4.1921e+71,  1.9496e+70,  3.0496e+71, -5.0181e+71,  5.4838e+70,\n",
       "            7.2661e+71,  4.0452e+70,  4.3951e+71,  1.7122e+71, -1.1099e+71,\n",
       "           -6.4253e+70, -8.8066e+71, -1.1518e+70,  1.2926e+71, -5.1120e+71,\n",
       "           -8.6700e+70,  1.3262e+71],\n",
       "          [-2.6155e+71,  4.6490e+70, -4.9576e+70,  6.5806e+71,  2.3508e+71,\n",
       "           -9.0461e+69, -7.9466e+70,  2.7627e+70, -6.3995e+71, -7.0773e+71,\n",
       "            3.0313e+71,  8.5734e+71,  1.5511e+71, -9.5117e+71, -7.5827e+71,\n",
       "            3.7420e+71, -4.2386e+70,  2.5632e+71,  3.1984e+71, -4.4300e+71,\n",
       "           -5.7810e+70,  5.4987e+71, -3.9044e+71,  1.8534e+71,  7.2539e+71,\n",
       "            1.2886e+71,  7.2971e+70,  2.9765e+70,  5.7492e+71,  6.7361e+71,\n",
       "            1.6020e+71,  4.0058e+71]], dtype=torch.float64, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-1.5533e+71, -8.9578e+69,  1.6429e+71], dtype=torch.float64,\n",
       "         requires_grad=True)],\n",
       " 'lr': 1.05e-06,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0,\n",
       " 'amsgrad': False,\n",
       " 'maximize': False,\n",
       " 'foreach': None,\n",
       " 'capturable': False,\n",
       " 'differentiable': False,\n",
       " 'fused': None}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'param_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39m# Update the lr for the next step and store\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Aumentar a taxa de aprendizagem exponencialmente\u001b[39;00m\n\u001b[0;32m     39\u001b[0m lr \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.05\u001b[39m\n\u001b[1;32m---> 40\u001b[0m optimizer\u001b[39m.\u001b[39;49mparam_group[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m lr\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'param_group'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch.optim as optim\n",
    "model =Torch.Cnn\n",
    "lr = 1e-6\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = Torch.loss_fn\n",
    "\n",
    "\n",
    "losses = []\n",
    "log_lrs = []\n",
    "\n",
    "epochs =10\n",
    "model.double()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\" Epoch: {epoch}\\n---------\")\n",
    "    for batch, (inputs, target) in enumerate(train_dataloader):\n",
    "\n",
    "        inputs = inputs.to('cpu').double()\n",
    "        inputs = inputs.unsqueeze(2)\n",
    "        # fazendo as previsões\n",
    "        output = model(inputs.double())\n",
    "\n",
    "        # calculando a perda\n",
    "        loss = loss_fn(output, target.long())\n",
    "\n",
    "        best_loss = loss.item()\n",
    "        # Store the values\n",
    "        if lr > 0 :\n",
    "            losses.append(loss.item())\n",
    "            log_lrs.append(math.log10(lr))\n",
    "        else:\n",
    "            pass\n",
    "        # Do the backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update the lr for the next step and store\n",
    "        # Aumentar a taxa de aprendizagem exponencialmente\n",
    "        lr *= 1.05\n",
    "        optimizer.param_group[0  ]['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(log_lrs, losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Rate Finder')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m math\u001b[39m.\u001b[39;49mlog10(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "math.log10(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "lrs = []\n",
    "for lr in log_lrs:\n",
    "    if lr > 0:\n",
    "        lrs.append(math.log10(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.8646131412461038,\n",
       " -1.4578309752178644,\n",
       " -1.2515282985032574,\n",
       " -1.1122370815163471,\n",
       " -1.0069378716703796,\n",
       " -0.9222525255350779,\n",
       " -0.8514165108066893,\n",
       " -0.7905303323532206,\n",
       " -0.7371400004962164,\n",
       " -0.6896005277313332,\n",
       " -0.6467552761037594,\n",
       " -0.6077599433883797,\n",
       " -0.5719793351003387,\n",
       " -0.5389235470786153,\n",
       " -0.5082067770951068,\n",
       " -0.47951977105591026,\n",
       " -0.45261082234828914,\n",
       " -0.42727232368398355,\n",
       " -0.40333103138665416,\n",
       " -0.3806408763955414,\n",
       " -0.35907756215467795,\n",
       " -0.33853444155916473,\n",
       " -0.3189193259200089,\n",
       " -0.3001519840256547,\n",
       " -0.2821621596113391,\n",
       " -0.2648879834030811,\n",
       " -0.2482746890961745,\n",
       " -0.2322735660266937,\n",
       " -0.2168410980347567,\n",
       " -0.20193825015868344,\n",
       " -0.18752987371457505,\n",
       " -0.17358420693911436,\n",
       " -0.16007245334690962,\n",
       " -0.14696842372584784,\n",
       " -0.13424823058160978,\n",
       " -0.12189002607240623,\n",
       " -0.10987377621103034,\n",
       " -0.09818106547322424,\n",
       " -0.08679492702747293,\n",
       " -0.07569969465739948,\n",
       " -0.0648808731333184,\n",
       " -0.054325024341554125,\n",
       " -0.04401966692734127,\n",
       " -0.033953187571375554,\n",
       " -0.024114762318294226,\n",
       " -0.014494286620709926,\n",
       " -0.005082312965216266,\n",
       " 0.004130004884849438,\n",
       " 0.013150961854719454,\n",
       " 0.02198834643889528,\n",
       " 0.030649481105778698,\n",
       " 0.039141258751467664,\n",
       " 0.04747017565742075,\n",
       " 0.05564236134678983,\n",
       " 0.06366360568316472,\n",
       " 0.07153938351183145,\n",
       " 0.07927487710621771,\n",
       " 0.08687499665001894,\n",
       " 0.0943443989577415,\n",
       " 0.1016875046124007,\n",
       " 0.10890851367830452,\n",
       " 0.11601142012876986,\n",
       " 0.1230000251128639,\n",
       " 0.12987794917150228,\n",
       " 0.1366486435011955,\n",
       " 0.1433154003531696,\n",
       " 0.149881362646304,\n",
       " 0.1563495328641472,\n",
       " 0.1627227812990554,\n",
       " 0.16900385370011387,\n",
       " 0.17519537837584698,\n",
       " 0.1812998727977025,\n",
       " 0.18731974974583376,\n",
       " 0.1932573230347295,\n",
       " 0.1991148128526946,\n",
       " 0.20489435074601767,\n",
       " 0.2105979842758264,\n",
       " 0.21622768137308998,\n",
       " 0.2217853344149479,\n",
       " 0.227272764043493,\n",
       " 0.2326917227462919,\n",
       " 0.2380438982162626,\n",
       " 0.24333091650702582,\n",
       " 0.24855434499849163,\n",
       " 0.2537156951862137,\n",
       " 0.2588164253069302,\n",
       " 0.26385794281170344,\n",
       " 0.2688416066971504,\n",
       " 0.273768729704426,\n",
       " 0.27864058039486006,\n",
       " 0.283458385110459,\n",
       " 0.2882233298268516,\n",
       " 0.2929365619056833,\n",
       " 0.2975991917529363,\n",
       " 0.30221229438917147,\n",
       " 0.30677691093724696,\n",
       " 0.3112940500326637,\n",
       " 0.31576468916131656,\n",
       " 0.32018977592909054,\n",
       " 0.32457022926742507,\n",
       " 0.32890694057868497,\n",
       " 0.3332007748249079,\n",
       " 0.3374525715632539,\n",
       " 0.34166314593125996,\n",
       " 0.3458332895847886,\n",
       " 0.3499637715913722,\n",
       " 0.35405533928147465,\n",
       " 0.3581087190600247,\n",
       " 0.3621246171804285,\n",
       " 0.3661037204831215,\n",
       " 0.3700466971005926,\n",
       " 0.37395419713069133,\n",
       " 0.3778268532799124,\n",
       " 0.38166528147825357,\n",
       " 0.38547008146713774,\n",
       " 0.38924183736180507,\n",
       " 0.392981118189493,\n",
       " 0.3966884784046446,\n",
       " 0.40036445838231244,\n",
       " 0.4040095848908547,\n",
       " 0.40762437154495995,\n",
       " 0.41120931923997206,\n",
       " 0.4147649165684366,\n",
       " 0.41829164021973336,\n",
       " 0.42178995536361225,\n",
       " 0.42526031601840647,\n",
       " 0.42870316540464853,\n",
       " 0.4321189362847811,\n",
       " 0.4355080512896123,\n",
       " 0.4388709232321304,\n",
       " 0.4422079554092634,\n",
       " 0.44551954189213205,\n",
       " 0.44880606780532073,\n",
       " 0.45206790959566084,\n",
       " 0.4553054352909946,\n",
       " 0.4585190047493659,\n",
       " 0.4617089698990586,\n",
       " 0.4648756749698835,\n",
       " 0.46801945671609413,\n",
       " 0.4711406446312914,\n",
       " 0.47423956115566207,\n",
       " 0.477316521875874,\n",
       " 0.4803718357179413,\n",
       " 0.4834058051333518,\n",
       " 0.48641872627873817,\n",
       " 0.48941088918936004,\n",
       " 0.4923825779466496,\n",
       " 0.49533407084006514,\n",
       " 0.49826564052348066,\n",
       " 0.5011775541663331,\n",
       " 0.5040700735997362,\n",
       " 0.5069434554577598,\n",
       " 0.5097979513140671,\n",
       " 0.5126338078140906,\n",
       " 0.5154512668029193,\n",
       " 0.5182505654490668,\n",
       " 0.5210319363642728,\n",
       " 0.523795607719496,\n",
       " 0.5265418033572371,\n",
       " 0.5292707429003339,\n",
       " 0.5319826418573599,\n",
       " 0.5346777117247508,\n",
       " 0.5373561600857844,\n",
       " 0.5400181907065242,\n",
       " 0.5426640036288425,\n",
       " 0.5452937952606255,\n",
       " 0.547907758463265,\n",
       " 0.5505060826365316,\n",
       " 0.553088953800925,\n",
       " 0.5556565546775897,\n",
       " 0.5582090647658813,\n",
       " 0.5607466604186683,\n",
       " 0.5632695149154452,\n",
       " 0.5657777985333353,\n",
       " 0.5682716786160539,\n",
       " 0.5707513196409035,\n",
       " 0.5732168832838671,\n",
       " 0.5756685284828635,\n",
       " 0.5781064114992283,\n",
       " 0.5805306859774779,\n",
       " 0.5829415030034155,\n",
       " 0.5853390111606328,\n",
       " 0.58772335658546,\n",
       " 0.5900946830204175,\n",
       " 0.592453131866214,\n",
       " 0.5947988422323418,\n",
       " 0.5971319509863127,\n",
       " 0.5994525928015781,\n",
       " 0.6017609002041759,\n",
       " 0.6040570036181444,\n",
       " 0.606341031409741,\n",
       " 0.6086131099305063,\n",
       " 0.6108733635592053,\n",
       " 0.6131219147426838,\n",
       " 0.6153588840356732,\n",
       " 0.617584390139574,\n",
       " 0.6197985499402521,\n",
       " 0.6220014785448756,\n",
       " 0.6241932893178219,\n",
       " 0.6263740939156841,\n",
       " 0.6285440023214021,\n",
       " 0.6307031228775453,\n",
       " 0.6328515623187732,\n",
       " 0.634989425803495,\n",
       " 0.6371168169447559,\n",
       " 0.6392338378403684,\n",
       " 0.6413405891023153,\n",
       " 0.6434371698854408,\n",
       " 0.6455236779154532,\n",
       " 0.6476002095162585,\n",
       " 0.6496668596366432,\n",
       " 0.651723721876325,\n",
       " 0.6537708885113902,\n",
       " 0.6558084505191338,\n",
       " 0.6578364976023199,\n",
       " 0.6598551182128779,\n",
       " 0.6618643995750514,\n",
       " 0.6638644277080129,\n",
       " 0.6658552874479611,\n",
       " 0.6678370624697134,\n",
       " 0.6698098353078087,\n",
       " 0.6717736873771317,\n",
       " 0.6737286989930751,\n",
       " 0.675674949391248,\n",
       " 0.6776125167467455,\n",
       " 0.6795414781929906,\n",
       " 0.6814619098401593,\n",
       " 0.6833738867931998,\n",
       " 0.685277483169457,\n",
       " 0.6871727721159129,\n",
       " 0.6890598258260514,\n",
       " 0.6909387155563594,\n",
       " 0.6928095116424721,\n",
       " 0.694672283514971,\n",
       " 0.6965270997148465,\n",
       " 0.6983740279086302,\n",
       " 0.7002131349032075,\n",
       " 0.7020444866603172,\n",
       " 0.7038681483107476,\n",
       " 0.7056841841682354,\n",
       " 0.7074926577430747,\n",
       " 0.709293631755444,\n",
       " 0.7110871681484596,\n",
       " 0.7128733281009576,\n",
       " 0.7146521720400167,\n",
       " 0.7164237596532246,\n",
       " 0.7181881499006947,\n",
       " 0.719945401026841,\n",
       " 0.7216955705719146,\n",
       " 0.7234387153833087,\n",
       " 0.7251748916266388,\n",
       " 0.726904154796601,\n",
       " 0.7286265597276155,\n",
       " 0.7303421606042598,\n",
       " 0.7320510109714972,\n",
       " 0.7337531637447033,\n",
       " 0.7354486712194991,\n",
       " 0.7371375850813908,\n",
       " 0.7388199564152238,\n",
       " 0.7404958357144542,\n",
       " 0.7421652728902425,\n",
       " 0.7438283172803721,\n",
       " 0.7454850176579992,\n",
       " 0.7471354222402349,\n",
       " 0.7487795786965656,\n",
       " 0.7504175341571155,\n",
       " 0.7520493352207515,\n",
       " 0.7536750279630391,\n",
       " 0.7552946579440482,\n",
       " 0.756908270216014,\n",
       " 0.7585159093308574,\n",
       " 0.7601176193475652,\n",
       " 0.7617134438394352,\n",
       " 0.7633034259011892,\n",
       " 0.7648876081559557,\n",
       " 0.7664660327621258,\n",
       " 0.7680387414200853,\n",
       " 0.7696057753788248,\n",
       " 0.7711671754424312,\n",
       " 0.7727229819764633,\n",
       " 0.774273234914213,\n",
       " 0.7758179737628556,\n",
       " 0.7773572376094909,\n",
       " 0.7788910651270777,\n",
       " 0.7804194945802636,\n",
       " 0.7819425638311133,\n",
       " 0.7834603103447355,\n",
       " 0.7849727711948138,\n",
       " 0.7864799830690393,\n",
       " 0.787981982274451,\n",
       " 0.7894788047426837,\n",
       " 0.7909704860351251,\n",
       " 0.792457061347986,\n",
       " 0.7939385655172823,\n",
       " 0.795415033023734,\n",
       " 0.7968864979975798,\n",
       " 0.7983529942233119,\n",
       " 0.7998145551443292,\n",
       " 0.8012712138675144,\n",
       " 0.8027230031677334,\n",
       " 0.8041699554922598,\n",
       " 0.8056121029651266,\n",
       " 0.8070494773914059,\n",
       " 0.8084821102614164,\n",
       " 0.8099100327548642,\n",
       " 0.8113332757449135,\n",
       " 0.8127518698021928,\n",
       " 0.814165845198734,\n",
       " 0.815575231911849,\n",
       " 0.8169800596279427,\n",
       " 0.8183803577462655,\n",
       " 0.8197761553826042,\n",
       " 0.821167481372915,\n",
       " 0.8225543642768977,\n",
       " 0.8239368323815134,\n",
       " 0.8253149137044462,\n",
       " 0.8266886359975104,\n",
       " 0.8280580267500036,\n",
       " 0.8294231131920073,\n",
       " 0.8307839222976362,\n",
       " 0.8321404807882357,\n",
       " 0.8334928151355306,\n",
       " 0.8348409515647249,\n",
       " 0.836184916057553,\n",
       " 0.8375247343552839,\n",
       " 0.8388604319616801,\n",
       " 0.84019203414591,\n",
       " 0.8415195659454168,\n",
       " 0.8428430521687424,\n",
       " 0.8441625173983102,\n",
       " 0.8454779859931636,\n",
       " 0.8467894820916654,\n",
       " 0.8480970296141546,\n",
       " 0.8494006522655647,\n",
       " 0.8507003735380022,\n",
       " 0.8519962167132863,\n",
       " 0.853288204865452,\n",
       " 0.8545763608632145,\n",
       " 0.855860707372399,\n",
       " 0.8571412668583327,\n",
       " 0.858418061588203,\n",
       " 0.8596911136333807,\n",
       " 0.8609604448717098,\n",
       " 0.8622260769897623,\n",
       " 0.8634880314850625,\n",
       " 0.8647463296682774,\n",
       " 0.8660009926653758,\n",
       " 0.8672520414197574,\n",
       " 0.8684994966943492,\n",
       " 0.869743379073674,\n",
       " 0.8709837089658883,\n",
       " 0.872220506604791,\n",
       " 0.8734537920518044,\n",
       " 0.8746835851979264,\n",
       " 0.8759099057656554,\n",
       " 0.8771327733108883,\n",
       " 0.8783522072247917,\n",
       " 0.8795682267356463,\n",
       " 0.8807808509106672,\n",
       " 0.8819900986577965,\n",
       " 0.8831959887274736,\n",
       " 0.8843985397143787,\n",
       " 0.8855977700591535,\n",
       " 0.8867936980500983,\n",
       " 0.8879863418248449,\n",
       " 0.8891757193720072,\n",
       " 0.8903618485328094,\n",
       " 0.891544747002692,\n",
       " 0.8927244323328951,\n",
       " 0.8939009219320215,\n",
       " 0.8950742330675777,\n",
       " 0.8962443828674953,\n",
       " 0.8974113883216303,\n",
       " 0.8985752662832438,\n",
       " 0.8997360334704624,\n",
       " 0.9008937064677186,\n",
       " 0.9020483017271732,\n",
       " 0.9031998355701177,\n",
       " 0.9043483241883585,\n",
       " 0.9054937836455836,\n",
       " 0.9066362298787102,\n",
       " 0.9077756786992153,\n",
       " 0.9089121457944485,\n",
       " 0.9100456467289283,\n",
       " 0.9111761969456209,\n",
       " 0.9123038117672024,\n",
       " 0.9134285063973053,\n",
       " 0.9145502959217481,\n",
       " 0.9156691953097493,\n",
       " 0.9167852194151269,\n",
       " 0.9178983829774802,\n",
       " 0.9190087006233586,\n",
       " 0.9201161868674148,\n",
       " 0.9212208561135432,\n",
       " 0.9223227226560037,\n",
       " 0.9234218006805317,\n",
       " 0.9245181042654339,\n",
       " 0.9256116473826704,\n",
       " 0.926702443898923,\n",
       " 0.9277905075766503,\n",
       " 0.9288758520751295,\n",
       " 0.9299584909514851,\n",
       " 0.9310384376617057,\n",
       " 0.9321157055616465,\n",
       " 0.9331903079080209,\n",
       " 0.9342622578593797,\n",
       " 0.9353315684770768,\n",
       " 0.936398252726225,\n",
       " 0.9374623234766394,\n",
       " 0.938523793503768,\n",
       " 0.939582675489613,\n",
       " 0.9406389820236396,\n",
       " 0.941692725603674,\n",
       " 0.9427439186367909,\n",
       " 0.9437925734401896,\n",
       " 0.9448387022420607,\n",
       " 0.9458823171824406,\n",
       " 0.946923430314058,\n",
       " 0.9479620536031682,\n",
       " 0.9489981989303785,\n",
       " 0.9500318780914643,\n",
       " 0.9510631027981735,\n",
       " 0.9520918846790243,\n",
       " 0.9531182352800904,\n",
       " 0.9541421660657801,\n",
       " 0.955163688419603,\n",
       " 0.9561828136449307,\n",
       " 0.9571995529657465,\n",
       " 0.9582139175273879,\n",
       " 0.9592259183972782,\n",
       " 0.9602355665656527,\n",
       " 0.9612428729462734,\n",
       " 0.9622478483771382,\n",
       " 0.9632505036211791,\n",
       " 0.9642508493669555,\n",
       " 0.9652488962293362,\n",
       " 0.9662446547501763,\n",
       " 0.9672381353989848,\n",
       " 0.9682293485735858,\n",
       " 0.9692183046007703,\n",
       " 0.9702050137369427,\n",
       " 0.9711894861687586,\n",
       " 0.9721717320137557,\n",
       " 0.9731517613209785,\n",
       " 0.9741295840715937,\n",
       " 0.9751052101795017,\n",
       " 0.9760786494919383,\n",
       " 0.9770499117900725,\n",
       " 0.9780190067895947,\n",
       " 0.9789859441413011,\n",
       " 0.9799507334316694,\n",
       " 0.9809133841834298,\n",
       " 0.9818739058561283,\n",
       " 0.9828323078466853,\n",
       " 0.9837885994899462,\n",
       " 0.9847427900592276,\n",
       " 0.9856948887668566,\n",
       " 0.9866449047647048,\n",
       " 0.9875928471447156,\n",
       " 0.9885387249394265,\n",
       " 0.9894825471224858,\n",
       " 0.9904243226091631,\n",
       " 0.9913640602568545,\n",
       " 0.9923017688655827,\n",
       " 0.9932374571784914,\n",
       " 0.9941711338823342,\n",
       " 0.9951028076079589,\n",
       " 0.9960324869307857,\n",
       " 0.9969601803712812,\n",
       " 0.9978858963954268,\n",
       " 0.9988096434151821,\n",
       " 0.9997314297889439,\n",
       " 1.0006512638219995,\n",
       " 1.0015691537669766,\n",
       " 1.002485107824286,\n",
       " 1.003399134142563,\n",
       " 1.0043112408191008,\n",
       " 1.005221435900282,\n",
       " 1.006129727382004,\n",
       " 1.0070361232101004,\n",
       " 1.0079406312807582,\n",
       " 1.008843259440931,\n",
       " 1.0097440154887465,\n",
       " 1.0106429071739114,\n",
       " 1.0115399421981113,\n",
       " 1.012435128215407,\n",
       " 1.0133284728326253,\n",
       " 1.014219983609748,\n",
       " 1.0151096680602953,\n",
       " 1.015997533651706,\n",
       " 1.0168835878057123,\n",
       " 1.017767837898714,\n",
       " 1.0186502912621458,\n",
       " 1.0195309551828422,\n",
       " 1.0204098369033983,\n",
       " 1.0212869436225276,\n",
       " 1.022162282495416,\n",
       " 1.023035860634071,\n",
       " 1.0239076851076694,\n",
       " 1.0247777629429005,\n",
       " 1.0256461011243048,\n",
       " 1.0265127065946118,\n",
       " 1.0273775862550723,\n",
       " 1.0282407469657886,\n",
       " 1.0291021955460402,\n",
       " 1.0299619387746082,\n",
       " 1.030819983390094,\n",
       " 1.0316763360912375,\n",
       " 1.0325310035372302,\n",
       " 1.033383992348026,\n",
       " 1.0342353091046483,\n",
       " 1.0350849603494965,\n",
       " 1.0359329525866452,\n",
       " 1.0367792922821448,\n",
       " 1.0376239858643164,\n",
       " 1.038467039724045,\n",
       " 1.03930846021507,\n",
       " 1.0401482536542717,\n",
       " 1.0409864263219568,\n",
       " 1.0418229844621392,\n",
       " 1.04265793428282,\n",
       " 1.0434912819562634,\n",
       " 1.0443230336192706,\n",
       " 1.0451531953734507,\n",
       " 1.0459817732854901,\n",
       " 1.0468087733874174,\n",
       " 1.0476342016768676,\n",
       " 1.0484580641173429,\n",
       " 1.0492803666384711,\n",
       " 1.0501011151362618,\n",
       " 1.0509203154733602,\n",
       " 1.051737973479298,\n",
       " 1.0525540949507426,\n",
       " 1.0533686856517432,\n",
       " 1.054181751313976,\n",
       " 1.0549932976369853,\n",
       " 1.0558033302884235,\n",
       " 1.0566118549042889,\n",
       " 1.0574188770891602,\n",
       " 1.0582244024164305,\n",
       " 1.0590284364285378,\n",
       " 1.0598309846371938,\n",
       " 1.0606320525236108,\n",
       " 1.061431645538726,\n",
       " 1.0622297691034241,\n",
       " 1.0630264286087587,\n",
       " 1.0638216294161693,\n",
       " 1.0646153768576985,\n",
       " 1.065407676236207,\n",
       " 1.0661985328255854,\n",
       " 1.0669879518709653,\n",
       " 1.067775938588928,\n",
       " 1.0685624981677109,\n",
       " 1.0693476357674128,\n",
       " 1.0701313565201973,\n",
       " 1.0709136655304934,\n",
       " 1.0716945678751957,\n",
       " 1.0724740686038614,\n",
       " 1.0732521727389066,\n",
       " 1.0740288852758009,\n",
       " 1.0748042111832585,\n",
       " 1.0755781554034303,\n",
       " 1.0763507228520925,\n",
       " 1.0771219184188332,\n",
       " 1.0778917469672393,\n",
       " 1.0786602133350796,\n",
       " 1.0794273223344877,\n",
       " 1.0801930787521423,\n",
       " 1.0809574873494472,\n",
       " 1.0817205528627085,\n",
       " 1.08248228000331,\n",
       " 1.0832426734578893,\n",
       " 1.0840017378885092,\n",
       " 1.0847594779328302,\n",
       " 1.0855158982042805,\n",
       " 1.0862710032922238,\n",
       " 1.0870247977621272,\n",
       " 1.0877772861557264,\n",
       " 1.0885284729911897,\n",
       " 1.0892783627632812,\n",
       " 1.090026959943522,\n",
       " 1.0907742689803501,\n",
       " 1.0915202942992792,\n",
       " 1.0922650403030558,\n",
       " 1.0930085113718149,\n",
       " 1.093750711863235,\n",
       " 1.0944916461126915,\n",
       " 1.0952313184334075,\n",
       " 1.0959697331166056,\n",
       " 1.0967068944316574,\n",
       " 1.0974428066262305,\n",
       " 1.098177473926436,\n",
       " 1.0989109005369746,\n",
       " 1.0996430906412802,\n",
       " 1.100374048401663,\n",
       " 1.1011037779594526,\n",
       " 1.1018322834351373,\n",
       " 1.102559568928505,\n",
       " 1.1032856385187808,\n",
       " 1.1040104962647643,\n",
       " 1.1047341462049665,\n",
       " 1.1054565923577437,\n",
       " 1.1061778387214323,\n",
       " 1.1068978892744812,\n",
       " 1.1076167479755834,\n",
       " 1.1083344187638071,\n",
       " 1.1090509055587239,\n",
       " 1.1097662122605392,\n",
       " 1.1104803427502175,\n",
       " 1.1111933008896107,\n",
       " 1.111905090521582,\n",
       " 1.1126157154701304,\n",
       " 1.1133251795405148,\n",
       " 1.1140334865193753,\n",
       " 1.1147406401748552,\n",
       " 1.1154466442567201,\n",
       " 1.116151502496479,\n",
       " 1.1168552186075011,\n",
       " 1.117557796285134,\n",
       " 1.1182592392068196,\n",
       " 1.11895955103221,\n",
       " 1.1196587354032816,\n",
       " 1.12035679594445,\n",
       " 1.1210537362626807,\n",
       " 1.1217495599476026,\n",
       " 1.1224442705716184,\n",
       " 1.1231378716900142,\n",
       " 1.1238303668410696,\n",
       " 1.1245217595461647,\n",
       " 1.1252120533098893,\n",
       " 1.1259012516201476,\n",
       " 1.1265893579482653,\n",
       " 1.127276375749094,\n",
       " 1.1279623084611152,\n",
       " 1.128647159506544,\n",
       " 1.1293309322914307,\n",
       " 1.1300136302057633,\n",
       " 1.1306952566235677,\n",
       " 1.1313758149030089,\n",
       " 1.1320553083864884,\n",
       " 1.132733740400744,\n",
       " 1.1334111142569478,\n",
       " 1.134087433250802,\n",
       " 1.1347627006626357,\n",
       " 1.1354369197575007,\n",
       " 1.136110093785266,\n",
       " 1.136782225980711,\n",
       " 1.1374533195636205,\n",
       " 1.1381233777388753,\n",
       " 1.138792403696545,\n",
       " 1.1394604006119802,\n",
       " 1.1401273716459002,\n",
       " 1.140793319944485,\n",
       " 1.1414582486394644,\n",
       " 1.1421221608482044,\n",
       " 1.1427850596737967,\n",
       " 1.1434469482051455,\n",
       " 1.1441078295170526,\n",
       " 1.144767706670305,\n",
       " 1.1454265827117582,\n",
       " 1.146084460674422,\n",
       " 1.146741343577543,\n",
       " 1.147397234426689,\n",
       " 1.1480521362138305,\n",
       " 1.1487060519174233,\n",
       " 1.1493589845024892,\n",
       " 1.1500109369206968,\n",
       " 1.1506619121104422,\n",
       " 1.1513119129969276,\n",
       " 1.1519609424922406,\n",
       " 1.1526090034954324,\n",
       " 1.1532560988925955,\n",
       " 1.153902231556941,\n",
       " 1.1545474043488744,\n",
       " 1.155191620116073,\n",
       " 1.1558348816935597,\n",
       " 1.156477191903779,\n",
       " 1.157118553556671,\n",
       " 1.1577589694497448,\n",
       " 1.158398442368152,\n",
       " 1.1590369750847596,\n",
       " 1.1596745703602216,\n",
       " 1.1603112309430514,\n",
       " 1.160946959569692,\n",
       " 1.1615817589645872,\n",
       " 1.1622156318402512,\n",
       " 1.1628485808973388,\n",
       " 1.1634806088247134,\n",
       " 1.1641117182995169,\n",
       " 1.1647419119872362,\n",
       " 1.1653711925417725,\n",
       " 1.1659995626055062,\n",
       " 1.1666270248093658,\n",
       " 1.1672535817728924,\n",
       " 1.1678792361043056,\n",
       " 1.168503990400569,\n",
       " 1.1691278472474549,\n",
       " 1.1697508092196083,\n",
       " 1.17037287888061,\n",
       " 1.1709940587830416,\n",
       " 1.1716143514685466,\n",
       " 1.1722337594678938,\n",
       " 1.1728522853010388,\n",
       " 1.173469931477186,\n",
       " 1.1740867004948488,\n",
       " 1.1747025948419114,\n",
       " 1.1753176169956883,\n",
       " 1.1759317694229836,\n",
       " 1.1765450545801517,\n",
       " 1.1771574749131553,\n",
       " 1.1777690328576238,\n",
       " 1.1783797308389123,\n",
       " 1.1789895712721585,\n",
       " 1.1795985565623401,\n",
       " 1.1802066891043324,\n",
       " 1.1808139712829635,\n",
       " 1.1814204054730721,\n",
       " 1.1820259940395619,\n",
       " 1.182630739337457,\n",
       " 1.1832346437119583,\n",
       " 1.183837709498496,\n",
       " 1.1844399390227849,\n",
       " 1.1850413346008781,\n",
       " 1.1856418985392214,\n",
       " 1.1862416331347039,\n",
       " 1.1868405406747133,\n",
       " 1.1874386234371865,\n",
       " 1.188035883690663,\n",
       " 1.188632323694335,\n",
       " 1.1892279456980999,\n",
       " 1.1898227519426106,\n",
       " 1.1904167446593261,\n",
       " 1.1910099260705624,\n",
       " 1.1916022983895413,\n",
       " 1.1921938638204408,\n",
       " 1.1927846245584441,\n",
       " 1.1933745827897881,\n",
       " 1.1939637406918124,\n",
       " 1.1945521004330075,\n",
       " 1.1951396641730623,\n",
       " 1.1957264340629117,\n",
       " 1.1963124122447848,\n",
       " 1.1968976008522505,\n",
       " 1.1974820020102646,\n",
       " 1.1980656178352167,\n",
       " 1.1986484504349753,\n",
       " 1.1992305019089338,\n",
       " 1.1998117743480563,\n",
       " 1.2003922698349219,\n",
       " 1.20097199044377,\n",
       " 1.2015509382405447,\n",
       " 1.202129115282939,\n",
       " 1.2027065236204384,\n",
       " 1.2032831652943647,\n",
       " 1.2038590423379196,\n",
       " 1.2044341567762267,\n",
       " 1.2050085106263755,\n",
       " 1.2055821058974634,\n",
       " 1.206154944590637,\n",
       " 1.2067270286991356,\n",
       " 1.2072983602083314,\n",
       " 1.2078689410957715,\n",
       " 1.2084387733312187,\n",
       " 1.209007858876693,\n",
       " 1.209576199686511,\n",
       " 1.210143797707327,\n",
       " 1.2107106548781728,\n",
       " 1.2112767731304974,\n",
       " 1.211842154388206,\n",
       " 1.212406800567701,\n",
       " 1.212970713577918,\n",
       " 1.2135338953203674,\n",
       " 1.2140963476891715,\n",
       " 1.214658072571103,\n",
       " 1.215219071845622,\n",
       " 1.2157793473849157,\n",
       " 1.2163389010539343,\n",
       " 1.216897734710429,\n",
       " 1.2174558502049886,\n",
       " 1.2180132493810765,\n",
       " 1.2185699340750669,\n",
       " 1.2191259061162816,\n",
       " 1.219681167327026,\n",
       " 1.2202357195226246,\n",
       " 1.2207895645114566,\n",
       " 1.2213427040949918,\n",
       " 1.2218951400678253,\n",
       " 1.2224468742177121,\n",
       " 1.2229979083256033,\n",
       " 1.2235482441656786,\n",
       " 1.224097883505382,\n",
       " 1.224646828105455,\n",
       " 1.2251950797199715,\n",
       " 1.2257426400963705,\n",
       " 1.226289510975489,\n",
       " 1.2268356940915974,\n",
       " 1.2273811911724297,\n",
       " 1.227926003939219,\n",
       " 1.2284701341067277,\n",
       " 1.2290135833832814,\n",
       " 1.2295563534708005,\n",
       " 1.2300984460648328,\n",
       " 1.2306398628545838,\n",
       " 1.2311806055229504,\n",
       " 1.2317206757465504,\n",
       " 1.2322600751957549,\n",
       " 1.2327988055347183,\n",
       " 1.2333368684214103,\n",
       " 1.2338742655076453,\n",
       " 1.234410998439114,\n",
       " 1.2349470688554125,\n",
       " 1.2354824783900729,\n",
       " 1.2360172286705937,\n",
       " 1.2365513213184682,\n",
       " 1.2370847579492157,\n",
       " 1.2376175401724085,\n",
       " 1.2381496695917038,\n",
       " 1.2386811478048705,\n",
       " 1.2392119764038185,\n",
       " 1.2397421569746283,\n",
       " 1.2402716910975782,\n",
       " 1.240800580347173,\n",
       " 1.241328826292173,\n",
       " 1.2418564304956192,\n",
       " 1.242383394514865,\n",
       " 1.2429097199016002,\n",
       " 1.2434354082018808,\n",
       " 1.2439604609561552,\n",
       " 1.2444848796992907,\n",
       " 1.245008665960602,\n",
       " 1.2455318212638768,\n",
       " 1.2460543471274028,\n",
       " 1.246576245063994,\n",
       " 1.2470975165810168,\n",
       " 1.2476181631804169,\n",
       " 1.2481381863587442,\n",
       " 1.2486575876071793,\n",
       " 1.249176368411559,\n",
       " 1.2496945302524023,\n",
       " 1.2502120746049343,\n",
       " 1.2507290029391127,\n",
       " 1.251245316719653,\n",
       " 1.251761017406052,\n",
       " 1.2522761064526144,\n",
       " 1.2527905853084755,\n",
       " 1.2533044554176276,\n",
       " 1.2538177182189425,\n",
       " 1.254330375146197,\n",
       " 1.2548424276280963,\n",
       " 1.2553538770882977,\n",
       " 1.2558647249454353,\n",
       " 1.2563749726131428,\n",
       " 1.2568846215000766,\n",
       " 1.2573936730099404,\n",
       " 1.2579021285415075,\n",
       " 1.2584099894886436,\n",
       " 1.258917257240331,\n",
       " 1.25942393318069,\n",
       " 1.2599300186890021,\n",
       " 1.2604355151397326,\n",
       " 1.2609404239025535,\n",
       " 1.2614447463423644,\n",
       " 1.261948483819316,\n",
       " 1.2624516376888313,\n",
       " 1.2629542093016282,\n",
       " 1.2634562000037401,\n",
       " 1.2639576111365391,\n",
       " 1.2644584440367557,\n",
       " 1.264958700036502,\n",
       " 1.2654583804632913,\n",
       " 1.2659574866400607,\n",
       " 1.2664560198851913,\n",
       " 1.2669539815125286,\n",
       " 1.267451372831405,\n",
       " 1.2679481951466582,\n",
       " 1.268444449758654,\n",
       " 1.2689401379633047,\n",
       " 1.2694352610520911,\n",
       " 1.2699298203120815,\n",
       " 1.2704238170259519,\n",
       " 1.270917252472007,\n",
       " 1.2714101279241987,\n",
       " 1.2719024446521467,\n",
       " 1.272394203921158,\n",
       " 1.272885406992246,\n",
       " 1.2733760551221502,\n",
       " 1.2738661495633554,\n",
       " 1.2743556915641114,\n",
       " 1.2748446823684512,\n",
       " 1.2753331232162102,\n",
       " 1.275821015343046,\n",
       " 1.2763083599804557,\n",
       " 1.2767951583557955,\n",
       " 1.2772814116922993,\n",
       " 1.2777671212090964,\n",
       " 1.2782522881212304,\n",
       " 1.2787369136396776,\n",
       " 1.2792209989713645,\n",
       " 1.2797045453191864,\n",
       " 1.2801875538820253,\n",
       " 1.2806700258547674,\n",
       " 1.2811519624283205,\n",
       " 1.281633364789633,\n",
       " 1.28211423412171,\n",
       " 1.2825945716036318,\n",
       " 1.2830743784105703,\n",
       " 1.283553655713807,\n",
       " 1.2840324046807496,\n",
       " 1.2845106264749497,\n",
       " 1.2849883222561191,\n",
       " 1.2854654931801472,\n",
       " 1.2859421403991176,\n",
       " 1.2864182650613245,\n",
       " 1.2868938683112894,\n",
       " 1.2873689512897784,\n",
       " 1.2878435151338175,\n",
       " 1.2883175609767095,\n",
       " 1.2887910899480501,\n",
       " 1.2892641031737442,\n",
       " 1.2897366017760215,\n",
       " 1.2902085868734536,\n",
       " 1.2906800595809682,\n",
       " 1.2911510210098667,\n",
       " 1.291621472267838,\n",
       " 1.2920914144589764,\n",
       " 1.2925608486837947,\n",
       " 1.2930297760392417,\n",
       " 1.2934981976187165,\n",
       " 1.2939661145120842,\n",
       " 1.2944335278056907,\n",
       " 1.294900438582378,\n",
       " 1.2953668479214997,\n",
       " 1.2958327568989356,\n",
       " 1.2962981665871065,\n",
       " 1.296763078054989,\n",
       " 1.2972274923681306,\n",
       " 1.297691410588664,\n",
       " 1.2981548337753221,\n",
       " 1.2986177629834512,\n",
       " 1.2990801992650276,\n",
       " 1.29954214366867,\n",
       " 1.300003597239655,\n",
       " 1.3004645610199301,\n",
       " 1.3009250360481293,\n",
       " 1.3013850233595858,\n",
       " 1.3018445239863472,\n",
       " 1.3023035389571875,\n",
       " 1.3027620692976236,\n",
       " 1.3032201160299266,\n",
       " 1.303677680173137,\n",
       " 1.304134762743077,\n",
       " 1.304591364752366,\n",
       " 1.3050474872104316,\n",
       " 1.3055031311235252,\n",
       " 1.305958297494734,\n",
       " 1.3064129873239942,\n",
       " 1.3068672016081055,\n",
       " 1.3073209413407427,\n",
       " 1.3077742075124694,\n",
       " 1.308227001110751,\n",
       " 1.3086793231199678,\n",
       " 1.309131174521427,\n",
       " 1.3095825562933763,\n",
       " 1.3100334694110165,\n",
       " 1.3104839148465142,\n",
       " 1.3109338935690134,\n",
       " 1.3113834065446497,\n",
       " 1.3118324547365612,\n",
       " 1.3122810391049016,\n",
       " 1.3127291606068527,\n",
       " 1.3131768201966363,\n",
       " 1.3136240188255262,\n",
       " 1.314070757441861,\n",
       " 1.3145170369910555,\n",
       " 1.3149628584156128,\n",
       " 1.3154082226551371,\n",
       " 1.3158531306463441,\n",
       " 1.3162975833230743,\n",
       " 1.3167415816163035,\n",
       " 1.3171851264541556,\n",
       " 1.3176282187619133,\n",
       " 1.3180708594620303,\n",
       " 1.3185130494741428,\n",
       " 1.3189547897150804,\n",
       " 1.3193960810988783,\n",
       " 1.3198369245367878,\n",
       " 1.3202773209372882,\n",
       " 1.3207172712060984,\n",
       " 1.3211567762461869,\n",
       " 1.3215958369577834,\n",
       " 1.3220344542383908,\n",
       " 1.322472628982795,\n",
       " 1.322910362083076,\n",
       " 1.3233476544286198,\n",
       " 1.3237845069061278,\n",
       " 1.3242209203996287,\n",
       " 1.3246568957904887,\n",
       " 1.3250924339574228,\n",
       " 1.3255275357765042,\n",
       " 1.3259622021211759,\n",
       " ...]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHHCAYAAACvJxw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1f0lEQVR4nO3de1xVVf7/8fcB5OIFSEWOIKiZecsRwxFxmqxkwrSUtDRG85JlfdPGlJy0NHOcojInLS2n+X5LnTRNLWdG04ZQmybxhlbeL5N3BbwBXhFh/f7o55mO4BIMhKOv5+OxH8naa+39WWsYz/uxzzpHhzHGCAAAAMXyqugCAAAAKjPCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8IScB2aPn26HA6H9uzZU9GlWK1YsUIOh0MrVqyo6FJuKC+//LIcDkdFlwF4DMISAFyllStX6uWXX1Z2dnZFlwKgHBGWAFSYO++8U2fPntWdd95Z0aVclZUrV2rcuHGEJeA6R1gCUGZOnz5dqv5eXl7y9/eXl1fl+KuotPUDuDFUjr+hAFwTS5Ys0a9//WtVq1ZNNWrUUJcuXbR582a3Pt9//7369++vm2++Wf7+/nI6nXrsscd07Ngxt34X971s2bJFv/3tb3XTTTfpjjvukCQ1aNBA999/v/7973+rbdu28vf3180336yZM2e6XaO4PUt33XWXbrvtNm3ZskV33323qlatqvDwcL3xxhtF5rN371517dpV1apVU506dTRs2DB98cUXJdoHZau/JGvw8ssva8SIEZKkhg0byuFwFNkn9tFHHyk6OloBAQGqWbOmHnnkEe3fv99a1/z58+VwOPTVV18VOffnP/9ZDodDmzZtkiRlZGRowIABqlevnvz8/FS3bl1169btqvaqXbhwQePHj1ejRo3k5+enBg0a6IUXXlBeXp5bv3Xr1ik+Pl61a9dWQECAGjZsqMcee8ytz5w5cxQdHa0aNWooMDBQLVu21OTJk0tdE1BZ+FR0AQCujb/+9a/q16+f4uPj9frrr+vMmTN67733dMcdd2jDhg1q0KCBJCklJUU//PCDBgwYIKfTqc2bN+v999/X5s2btWrVqiIbgx9++GE1btxYr776qowxrvZdu3bpoYce0sCBA9WvXz998MEH6t+/v6Kjo9WiRQtrrSdOnFCnTp3UvXt39ezZU/Pnz9fzzz+vli1b6r777pP041Oge+65R4cPH9bQoUPldDo1e/ZsLV++vFTrUlz9JVmD7t27a8eOHfr444/11ltvqXbt2pKkkJAQSdIrr7yiMWPGqGfPnnr88cd15MgRvfPOO7rzzju1YcMGBQcHF1tPly5dVL16dX3yySfq0KGD27m5c+eqRYsWuu222yRJPXr00ObNm/XMM8+oQYMGysrKUkpKivbt2+f637OkHn/8cc2YMUMPPfSQkpKStHr1aiUnJ2vr1q367LPPJElZWVm69957FRISopEjRyo4OFh79uzRp59+6rpOSkqKEhMT1bFjR73++uuSpK1bt+qbb77R0KFDS1UTUGkYANedDz/80Egyu3fvNsYYc/LkSRMcHGyeeOIJt34ZGRkmKCjIrf3MmTNFrvfxxx8bSeZf//qXq23s2LFGkklMTCzSv379+kX6Z2VlGT8/P5OUlORqW758uZFkli9f7mrr0KGDkWRmzpzpasvLyzNOp9P06NHD1TZx4kQjySxcuNDVdvbsWdO0adMi1yyOrf6SrsGECRPc1vmiPXv2GG9vb/PKK6+4tW/cuNH4+PgUab9UYmKiqVOnjrlw4YKr7fDhw8bLy8v84Q9/MMYYc+LECSPJTJgwwXqt4lyc+0XffvutkWQef/xxt37PPfeckWSWLVtmjDHms88+M5LM2rVrL3vtoUOHmsDAQLfaAU/H23DADSAlJUXZ2dlKTEzU0aNHXYe3t7diYmLcnsYEBAS4/nzu3DkdPXpU7dq1kyStX7++yLWfeuqpYu/ZvHlz/frXv3b9HBISoiZNmuiHH364Yr3Vq1dXnz59XD/7+vqqbdu2bmOXLl2q8PBwde3a1dXm7++vJ5544orXv1L9pV2DS3366acqLCxUz5493dbb6XSqcePGV3z61atXL2VlZbm9lTh//nwVFhaqV69erhp9fX21YsUKnThxoiRTvazPP/9ckjR8+HC39qSkJEnS4sWLJcn1NGzRokXKz88v9lrBwcE6ffq0UlJSflZNQGVCWAJuADt37pQk3XPPPQoJCXE7/vnPfyorK8vV9/jx4xo6dKhCQ0MVEBCgkJAQNWzYUJKUk5NT5NoXz10qMjKySNtNN91Uohf2evXqFXm779Kxe/fuVaNGjYr0u+WWW654/Z8qrv7SrsGldu7cKWOMGjduXGS9t27d6rbexenUqZOCgoI0d+5cV9vcuXMVFRWlW2+9VZLk5+en119/XUuWLFFoaKjuvPNOvfHGG8rIyCjN9CX9uJZeXl5F1s7pdCo4OFh79+6VJHXo0EE9evTQuHHjVLt2bXXr1k0ffvih276mp59+Wrfeeqvuu+8+1atXT4899piWLl1a6pqAyoQ9S8ANoLCwUNKP+5acTmeR8z4+//2roGfPnlq5cqVGjBihqKgoVa9eXYWFherUqZPrOj/106cwP+Xt7V1su/nJvqbL+TljS6u4+ku7BpcqLCyUw+HQkiVLip1L9erVreP9/PyUkJCgzz77TO+++64yMzP1zTff6NVXX3Xr9+yzz+qBBx7QwoUL9cUXX2jMmDFKTk7WsmXL1Lp16yvWeakrfVGlw+HQ/PnztWrVKv3jH//QF198occee0wTJ07UqlWrVL16ddWpU0fffvutvvjiCy1ZskRLlizRhx9+qL59+2rGjBmlrgmoDAhLwA2gUaNGkqQ6deooLi7usv1OnDih1NRUjRs3Ti+99JKr/eKTqcqkfv362rJli4wxbi/yu3bt+lnXLc0aXC5cNGrUSMYYNWzY0PUkqLR69eqlGTNmKDU1VVu3bpUxxvUW3KX3SkpKUlJSknbu3KmoqChNnDhRH330UYnvVb9+fRUWFmrnzp1q1qyZqz0zM1PZ2dmqX7++W/927dqpXbt2euWVVzR79mz17t1bc+bM0eOPPy7px7dNH3jgAT3wwAMqLCzU008/rT//+c8aM2ZMqZ/8AZUBb8MBN4D4+HgFBgbq1VdfLXavyZEjRyT994nOpU9wJk2aVO41llZ8fLwOHjyov//97662c+fO6S9/+cvPum5p1qBatWqSVORLKbt37y5vb2+NGzeuyHWMMUW+hqE4cXFxqlmzpubOnau5c+eqbdu2bm8ZnjlzRufOnXMb06hRI9WoUaPIx/2vpHPnzpKKzvFPf/qTpB8/oSf9GCQvnU9UVJQkue556dy8vLz0i1/8wq0P4Gl4sgTcAAIDA/Xee+/p0Ucf1e23365HHnlEISEh2rdvnxYvXqxf/epXmjJligIDA117X/Lz8xUeHq5//vOf2r17d0VPoYgnn3xSU6ZMUWJiooYOHaq6detq1qxZ8vf3l3Tlt5QupzRrEB0dLUl68cUX9cgjj6hKlSp64IEH1KhRI/3xj3/UqFGjtGfPHiUkJKhGjRravXu3PvvsMw0aNEjPPfectY4qVaqoe/fumjNnjk6fPq0333zT7fyOHTvUsWNH9ezZU82bN5ePj48+++wzZWZm6pFHHinVnFu1aqV+/frp/fffV3Z2tjp06KA1a9ZoxowZSkhI0N133y1JmjFjht599109+OCDatSokU6ePKm//OUvCgwMdAWuxx9/XMePH9c999yjevXqae/evXrnnXcUFRXl9tQK8CgV9Ck8AOXo0q8OuGj58uUmPj7eBAUFGX9/f9OoUSPTv39/s27dOlefAwcOmAcffNAEBweboKAg8/DDD5tDhw4ZSWbs2LGufhc/fn7kyJEi969fv77p0qVLkfYOHTqYDh06uNWjYr46oEWLFkXG9uvXz9SvX9+t7YcffjBdunQxAQEBJiQkxCQlJZkFCxYYSWbVqlXWNbLVX9I1MMaY8ePHm/DwcOPl5VVkzRcsWGDuuOMOU61aNVOtWjXTtGlTM3jwYLN9+3ZrbRelpKQYScbhcJj9+/e7nTt69KgZPHiwadq0qalWrZoJCgoyMTEx5pNPPrnidS/96gBjjMnPzzfjxo0zDRs2NFWqVDERERFm1KhR5ty5c64+69evN4mJiSYyMtL4+fmZOnXqmPvvv9/t92f+/Pnm3nvvNXXq1DG+vr4mMjLSPPnkk+bw4cMlmjNQGTmMKYcdkwBQQSZNmqRhw4bpwIEDCg8Pr+hyAFwHCEsAPNbZs2eLfCdS69atVVBQoB07dlRgZQCuJ+xZAuCxunfvrsjISEVFRSknJ0cfffSRtm3bplmzZlV0aQCuI4QlAB4rPj5e//u//6tZs2apoKBAzZs315w5c4r9iD0AXC3ehgMAALDge5YAAAAsCEsAAAAW7FkqA4WFhTp06JBq1Khx1V+EBwAAri1jjE6ePKmwsDB5eV3++RFhqQwcOnRIERERFV0GAAC4Cvv371e9evUue56wVAZq1Kgh6cfFDgwMrOBqAABASeTm5ioiIsL1On45hKUycPGtt8DAQMISAAAe5kpbaNjgDQAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFh4XFiaOnWqGjRoIH9/f8XExGjNmjXW/vPmzVPTpk3l7++vli1b6vPPP79s36eeekoOh0OTJk0q46oBAICn8qiwNHfuXA0fPlxjx47V+vXr1apVK8XHxysrK6vY/itXrlRiYqIGDhyoDRs2KCEhQQkJCdq0aVORvp999plWrVqlsLCw8p4GAADwIB4Vlv70pz/piSee0IABA9S8eXNNmzZNVatW1QcffFBs/8mTJ6tTp04aMWKEmjVrpvHjx+v222/XlClT3PodPHhQzzzzjGbNmqUqVapci6kAAAAP4TFh6fz580pPT1dcXJyrzcvLS3FxcUpLSyt2TFpamlt/SYqPj3frX1hYqEcffVQjRoxQixYtyqd4AADgsXwquoCSOnr0qAoKChQaGurWHhoaqm3bthU7JiMjo9j+GRkZrp9ff/11+fj46He/+12Ja8nLy1NeXp7r59zc3BKPBQAAnsVjniyVh/T0dE2ePFnTp0+Xw+Eo8bjk5GQFBQW5joiIiHKsEgAAVCSPCUu1a9eWt7e3MjMz3dozMzPldDqLHeN0Oq39v/76a2VlZSkyMlI+Pj7y8fHR3r17lZSUpAYNGly2llGjRiknJ8d17N+//+dNDgAAVFoeE5Z8fX0VHR2t1NRUV1thYaFSU1MVGxtb7JjY2Fi3/pKUkpLi6v/oo4/q+++/17fffus6wsLCNGLECH3xxReXrcXPz0+BgYFuBwAAuD55zJ4lSRo+fLj69eunNm3aqG3btpo0aZJOnz6tAQMGSJL69u2r8PBwJScnS5KGDh2qDh06aOLEierSpYvmzJmjdevW6f3335ck1apVS7Vq1XK7R5UqVeR0OtWkSZNrOzkAAFApeVRY6tWrl44cOaKXXnpJGRkZioqK0tKlS12buPft2ycvr/8+LGvfvr1mz56t0aNH64UXXlDjxo21cOFC3XbbbRU1BQAA4GEcxhhT0UV4utzcXAUFBSknJ4e35AAA8BAlff32mD1LAAAAFYGwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACAhceFpalTp6pBgwby9/dXTEyM1qxZY+0/b948NW3aVP7+/mrZsqU+//xz17n8/Hw9//zzatmypapVq6awsDD17dtXhw4dKu9pAAAAD+FRYWnu3LkaPny4xo4dq/Xr16tVq1aKj49XVlZWsf1XrlypxMREDRw4UBs2bFBCQoISEhK0adMmSdKZM2e0fv16jRkzRuvXr9enn36q7du3q2vXrtdyWgAAoBJzGGNMRRdRUjExMfrlL3+pKVOmSJIKCwsVERGhZ555RiNHjizSv1evXjp9+rQWLVrkamvXrp2ioqI0bdq0Yu+xdu1atW3bVnv37lVkZGSJ6srNzVVQUJBycnIUGBh4FTMDAADXWklfvz3mydL58+eVnp6uuLg4V5uXl5fi4uKUlpZW7Ji0tDS3/pIUHx9/2f6SlJOTI4fDoeDg4DKpGwAAeDafii6gpI4ePaqCggKFhoa6tYeGhmrbtm3FjsnIyCi2f0ZGRrH9z507p+eff16JiYnWhJmXl6e8vDzXz7m5uSWdBgAA8DAe82SpvOXn56tnz54yxui9996z9k1OTlZQUJDriIiIuEZVAgCAa81jwlLt2rXl7e2tzMxMt/bMzEw5nc5ixzidzhL1vxiU9u7dq5SUlCvuOxo1apRycnJcx/79+69iRgAAwBN4TFjy9fVVdHS0UlNTXW2FhYVKTU1VbGxssWNiY2Pd+ktSSkqKW/+LQWnnzp368ssvVatWrSvW4ufnp8DAQLcDAABcnzxmz5IkDR8+XP369VObNm3Utm1bTZo0SadPn9aAAQMkSX379lV4eLiSk5MlSUOHDlWHDh00ceJEdenSRXPmzNG6dev0/vvvS/oxKD300ENav369Fi1apIKCAtd+ppo1a8rX17diJgoAACoNjwpLvXr10pEjR/TSSy8pIyNDUVFRWrp0qWsT9759++Tl9d+HZe3bt9fs2bM1evRovfDCC2rcuLEWLlyo2267TZJ08OBB/f3vf5ckRUVFud1r+fLluuuuu67JvAAAQOXlUd+zVFnxPUsAAHie6+57lgAAACoCYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBxVWFpxowZWrx4sevn3//+9woODlb79u21d+/eMisOAACgol1VWHr11VcVEBAgSUpLS9PUqVP1xhtvqHbt2ho2bFiZFggAAFCRfK5m0P79+3XLLbdIkhYuXKgePXpo0KBB+tWvfqW77rqrLOsDAACoUFf1ZKl69eo6duyYJOmf//ynfvOb30iS/P39dfbs2bKrDgAAoIJd1ZOl3/zmN3r88cfVunVr7dixQ507d5Ykbd68WQ0aNCjL+gAAACrUVT1Zmjp1qmJjY3XkyBEtWLBAtWrVkiSlp6crMTGxTAsEAACoSFcVloKDgzVlyhT97W9/U6dOnVzt48aN04svvlhmxRVn6tSpatCggfz9/RUTE6M1a9ZY+8+bN09NmzaVv7+/WrZsqc8//9ztvDFGL730kurWrauAgADFxcVp586d5TkFAADgQa4qLC1dulT//ve/XT9PnTpVUVFR+u1vf6sTJ06UWXGXmjt3roYPH66xY8dq/fr1atWqleLj45WVlVVs/5UrVyoxMVEDBw7Uhg0blJCQoISEBG3atMnV54033tDbb7+tadOmafXq1apWrZri4+N17ty5cpsHAADwHA5jjCntoJYtW+r1119X586dtXHjRv3yl7/U8OHDtXz5cjVt2lQffvhhedSqmJgY/fKXv9SUKVMkSYWFhYqIiNAzzzyjkSNHFunfq1cvnT59WosWLXK1tWvXTlFRUZo2bZqMMQoLC1NSUpKee+45SVJOTo5CQ0M1ffp0PfLIIyWqKzc3V0FBQcrJyVFgYGAZzBQAAJS3kr5+X9WTpd27d6t58+aSpAULFuj+++/Xq6++qqlTp2rJkiVXV/EVnD9/Xunp6YqLi3O1eXl5KS4uTmlpacWOSUtLc+svSfHx8a7+u3fvVkZGhlufoKAgxcTEXPaakpSXl6fc3Fy3AwAAXJ+uKiz5+vrqzJkzkqQvv/xS9957rySpZs2a5RYcjh49qoKCAoWGhrq1h4aGKiMjo9gxGRkZ1v4X/1uaa0pScnKygoKCXEdERESp5wMAADzDVYWlO+64Q8OHD9f48eO1Zs0adenSRZK0Y8cO1atXr0wLrIxGjRqlnJwc17F///6KLgkAAJSTqwpLU6ZMkY+Pj+bPn6/33ntP4eHhkqQlS5a4fTquLNWuXVve3t7KzMx0a8/MzJTT6Sx2jNPptPa/+N/SXFOS/Pz8FBgY6HYAAIDr01WFpcjISC1atEjfffedBg4c6Gp/66239Pbbb5dZcT/l6+ur6OhopaamutoKCwuVmpqq2NjYYsfExsa69ZeklJQUV/+GDRvK6XS69cnNzdXq1asve00AAHBjuapv8JakgoICLVy4UFu3bpUktWjRQl27dpW3t3eZFXep4cOHq1+/fmrTpo3atm2rSZMm6fTp0xowYIAkqW/fvgoPD1dycrIkaejQoerQoYMmTpyoLl26aM6cOVq3bp3ef/99SZLD4dCzzz6rP/7xj2rcuLEaNmyoMWPGKCwsTAkJCeU2DwAA4DmuKizt2rVLnTt31sGDB9WkSRNJP256joiI0OLFi9WoUaMyLfKiXr166ciRI3rppZeUkZGhqKgoLV261LVBe9++ffLy+u/Dsvbt22v27NkaPXq0XnjhBTVu3FgLFy7Ubbfd5urz+9//XqdPn9agQYOUnZ2tO+64Q0uXLpW/v3+5zAEAAHiWq/qepc6dO8sYo1mzZqlmzZqSpGPHjqlPnz7y8vLS4sWLy7zQyozvWQIAwPOU9PX7qp4sffXVV1q1apUrKElSrVq19Nprr+lXv/rV1VwSAACgUrqqDd5+fn46efJkkfZTp07J19f3ZxcFAABQWVxVWLr//vs1aNAgrV69WsYYGWO0atUqPfXUU+ratWtZ1wgAAFBhriosvf3222rUqJFiY2Pl7+8vf39/tW/fXrfccosmTZpUxiUCAABUnKvasxQcHKy//e1v2rVrl+urA5o1a6ZbbrmlTIsDAACoaCUOS8OHD7eeX758uevPf/rTn66+IgAAgEqkxGFpw4YNJerncDiuuhgAAIDKpsRh6adPjgAAAG4UV7XBGwAA4EZBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMDCY8LS8ePH1bt3bwUGBio4OFgDBw7UqVOnrGPOnTunwYMHq1atWqpevbp69OihzMxM1/nvvvtOiYmJioiIUEBAgJo1a6bJkyeX91QAAIAH8Ziw1Lt3b23evFkpKSlatGiR/vWvf2nQoEHWMcOGDdM//vEPzZs3T1999ZUOHTqk7t27u86np6erTp06+uijj7R582a9+OKLGjVqlKZMmVLe0wEAAB7CYYwxFV3ElWzdulXNmzfX2rVr1aZNG0nS0qVL1blzZx04cEBhYWFFxuTk5CgkJESzZ8/WQw89JEnatm2bmjVrprS0NLVr167Yew0ePFhbt27VsmXLSlxfbm6ugoKClJOTo8DAwKuYIQAAuNZK+vrtEU+W0tLSFBwc7ApKkhQXFycvLy+tXr262DHp6enKz89XXFycq61p06aKjIxUWlraZe+Vk5OjmjVrWuvJy8tTbm6u2wEAAK5PHhGWMjIyVKdOHbc2Hx8f1axZUxkZGZcd4+vrq+DgYLf20NDQy45ZuXKl5s6de8W395KTkxUUFOQ6IiIiSj4ZAADgUSo0LI0cOVIOh8N6bNu27ZrUsmnTJnXr1k1jx47Vvffea+07atQo5eTkuI79+/dfkxoBAMC151ORN09KSlL//v2tfW6++WY5nU5lZWW5tV+4cEHHjx+X0+ksdpzT6dT58+eVnZ3t9nQpMzOzyJgtW7aoY8eOGjRokEaPHn3Fuv38/OTn53fFfgAAwPNVaFgKCQlRSEjIFfvFxsYqOztb6enpio6OliQtW7ZMhYWFiomJKXZMdHS0qlSpotTUVPXo0UOStH37du3bt0+xsbGufps3b9Y999yjfv366ZVXXimDWQEAgOuJR3waTpLuu+8+ZWZmatq0acrPz9eAAQPUpk0bzZ49W5J08OBBdezYUTNnzlTbtm0lSf/zP/+jzz//XNOnT1dgYKCeeeYZST/uTZJ+fOvtnnvuUXx8vCZMmOC6l7e3d4lC3EV8Gg4AAM9T0tfvCn2yVBqzZs3SkCFD1LFjR3l5ealHjx56++23Xefz8/O1fft2nTlzxtX21ltvufrm5eUpPj5e7777ruv8/PnzdeTIEX300Uf66KOPXO3169fXnj17rsm8AABA5eYxT5YqM54sAQDgea6r71kCAACoKIQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsPCYsHT9+XL1791ZgYKCCg4M1cOBAnTp1yjrm3LlzGjx4sGrVqqXq1aurR48eyszMLLbvsWPHVK9ePTkcDmVnZ5fDDAAAgCfymLDUu3dvbd68WSkpKVq0aJH+9a9/adCgQdYxw4YN0z/+8Q/NmzdPX331lQ4dOqTu3bsX23fgwIH6xS9+UR6lAwAAD+YwxpiKLuJKtm7dqubNm2vt2rVq06aNJGnp0qXq3LmzDhw4oLCwsCJjcnJyFBISotmzZ+uhhx6SJG3btk3NmjVTWlqa2rVr5+r73nvvae7cuXrppZfUsWNHnThxQsHBwSWuLzc3V0FBQcrJyVFgYODPmywAALgmSvr67RFPltLS0hQcHOwKSpIUFxcnLy8vrV69utgx6enpys/PV1xcnKutadOmioyMVFpamqtty5Yt+sMf/qCZM2fKy6tky5GXl6fc3Fy3AwAAXJ88IixlZGSoTp06bm0+Pj6qWbOmMjIyLjvG19e3yBOi0NBQ15i8vDwlJiZqwoQJioyMLHE9ycnJCgoKch0RERGlmxAAAPAYFRqWRo4cKYfDYT22bdtWbvcfNWqUmjVrpj59+pR6XE5OjuvYv39/OVUIAAAqmk9F3jwpKUn9+/e39rn55pvldDqVlZXl1n7hwgUdP35cTqez2HFOp1Pnz59Xdna229OlzMxM15hly5Zp48aNmj9/viTp4vat2rVr68UXX9S4ceOKvbafn5/8/PxKMkUAAODhKjQshYSEKCQk5Ir9YmNjlZ2drfT0dEVHR0v6MegUFhYqJiam2DHR0dGqUqWKUlNT1aNHD0nS9u3btW/fPsXGxkqSFixYoLNnz7rGrF27Vo899pi+/vprNWrU6OdODwAAXAcqNCyVVLNmzdSpUyc98cQTmjZtmvLz8zVkyBA98sgjrk/CHTx4UB07dtTMmTPVtm1bBQUFaeDAgRo+fLhq1qypwMBAPfPMM4qNjXV9Eu7SQHT06FHX/UrzaTgAAHD98oiwJEmzZs3SkCFD1LFjR3l5ealHjx56++23Xefz8/O1fft2nTlzxtX21ltvufrm5eUpPj5e7777bkWUDwAAPJRHfM9SZcf3LAEA4Hmuq+9ZAgAAqCiEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAICFT0UXcD0wxkiScnNzK7gSAABQUhdfty++jl8OYakMnDx5UpIUERFRwZUAAIDSOnnypIKCgi573mGuFKdwRYWFhTp06JBq1Kghh8NR0eVUqNzcXEVERGj//v0KDAys6HKuW6zztcNaXxus87XBOrszxujkyZMKCwuTl9fldybxZKkMeHl5qV69ehVdRqUSGBjI/xGvAdb52mGtrw3W+dpgnf/L9kTpIjZ4AwAAWBCWAAAALAhLKFN+fn4aO3as/Pz8KrqU6xrrfO2w1tcG63xtsM5Xhw3eAAAAFjxZAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQllNrx48fVu3dvBQYGKjg4WAMHDtSpU6esY86dO6fBgwerVq1aql69unr06KHMzMxi+x47dkz16tWTw+FQdnZ2OczAM5THOn/33XdKTExURESEAgIC1KxZM02ePLm8p1KpTJ06VQ0aNJC/v79iYmK0Zs0aa/958+apadOm8vf3V8uWLfX555+7nTfG6KWXXlLdunUVEBCguLg47dy5szyn4BHKcp3z8/P1/PPPq2XLlqpWrZrCwsLUt29fHTp0qLynUemV9e/zTz311FNyOByaNGlSGVftgQxQSp06dTKtWrUyq1atMl9//bW55ZZbTGJionXMU089ZSIiIkxqaqpZt26dadeunWnfvn2xfbt162buu+8+I8mcOHGiHGbgGcpjnf/v//7P/O53vzMrVqww//nPf8xf//pXExAQYN55553ynk6lMGfOHOPr62s++OADs3nzZvPEE0+Y4OBgk5mZWWz/b775xnh7e5s33njDbNmyxYwePdpUqVLFbNy40dXntddeM0FBQWbhwoXmu+++M127djUNGzY0Z8+evVbTqnTKep2zs7NNXFycmTt3rtm2bZtJS0szbdu2NdHR0ddyWpVOefw+X/Tpp5+aVq1ambCwMPPWW2+V80wqP8ISSmXLli1Gklm7dq2rbcmSJcbhcJiDBw8WOyY7O9tUqVLFzJs3z9W2detWI8mkpaW59X333XdNhw4dTGpq6g0dlsp7nX/q6aefNnfffXfZFV+JtW3b1gwePNj1c0FBgQkLCzPJycnF9u/Zs6fp0qWLW1tMTIx58sknjTHGFBYWGqfTaSZMmOA6n52dbfz8/MzHH39cDjPwDGW9zsVZs2aNkWT27t1bNkV7oPJa5wMHDpjw8HCzadMmU79+fcKSMYa34VAqaWlpCg4OVps2bVxtcXFx8vLy0urVq4sdk56ervz8fMXFxbnamjZtqsjISKWlpbnatmzZoj/84Q+aOXOm9R80vBGU5zpfKicnRzVr1iy74iup8+fPKz093W19vLy8FBcXd9n1SUtLc+svSfHx8a7+u3fvVkZGhlufoKAgxcTEWNf8elYe61ycnJwcORwOBQcHl0ndnqa81rmwsFCPPvqoRowYoRYtWpRP8R7oxn5FQqllZGSoTp06bm0+Pj6qWbOmMjIyLjvG19e3yF9qoaGhrjF5eXlKTEzUhAkTFBkZWS61e5LyWudLrVy5UnPnztWgQYPKpO7K7OjRoyooKFBoaKhbu219MjIyrP0v/rc017zelcc6X+rcuXN6/vnnlZiYeMP+Y7Dltc6vv/66fHx89Lvf/a7si/ZghCVIkkaOHCmHw2E9tm3bVm73HzVqlJo1a6Y+ffqU2z0qg4pe55/atGmTunXrprFjx+ree++9JvcEfq78/Hz17NlTxhi99957FV3OdSU9PV2TJ0/W9OnT5XA4KrqcSsWnogtA5ZCUlKT+/ftb+9x8881yOp3Kyspya79w4YKOHz8up9NZ7Din06nz588rOzvb7alHZmama8yyZcu0ceNGzZ8/X9KPnzCSpNq1a+vFF1/UuHHjrnJmlUtFr/NFW7ZsUceOHTVo0CCNHj36qubiaWrXri1vb+8in8Isbn0ucjqd1v4X/5uZmam6deu69YmKiirD6j1HeazzRReD0t69e7Vs2bIb9qmSVD7r/PXXXysrK8vt6X5BQYGSkpI0adIk7dmzp2wn4UkqetMUPMvFjcfr1q1ztX3xxRcl2ng8f/58V9u2bdvcNh7v2rXLbNy40XV88MEHRpJZuXLlZT/ZcT0rr3U2xphNmzaZOnXqmBEjRpTfBCqptm3bmiFDhrh+LigoMOHh4dYNsffff79bW2xsbJEN3m+++abrfE5ODhu8y3idjTHm/PnzJiEhwbRo0cJkZWWVT+EepqzX+ejRo25/D2/cuNGEhYWZ559/3mzbtq38JuIBCEsotU6dOpnWrVub1atXm3//+9+mcePGbh9pP3DggGnSpIlZvXq1q+2pp54ykZGRZtmyZWbdunUmNjbWxMbGXvYey5cvv6E/DWdM+azzxo0bTUhIiOnTp485fPiw67hRXnzmzJlj/Pz8zPTp082WLVvMoEGDTHBwsMnIyDDGGPPoo4+akSNHuvp/8803xsfHx7z55ptm69atZuzYscV+dUBwcLD529/+Zr7//nvTrVs3vjqgjNf5/PnzpmvXrqZevXrm22+/dfvdzcvLq5A5Vgbl8ft8KT4N9yPCEkrt2LFjJjEx0VSvXt0EBgaaAQMGmJMnT7rO796920gyy5cvd7WdPXvWPP300+amm24yVatWNQ8++KA5fPjwZe9BWCqfdR47dqyRVOSoX7/+NZxZxXrnnXdMZGSk8fX1NW3btjWrVq1ynevQoYPp16+fW/9PPvnE3HrrrcbX19e0aNHCLF682O18YWGhGTNmjAkNDTV+fn6mY8eOZvv27ddiKpVaWa7zxd/14o6f/v7fiMr69/lShKUfOYz5/5tDAAAAUASfhgMAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBOCau+uuu/Tss89WdBmSpJdffvmG/XfcAJQMYQnADe25555TampqRZdxWStWrJDD4VB2dnZFlwLcsAhLAK5L58+fL1G/6tWrq1atWuVcTVElrQ9AxSMsAahweXl5eu655xQeHq5q1aopJiZGK1ascJ0/duyYEhMTFR4erqpVq6ply5b6+OOP3a5x1113aciQIXr22WdVu3ZtxcfHu57KpKamqk2bNqpatarat2+v7du3u8Zd+jZc//79lZCQoDfffFN169ZVrVq1NHjwYOXn57v6HD58WF26dFFAQIAaNmyo2bNnq0GDBpo0adJl53jxuq+88orCwsLUpEkTSdJf//pXtWnTRjVq1JDT6dRvf/tbZWVlSZL27Nmju+++W5J00003yeFwqH///pKkwsJCJScnq2HDhgoICFCrVq00f/78q1l+AFdAWAJQ4YYMGaK0tDTNmTNH33//vR5++GF16tRJO3fulCSdO3dO0dHRWrx4sTZt2qRBgwbp0Ucf1Zo1a9yuM2PGDPn6+uqbb77RtGnTXO0vvviiJk6cqHXr1snHx0ePPfaYtZ7ly5frP//5j5YvX64ZM2Zo+vTpmj59uut83759dejQIa1YsUILFizQ+++/7wo4Nqmpqdq+fbtSUlK0aNEiSVJ+fr7Gjx+v7777TgsXLtSePXtcgSgiIkILFiyQJG3fvl2HDx/W5MmTJUnJycmaOXOmpk2bps2bN2vYsGHq06ePvvrqqyvWAaCUKvpf8gVw4+nQoYMZOnSoMcaYvXv3Gm9vb3Pw4EG3Ph07djSjRo267DW6dOlikpKS3K7ZunVrtz7Lly83ksyXX37palu8eLGRZM6ePWuMMWbs2LGmVatWrvP9+vUz9evXNxcuXHC1Pfzww6ZXr17GGGO2bt1qJJm1a9e6zu/cudNIsv7r7P369TOhoaEmLy/vsn2MMWbt2rVGkjl58qTbHE6cOOHqc+7cOVO1alWzcuVKt7EDBw40iYmJ1usDKD2figxqALBx40YVFBTo1ltvdWvPy8tz7SUqKCjQq6++qk8++UQHDx7U+fPnlZeXp6pVq7qNiY6OLvYev/jFL1x/rlu3riQpKytLkZGRxfZv0aKFvL293cZs3LhR0o9PeHx8fHT77be7zt9yyy266aabrjjXli1bytfX160tPT1dL7/8sr777judOHFChYWFkqR9+/apefPmxV5n165dOnPmjH7zm9+4tZ8/f16tW7e+Yh0ASoewBKBCnTp1St7e3kpPT3cLKNKPm68lacKECZo8ebImTZqkli1bqlq1anr22WeLbJKuVq1asfeoUqWK688Oh0OSXKHkSv0vjrH1L6lL6zt9+rTi4+MVHx+vWbNmKSQkRPv27VN8fLx1A/ipU6ckSYsXL1Z4eLjbOT8/v59dJwB3hCUAFap169YqKChQVlaWfv3rXxfb55tvvlG3bt3Up08fST8GnR07dlz2yUt5atKkiS5cuKANGza4nmTt2rVLJ06cKPW1tm3bpmPHjum1115TRESEJGndunVufS4+iSooKHC1NW/eXH5+ftq3b586dOhwtVMBUEJs8AZQoW699Vb17t1bffv21aeffqrdu3drzZo1Sk5O1uLFiyVJjRs3VkpKilauXKmtW7fqySefVGZmZoXU27RpU8XFxWnQoEFas2aNNmzYoEGDBikgIMD11KqkIiMj5evrq3feeUc//PCD/v73v2v8+PFuferXry+Hw6FFixbpyJEjOnXqlGrUqKHnnntOw4YN04wZM/Sf//xH69ev1zvvvKMZM2aU5XQBiLAEoBL48MMP1bdvXyUlJalJkyZKSEjQ2rVrXXuKRo8erdtvv13x8fG666675HQ6lZCQUGH1zpw5U6Ghobrzzjv14IMP6oknnlCNGjXk7+9fquuEhIRo+vTpmjdvnpo3b67XXntNb775pluf8PBwjRs3TiNHjlRoaKiGDBkiSRo/frzGjBmj5ORkNWvWTJ06ddLixYvVsGHDMpsngB85jDGmoosAAE924MABRURE6Msvv1THjh0ruhwAZYywBACltGzZMp06dUotW7bU4cOH9fvf/14HDx7Ujh07imwOB+D52OANAKWUn5+vF154QT/88INq1Kih9u3ba9asWQQl4DrFkyUAAAALNngDAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFj8P35UOwBXYcZ1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "logs,losses= find_lr(model= Torch.Cnn, loss_fn= Torch.loss_fn, optimizer= Torch.optimizer)\n",
    "plt.plot(logs,losses)\n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('loss')\n",
    "plt.title('learning rate vs loss')\n",
    "plt.show()\n",
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.0827, dtype=torch.float64, grad_fn=<NllLossBackward0>)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_lr(model= Torch.Cnn, loss_fn= Torch.loss_fn, optimizer= Torch.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim  as optim\n",
    "\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "{ 'params': Torch.Cnn.parameters(), 'lr': 0.0125},\n",
    "], lr=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas 100000000 equivalente a 40 segundos\n",
      " Pulando em 0 segundos , em 1 vezes\n",
      "Tamanho da memoria ocupada :4577.87 MB\n",
      "CPU times: total: 14min 1s\n",
      "Wall time: 34min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 20001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = DATA_1M(seconds=40,columns=20000, jump_time =0, n_jumps=1)\n",
    "print(data)\n",
    "data_fourier = data(Fourier=True)\n",
    "data_fourier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (21750, 20000) float64\n",
      "X_Test shape: (8250, 20000) float64\n",
      "y_train shape: (21750,) float64\n",
      "y_test shape: (8250,) float64\n",
      "\n",
      "--------\n",
      "Valor 0: 10000 ocorrência(s)- 0.33%\n",
      "Valor 1: 10000 ocorrência(s)- 0.33%\n",
      "Valor 2: 10000 ocorrência(s)- 0.33%\n",
      "Dataset :  (30000, 20001)\n"
     ]
    }
   ],
   "source": [
    "data.Spliting(data= data_fourier, random_state= 38, test_size = 0.275, shuffle = True, inplace= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape , Y shape torch.Size([64, 20000]) torch.Size([64])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001E0EE4EFFD0>, <torch.utils.data.dataloader.DataLoader object at 0x000001E0EE1D94D0>)\n",
      "Length of train dataloader: 340 batches of 64\n",
      "Length of test dataloader: 129 batches of 64\n"
     ]
    }
   ],
   "source": [
    "train_dataloader , test_dataloader = data.DataLoaders(batch_size=64, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.34507 | Train accuracy: 38.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [13:47<3:13:01, 827.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 84.69437 | Test accuracy: 41.67%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 1.23940 | Train accuracy: 48.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [27:15<2:56:50, 816.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 90.13758 | Test accuracy: 30.20%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 1.08449 | Train accuracy: 65.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [41:02<2:44:14, 821.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 85.79268 | Test accuracy: 40.52%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.99929 | Train accuracy: 74.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [54:35<2:29:58, 818.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.04421 | Test accuracy: 39.24%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.95456 | Train accuracy: 79.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [1:08:34<2:17:34, 825.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.70774 | Test accuracy: 38.63%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.92030 | Train accuracy: 82.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [1:22:22<2:03:55, 826.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.27540 | Test accuracy: 39.31%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.88564 | Train accuracy: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [1:35:11<1:47:41, 807.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.88641 | Test accuracy: 38.86%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.85450 | Train accuracy: 89.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [1:48:31<1:33:56, 805.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.64834 | Test accuracy: 37.73%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.83719 | Train accuracy: 90.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [2:02:30<1:21:34, 815.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.55235 | Test accuracy: 38.43%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.82399 | Train accuracy: 92.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [2:16:19<1:08:19, 819.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.34147 | Test accuracy: 38.42%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.81576 | Train accuracy: 92.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [2:30:09<54:51, 822.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.66981 | Test accuracy: 38.00%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.81025 | Train accuracy: 93.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [2:43:41<40:58, 819.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.86864 | Test accuracy: 37.72%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.80280 | Train accuracy: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [2:57:12<27:13, 816.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.00118 | Test accuracy: 39.11%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.79937 | Train accuracy: 94.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [3:10:39<13:34, 814.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.97332 | Test accuracy: 39.22%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.79809 | Train accuracy: 94.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [3:24:08<00:00, 816.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.60427 | Test accuracy: 38.22%\n",
      "CPU times: total: 20h 14min 1s\n",
      "Wall time: 3h 24min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
      "0       38.215467   87.604266       38.984375    1.345068\n",
      "1       38.215467   87.604266       48.654684    1.239400\n",
      "2       38.215467   87.604266       65.315564    1.084490\n",
      "3       38.215467   87.604266       74.356447    0.999285\n",
      "4       38.215467   87.604266       79.091605    0.954565\n",
      "5       38.215467   87.604266       82.588848    0.920301\n",
      "6       38.215467   87.604266       85.979541    0.885640\n",
      "7       38.215467   87.604266       89.214495    0.854497\n",
      "8       38.215467   87.604266       90.866353    0.837193\n",
      "9       38.215467   87.604266       92.227158    0.823987\n",
      "10      38.215467   87.604266       92.979133    0.815760\n",
      "11      38.215467   87.604266       93.506774    0.810251\n",
      "12      38.215467   87.604266       94.273046    0.802804\n",
      "13      38.215467   87.604266       94.605971    0.799371\n",
      "14      38.215467   87.604266       94.717967    0.798092\n"
     ]
    }
   ],
   "source": [
    "print(Torch(test= True, train= True))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.39      0.55      0.45      2716\n",
      "        WIFI       0.41      0.34      0.37      2809\n",
      "         LTE       0.35      0.25      0.29      2725\n",
      "\n",
      "    accuracy                           0.38      8250\n",
      "   macro avg       0.38      0.38      0.37      8250\n",
      "weighted avg       0.38      0.38      0.37      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data.y_test, Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
