{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janat\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from  Data_Loader import DATA_1M\n",
    "from helper_functions import accuracy_fn\n",
    "from CnnModel import NeuralNetCNN\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, recall_score)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas 13333248, equivalente a 8 segundos \n",
      " Pulando em 0 segundos em 3 vezes\n",
      "tamanho da memória ocupada :612.73 MB\n",
      "CPU times: total: 29.5 s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(312498, 257)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = DATA_1M(seconds=8,columns=256, jump_time =0, n_jumps=3)\n",
    "print(data)\n",
    "data_fourier = data(Fourier=True, Normalizing= True)\n",
    "data_fourier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.938415</td>\n",
       "      <td>-23.360631</td>\n",
       "      <td>9.682030</td>\n",
       "      <td>15.125879</td>\n",
       "      <td>46.366661</td>\n",
       "      <td>-7.256437</td>\n",
       "      <td>8.299082</td>\n",
       "      <td>-23.070582</td>\n",
       "      <td>-48.915892</td>\n",
       "      <td>23.237752</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.710768</td>\n",
       "      <td>-0.279310</td>\n",
       "      <td>-2.896621</td>\n",
       "      <td>15.094491</td>\n",
       "      <td>8.561273</td>\n",
       "      <td>-5.811388</td>\n",
       "      <td>31.997964</td>\n",
       "      <td>-13.973196</td>\n",
       "      <td>-5.184306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14.591125</td>\n",
       "      <td>-8.008776</td>\n",
       "      <td>2.711165</td>\n",
       "      <td>-14.151475</td>\n",
       "      <td>4.141044</td>\n",
       "      <td>-3.151526</td>\n",
       "      <td>-7.338920</td>\n",
       "      <td>19.632322</td>\n",
       "      <td>-1.349845</td>\n",
       "      <td>-26.822912</td>\n",
       "      <td>...</td>\n",
       "      <td>12.933498</td>\n",
       "      <td>4.079540</td>\n",
       "      <td>-15.472495</td>\n",
       "      <td>-16.445447</td>\n",
       "      <td>-3.342657</td>\n",
       "      <td>-15.360348</td>\n",
       "      <td>2.811957</td>\n",
       "      <td>11.066312</td>\n",
       "      <td>-1.721149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.656549</td>\n",
       "      <td>7.035667</td>\n",
       "      <td>-7.388840</td>\n",
       "      <td>9.045784</td>\n",
       "      <td>-1.946426</td>\n",
       "      <td>8.474975</td>\n",
       "      <td>3.446897</td>\n",
       "      <td>6.481240</td>\n",
       "      <td>5.563569</td>\n",
       "      <td>-0.272866</td>\n",
       "      <td>...</td>\n",
       "      <td>3.862787</td>\n",
       "      <td>3.259748</td>\n",
       "      <td>7.428633</td>\n",
       "      <td>-20.358144</td>\n",
       "      <td>-2.946711</td>\n",
       "      <td>-18.682650</td>\n",
       "      <td>10.160104</td>\n",
       "      <td>-8.257884</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.661408</td>\n",
       "      <td>-7.346004</td>\n",
       "      <td>4.399998</td>\n",
       "      <td>-10.226333</td>\n",
       "      <td>0.535805</td>\n",
       "      <td>-4.238201</td>\n",
       "      <td>-2.220651</td>\n",
       "      <td>13.966324</td>\n",
       "      <td>-6.324431</td>\n",
       "      <td>1.508628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707460</td>\n",
       "      <td>2.040866</td>\n",
       "      <td>-8.380290</td>\n",
       "      <td>0.645318</td>\n",
       "      <td>-5.161406</td>\n",
       "      <td>7.853587</td>\n",
       "      <td>14.894727</td>\n",
       "      <td>-4.128859</td>\n",
       "      <td>13.846052</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.225394</td>\n",
       "      <td>1.563694</td>\n",
       "      <td>11.576329</td>\n",
       "      <td>-2.249650</td>\n",
       "      <td>-1.770594</td>\n",
       "      <td>11.627922</td>\n",
       "      <td>-6.178324</td>\n",
       "      <td>3.360065</td>\n",
       "      <td>-11.349237</td>\n",
       "      <td>16.233691</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.975913</td>\n",
       "      <td>2.143824</td>\n",
       "      <td>4.781468</td>\n",
       "      <td>-0.598354</td>\n",
       "      <td>9.750099</td>\n",
       "      <td>14.131026</td>\n",
       "      <td>-0.712078</td>\n",
       "      <td>-12.659802</td>\n",
       "      <td>-3.705983</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312493</th>\n",
       "      <td>-9.894769</td>\n",
       "      <td>11.089735</td>\n",
       "      <td>8.534893</td>\n",
       "      <td>-8.374133</td>\n",
       "      <td>13.637887</td>\n",
       "      <td>5.184426</td>\n",
       "      <td>1.051620</td>\n",
       "      <td>9.858845</td>\n",
       "      <td>-1.826800</td>\n",
       "      <td>-0.524784</td>\n",
       "      <td>...</td>\n",
       "      <td>3.942639</td>\n",
       "      <td>-6.396674</td>\n",
       "      <td>-17.591382</td>\n",
       "      <td>7.351799</td>\n",
       "      <td>-10.342751</td>\n",
       "      <td>-3.664545</td>\n",
       "      <td>-1.261607</td>\n",
       "      <td>-3.430422</td>\n",
       "      <td>-1.505327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312494</th>\n",
       "      <td>-17.383182</td>\n",
       "      <td>0.928530</td>\n",
       "      <td>-2.247971</td>\n",
       "      <td>7.323248</td>\n",
       "      <td>-1.258868</td>\n",
       "      <td>1.299997</td>\n",
       "      <td>7.680381</td>\n",
       "      <td>7.660841</td>\n",
       "      <td>-8.293676</td>\n",
       "      <td>6.243926</td>\n",
       "      <td>...</td>\n",
       "      <td>2.799460</td>\n",
       "      <td>6.389730</td>\n",
       "      <td>7.101805</td>\n",
       "      <td>-6.931006</td>\n",
       "      <td>6.834814</td>\n",
       "      <td>3.339345</td>\n",
       "      <td>-17.939175</td>\n",
       "      <td>-2.745441</td>\n",
       "      <td>7.506226</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312495</th>\n",
       "      <td>-2.724524</td>\n",
       "      <td>-8.151146</td>\n",
       "      <td>6.320251</td>\n",
       "      <td>1.039138</td>\n",
       "      <td>2.085590</td>\n",
       "      <td>-6.688239</td>\n",
       "      <td>1.824198</td>\n",
       "      <td>-1.174768</td>\n",
       "      <td>-0.240556</td>\n",
       "      <td>2.817313</td>\n",
       "      <td>...</td>\n",
       "      <td>3.016716</td>\n",
       "      <td>14.434292</td>\n",
       "      <td>8.649997</td>\n",
       "      <td>3.334026</td>\n",
       "      <td>-4.751534</td>\n",
       "      <td>9.072261</td>\n",
       "      <td>-1.058854</td>\n",
       "      <td>-8.875137</td>\n",
       "      <td>14.394309</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312496</th>\n",
       "      <td>0.647945</td>\n",
       "      <td>-23.470288</td>\n",
       "      <td>-2.891567</td>\n",
       "      <td>-11.730332</td>\n",
       "      <td>3.737442</td>\n",
       "      <td>-0.502778</td>\n",
       "      <td>10.400979</td>\n",
       "      <td>-0.488360</td>\n",
       "      <td>-3.832730</td>\n",
       "      <td>-3.961692</td>\n",
       "      <td>...</td>\n",
       "      <td>22.711689</td>\n",
       "      <td>-13.302730</td>\n",
       "      <td>5.908286</td>\n",
       "      <td>-2.300022</td>\n",
       "      <td>-7.265795</td>\n",
       "      <td>7.196590</td>\n",
       "      <td>-0.862335</td>\n",
       "      <td>-3.902323</td>\n",
       "      <td>1.783257</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312497</th>\n",
       "      <td>-29.793261</td>\n",
       "      <td>-10.538975</td>\n",
       "      <td>9.558486</td>\n",
       "      <td>-4.459242</td>\n",
       "      <td>12.629509</td>\n",
       "      <td>7.636080</td>\n",
       "      <td>12.137160</td>\n",
       "      <td>-15.345711</td>\n",
       "      <td>16.660747</td>\n",
       "      <td>3.110058</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.732340</td>\n",
       "      <td>-16.281778</td>\n",
       "      <td>17.594014</td>\n",
       "      <td>-10.338802</td>\n",
       "      <td>-31.588791</td>\n",
       "      <td>38.145971</td>\n",
       "      <td>-0.438792</td>\n",
       "      <td>13.043799</td>\n",
       "      <td>7.935081</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312498 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5     \n",
       "0       -0.938415 -23.360631   9.682030  15.125879  46.366661  -7.256437  \\\n",
       "1      -14.591125  -8.008776   2.711165 -14.151475   4.141044  -3.151526   \n",
       "2       -8.656549   7.035667  -7.388840   9.045784  -1.946426   8.474975   \n",
       "3       -7.661408  -7.346004   4.399998 -10.226333   0.535805  -4.238201   \n",
       "4      -15.225394   1.563694  11.576329  -2.249650  -1.770594  11.627922   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "312493  -9.894769  11.089735   8.534893  -8.374133  13.637887   5.184426   \n",
       "312494 -17.383182   0.928530  -2.247971   7.323248  -1.258868   1.299997   \n",
       "312495  -2.724524  -8.151146   6.320251   1.039138   2.085590  -6.688239   \n",
       "312496   0.647945 -23.470288  -2.891567 -11.730332   3.737442  -0.502778   \n",
       "312497 -29.793261 -10.538975   9.558486  -4.459242  12.629509   7.636080   \n",
       "\n",
       "              6          7          8          9    ...        247        248   \n",
       "0        8.299082 -23.070582 -48.915892  23.237752  ...  -1.710768  -0.279310  \\\n",
       "1       -7.338920  19.632322  -1.349845 -26.822912  ...  12.933498   4.079540   \n",
       "2        3.446897   6.481240   5.563569  -0.272866  ...   3.862787   3.259748   \n",
       "3       -2.220651  13.966324  -6.324431   1.508628  ...   0.707460   2.040866   \n",
       "4       -6.178324   3.360065 -11.349237  16.233691  ...  -7.975913   2.143824   \n",
       "...           ...        ...        ...        ...  ...        ...        ...   \n",
       "312493   1.051620   9.858845  -1.826800  -0.524784  ...   3.942639  -6.396674   \n",
       "312494   7.680381   7.660841  -8.293676   6.243926  ...   2.799460   6.389730   \n",
       "312495   1.824198  -1.174768  -0.240556   2.817313  ...   3.016716  14.434292   \n",
       "312496  10.400979  -0.488360  -3.832730  -3.961692  ...  22.711689 -13.302730   \n",
       "312497  12.137160 -15.345711  16.660747   3.110058  ... -26.732340 -16.281778   \n",
       "\n",
       "              249        250        251        252        253        254   \n",
       "0       -2.896621  15.094491   8.561273  -5.811388  31.997964 -13.973196  \\\n",
       "1      -15.472495 -16.445447  -3.342657 -15.360348   2.811957  11.066312   \n",
       "2        7.428633 -20.358144  -2.946711 -18.682650  10.160104  -8.257884   \n",
       "3       -8.380290   0.645318  -5.161406   7.853587  14.894727  -4.128859   \n",
       "4        4.781468  -0.598354   9.750099  14.131026  -0.712078 -12.659802   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "312493 -17.591382   7.351799 -10.342751  -3.664545  -1.261607  -3.430422   \n",
       "312494   7.101805  -6.931006   6.834814   3.339345 -17.939175  -2.745441   \n",
       "312495   8.649997   3.334026  -4.751534   9.072261  -1.058854  -8.875137   \n",
       "312496   5.908286  -2.300022  -7.265795   7.196590  -0.862335  -3.902323   \n",
       "312497  17.594014 -10.338802 -31.588791  38.145971  -0.438792  13.043799   \n",
       "\n",
       "              255  256  \n",
       "0       -5.184306  0.0  \n",
       "1       -1.721149  0.0  \n",
       "2        0.012987  0.0  \n",
       "3       13.846052  0.0  \n",
       "4       -3.705983  0.0  \n",
       "...           ...  ...  \n",
       "312493  -1.505327  2.0  \n",
       "312494   7.506226  2.0  \n",
       "312495  14.394309  2.0  \n",
       "312496   1.783257  2.0  \n",
       "312497   7.935081  2.0  \n",
       "\n",
       "[312498 rows x 257 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data_fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho da memória ocupada :612.73 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.279978</td>\n",
       "      <td>-6.945764</td>\n",
       "      <td>2.888653</td>\n",
       "      <td>4.497243</td>\n",
       "      <td>13.833585</td>\n",
       "      <td>-2.157582</td>\n",
       "      <td>2.476048</td>\n",
       "      <td>-6.859525</td>\n",
       "      <td>-14.594153</td>\n",
       "      <td>6.909106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508715</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.861299</td>\n",
       "      <td>4.503471</td>\n",
       "      <td>2.545420</td>\n",
       "      <td>-1.733839</td>\n",
       "      <td>9.513738</td>\n",
       "      <td>-4.168931</td>\n",
       "      <td>-1.541486</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.353291</td>\n",
       "      <td>-2.381271</td>\n",
       "      <td>0.808882</td>\n",
       "      <td>-4.207650</td>\n",
       "      <td>1.235489</td>\n",
       "      <td>-0.937089</td>\n",
       "      <td>-2.189581</td>\n",
       "      <td>5.837121</td>\n",
       "      <td>-0.402729</td>\n",
       "      <td>-7.975187</td>\n",
       "      <td>...</td>\n",
       "      <td>3.845393</td>\n",
       "      <td>1.217139</td>\n",
       "      <td>-4.600423</td>\n",
       "      <td>-4.906532</td>\n",
       "      <td>-0.993917</td>\n",
       "      <td>-4.582790</td>\n",
       "      <td>0.836004</td>\n",
       "      <td>3.301656</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.582699</td>\n",
       "      <td>2.091819</td>\n",
       "      <td>-2.204475</td>\n",
       "      <td>2.689478</td>\n",
       "      <td>-0.580720</td>\n",
       "      <td>2.519762</td>\n",
       "      <td>1.028389</td>\n",
       "      <td>1.926974</td>\n",
       "      <td>1.659902</td>\n",
       "      <td>-0.081191</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148443</td>\n",
       "      <td>0.972552</td>\n",
       "      <td>2.208658</td>\n",
       "      <td>-6.073893</td>\n",
       "      <td>-0.876192</td>\n",
       "      <td>-5.574006</td>\n",
       "      <td>3.020793</td>\n",
       "      <td>-2.463756</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.285796</td>\n",
       "      <td>-2.184213</td>\n",
       "      <td>1.312748</td>\n",
       "      <td>-3.040607</td>\n",
       "      <td>0.159859</td>\n",
       "      <td>-1.260185</td>\n",
       "      <td>-0.662536</td>\n",
       "      <td>4.152478</td>\n",
       "      <td>-1.886907</td>\n",
       "      <td>0.448492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210285</td>\n",
       "      <td>0.608896</td>\n",
       "      <td>-2.491732</td>\n",
       "      <td>0.192532</td>\n",
       "      <td>-1.534677</td>\n",
       "      <td>2.343133</td>\n",
       "      <td>4.428516</td>\n",
       "      <td>-1.231853</td>\n",
       "      <td>4.116718</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.542527</td>\n",
       "      <td>0.464864</td>\n",
       "      <td>3.453821</td>\n",
       "      <td>-0.668939</td>\n",
       "      <td>-0.528260</td>\n",
       "      <td>3.457212</td>\n",
       "      <td>-1.843315</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>-3.386067</td>\n",
       "      <td>4.826623</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.371500</td>\n",
       "      <td>0.639614</td>\n",
       "      <td>1.421589</td>\n",
       "      <td>-0.178520</td>\n",
       "      <td>2.898888</td>\n",
       "      <td>4.216020</td>\n",
       "      <td>-0.211780</td>\n",
       "      <td>-3.777077</td>\n",
       "      <td>-1.101943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312493</th>\n",
       "      <td>-3.227220</td>\n",
       "      <td>3.610345</td>\n",
       "      <td>2.783634</td>\n",
       "      <td>-2.726261</td>\n",
       "      <td>4.447981</td>\n",
       "      <td>1.687828</td>\n",
       "      <td>0.342956</td>\n",
       "      <td>3.209620</td>\n",
       "      <td>-0.595843</td>\n",
       "      <td>-0.170847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.283555</td>\n",
       "      <td>-2.086312</td>\n",
       "      <td>-5.727004</td>\n",
       "      <td>2.397766</td>\n",
       "      <td>-3.367159</td>\n",
       "      <td>-1.195226</td>\n",
       "      <td>-0.410725</td>\n",
       "      <td>-1.118866</td>\n",
       "      <td>-0.490070</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312494</th>\n",
       "      <td>-5.669573</td>\n",
       "      <td>0.302290</td>\n",
       "      <td>-0.733209</td>\n",
       "      <td>2.384138</td>\n",
       "      <td>-0.410612</td>\n",
       "      <td>0.423224</td>\n",
       "      <td>2.504934</td>\n",
       "      <td>2.494043</td>\n",
       "      <td>-2.705021</td>\n",
       "      <td>2.032756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911385</td>\n",
       "      <td>2.083987</td>\n",
       "      <td>2.312045</td>\n",
       "      <td>-2.260585</td>\n",
       "      <td>2.225124</td>\n",
       "      <td>1.089100</td>\n",
       "      <td>-5.840231</td>\n",
       "      <td>-0.895459</td>\n",
       "      <td>2.443707</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312495</th>\n",
       "      <td>-0.888637</td>\n",
       "      <td>-2.653666</td>\n",
       "      <td>2.061326</td>\n",
       "      <td>0.338299</td>\n",
       "      <td>0.680187</td>\n",
       "      <td>-2.177406</td>\n",
       "      <td>0.594933</td>\n",
       "      <td>-0.382454</td>\n",
       "      <td>-0.078488</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982114</td>\n",
       "      <td>4.707729</td>\n",
       "      <td>2.816070</td>\n",
       "      <td>1.087365</td>\n",
       "      <td>-1.546897</td>\n",
       "      <td>2.958897</td>\n",
       "      <td>-0.344718</td>\n",
       "      <td>-2.894665</td>\n",
       "      <td>4.686174</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312496</th>\n",
       "      <td>0.211298</td>\n",
       "      <td>-7.640925</td>\n",
       "      <td>-0.943118</td>\n",
       "      <td>-3.818896</td>\n",
       "      <td>1.218940</td>\n",
       "      <td>-0.163683</td>\n",
       "      <td>3.392260</td>\n",
       "      <td>-0.158989</td>\n",
       "      <td>-1.250079</td>\n",
       "      <td>-1.289758</td>\n",
       "      <td>...</td>\n",
       "      <td>7.393958</td>\n",
       "      <td>-4.338730</td>\n",
       "      <td>1.923486</td>\n",
       "      <td>-0.750185</td>\n",
       "      <td>-2.365433</td>\n",
       "      <td>2.347145</td>\n",
       "      <td>-0.280739</td>\n",
       "      <td>-1.272777</td>\n",
       "      <td>0.580552</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312497</th>\n",
       "      <td>-9.717133</td>\n",
       "      <td>-3.431041</td>\n",
       "      <td>3.117480</td>\n",
       "      <td>-1.451739</td>\n",
       "      <td>4.119097</td>\n",
       "      <td>2.485982</td>\n",
       "      <td>3.958517</td>\n",
       "      <td>-4.995910</td>\n",
       "      <td>5.433889</td>\n",
       "      <td>1.012502</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.702911</td>\n",
       "      <td>-5.310349</td>\n",
       "      <td>5.727861</td>\n",
       "      <td>-3.372041</td>\n",
       "      <td>-10.283964</td>\n",
       "      <td>12.441317</td>\n",
       "      <td>-0.142852</td>\n",
       "      <td>4.254218</td>\n",
       "      <td>2.583324</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312498 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3          4         5         6     \n",
       "0      -0.279978 -6.945764  2.888653  4.497243  13.833585 -2.157582  2.476048  \\\n",
       "1      -4.353291 -2.381271  0.808882 -4.207650   1.235489 -0.937089 -2.189581   \n",
       "2      -2.582699  2.091819 -2.204475  2.689478  -0.580720  2.519762  1.028389   \n",
       "3      -2.285796 -2.184213  1.312748 -3.040607   0.159859 -1.260185 -0.662536   \n",
       "4      -4.542527  0.464864  3.453821 -0.668939  -0.528260  3.457212 -1.843315   \n",
       "...          ...       ...       ...       ...        ...       ...       ...   \n",
       "312493 -3.227220  3.610345  2.783634 -2.726261   4.447981  1.687828  0.342956   \n",
       "312494 -5.669573  0.302290 -0.733209  2.384138  -0.410612  0.423224  2.504934   \n",
       "312495 -0.888637 -2.653666  2.061326  0.338299   0.680187 -2.177406  0.594933   \n",
       "312496  0.211298 -7.640925 -0.943118 -3.818896   1.218940 -0.163683  3.392260   \n",
       "312497 -9.717133 -3.431041  3.117480 -1.451739   4.119097  2.485982  3.958517   \n",
       "\n",
       "             7          8         9    ...       247       248       249   \n",
       "0      -6.859525 -14.594153  6.909106  ... -0.508715 -0.083333 -0.861299  \\\n",
       "1       5.837121  -0.402729 -7.975187  ...  3.845393  1.217139 -4.600423   \n",
       "2       1.926974   1.659902 -0.081191  ...  1.148443  0.972552  2.208658   \n",
       "3       4.152478  -1.886907  0.448492  ...  0.210285  0.608896 -2.491732   \n",
       "4       0.998971  -3.386067  4.826623  ... -2.371500  0.639614  1.421589   \n",
       "...          ...        ...       ...  ...       ...       ...       ...   \n",
       "312493  3.209620  -0.595843 -0.170847  ...  1.283555 -2.086312 -5.727004   \n",
       "312494  2.494043  -2.705021  2.032756  ...  0.911385  2.083987  2.312045   \n",
       "312495 -0.382454  -0.078488  0.917197  ...  0.982114  4.707729  2.816070   \n",
       "312496 -0.158989  -1.250079 -1.289758  ...  7.393958 -4.338730  1.923486   \n",
       "312497 -4.995910   5.433889  1.012502  ... -8.702911 -5.310349  5.727861   \n",
       "\n",
       "             250        251        252       253       254       255  256  \n",
       "0       4.503471   2.545420  -1.733839  9.513738 -4.168931 -1.541486  0.0  \n",
       "1      -4.906532  -0.993917  -4.582790  0.836004  3.301656 -0.511802  0.0  \n",
       "2      -6.073893  -0.876192  -5.574006  3.020793 -2.463756  0.003800  0.0  \n",
       "3       0.192532  -1.534677   2.343133  4.428516 -1.231853  4.116718  0.0  \n",
       "4      -0.178520   2.898888   4.216020 -0.211780 -3.777077 -1.101943  0.0  \n",
       "...          ...        ...        ...       ...       ...       ...  ...  \n",
       "312493  2.397766  -3.367159  -1.195226 -0.410725 -1.118866 -0.490070  2.0  \n",
       "312494 -2.260585   2.225124   1.089100 -5.840231 -0.895459  2.443707  2.0  \n",
       "312495  1.087365  -1.546897   2.958897 -0.344718 -2.894665  4.686174  2.0  \n",
       "312496 -0.750185  -2.365433   2.347145 -0.280739 -1.272777  0.580552  2.0  \n",
       "312497 -3.372041 -10.283964  12.441317 -0.142852  4.254218  2.583324  2.0  \n",
       "\n",
       "[312498 rows x 257 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data(Fourier=True, Normalizing= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape array (100000000, 1),\n",
      "\n",
      "                Clear array \n",
      " [[ 0.0000000e+00-6.1037244e-05j]\n",
      " [-3.0518622e-05+3.0518622e-05j]\n",
      " [-6.1037244e-05-3.0518622e-05j]\n",
      " ...\n",
      " [-6.1037244e-05+6.1037244e-05j]\n",
      " [ 0.0000000e+00-3.0518622e-05j]\n",
      " [ 9.1555863e-05-1.8311173e-04j]] \n",
      "  \n",
      "                memory usage 762.94 MB\n"
     ]
    }
   ],
   "source": [
    "data.clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape array (100000000, 1),\n",
      "\n",
      "               WIFI array \n",
      " [[ 0.0000000e+00+6.1037244e-05j]\n",
      " [ 1.5259311e-04-3.0518622e-05j]\n",
      " [ 6.1037244e-05-1.5259311e-04j]\n",
      " ...\n",
      " [-2.1363035e-04-1.2207449e-04j]\n",
      " [-9.1555863e-05-2.4414898e-04j]\n",
      " [-6.1037244e-05+1.8311173e-04j]] \n",
      "  \n",
      "                memory usage 762.94 MB\n"
     ]
    }
   ],
   "source": [
    "data.wifi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape array (100000000, 1),\n",
      "\n",
      "                LTE array \n",
      "[[-3.0518622e-05+0.0000000e+00j]\n",
      " [-9.1555863e-05+1.2207449e-04j]\n",
      " [-6.1037244e-05+6.1037244e-05j]\n",
      " ...\n",
      " [-9.1555863e-05+1.5259311e-04j]\n",
      " [-2.7466760e-04+6.1037244e-05j]\n",
      " [-3.0518623e-04+6.1037244e-05j]] \n",
      "  \n",
      "                memory usage 762.94 MB\n"
     ]
    }
   ],
   "source": [
    "data.lte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch = NeuralNetCNN(columns= data_fourier.shape[1] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(256, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(32, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(48, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(48, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(48, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(48, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=32, out_features=3, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Torch.Cnn\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtendedClassifier(\n",
       "  (conv): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(256, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(32, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(48, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(48, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(48, 48, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(48, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (4): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Tanh()\n",
       "        (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=32, out_features=3, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "    (6): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Torch.ExtenderClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (234373, 256) float64\n",
      "X_Test shape: (78125, 256) float64\n",
      "y_train shape: (234373,) float64\n",
      "y_test shape: (78125,) float64\n",
      "\n",
      "--------\n",
      "X_train device: cpu\n",
      "X_Test device: cpu\n",
      "y_train device: cpu\n",
      "y_test device: cpu\n",
      "Valor 0: 104166 ocorrência(s)- 0.33%\n",
      "Valor 1: 104166 ocorrência(s)- 0.33%\n",
      "Valor 2: 104166 ocorrência(s)- 0.33%\n",
      "Dataset :  (312498, 257)\n"
     ]
    }
   ],
   "source": [
    "data.Spliting(data= data_fourier, random_state= 30, test_size = 0.25, shuffle = True, inplace= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([256, 256]) y torch.Size([256])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001391F3F7A90>, <torch.utils.data.dataloader.DataLoader object at 0x0000013950C5E090>)\n",
      "Length of train dataloader: 916 batches of 256\n",
      "Length of test dataloader: 306 batches of 256\n"
     ]
    }
   ],
   "source": [
    "train_dataloader , test_dataloader = data.DataLoaders(batch_size=256, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.10066 | Train accuracy: 34.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:06<10:02, 66.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 168.44793 | Test accuracy: 35.63%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 1.09421 | Train accuracy: 36.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:21<09:29, 71.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 167.58927 | Test accuracy: 37.64%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 1.08777 | Train accuracy: 38.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:29<08:09, 69.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 166.69983 | Test accuracy: 39.40%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 1.07853 | Train accuracy: 41.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:40<07:03, 70.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 165.65956 | Test accuracy: 40.88%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 1.06678 | Train accuracy: 43.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:41<05:35, 67.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 164.06107 | Test accuracy: 42.77%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 1.05245 | Train accuracy: 45.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [06:44<04:21, 65.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 162.34507 | Test accuracy: 44.41%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 1.03905 | Train accuracy: 47.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [07:50<03:16, 65.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 161.17756 | Test accuracy: 45.92%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 1.02602 | Train accuracy: 49.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [09:01<02:14, 67.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 159.51661 | Test accuracy: 47.50%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 1.01579 | Train accuracy: 50.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [10:12<01:08, 68.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 158.74077 | Test accuracy: 48.19%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 1.00547 | Train accuracy: 51.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:24<00:00, 68.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 157.82004 | Test accuracy: 48.99%\n",
      "CPU times: total: 18min 39s\n",
      "Wall time: 11min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
      "0          48.14      233.63           51.79        0.99\n",
      "1          48.01      233.72           52.13        0.99\n",
      "2          48.14      233.70           52.43        0.99\n",
      "3          48.00      233.80           52.75        0.99\n",
      "4          47.98      234.21           52.84        0.99\n"
     ]
    }
   ],
   "source": [
    "print(Torch(test= True, train= True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.49      0.80      0.61     19464\n",
      "        WIFI       0.34      0.01      0.01     19406\n",
      "         LTE       0.64      0.86      0.74     19723\n",
      "\n",
      "    accuracy                           0.56     58593\n",
      "   macro avg       0.49      0.56      0.45     58593\n",
      "weighted avg       0.49      0.56      0.45     58593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data.y_test, Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de linhas 100000000 equivalente a 40 segundos\n",
      " Pulando em 0 segundos , em 1 vezes\n",
      "Tamanho da memoria ocupada :4577.87 MB\n",
      "CPU times: total: 14min 1s\n",
      "Wall time: 34min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 20001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = DATA_1M(seconds=40,columns=20000, jump_time =0, n_jumps=1)\n",
    "print(data)\n",
    "data_fourier = data(Fourier=True)\n",
    "data_fourier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (21750, 20000) float64\n",
      "X_Test shape: (8250, 20000) float64\n",
      "y_train shape: (21750,) float64\n",
      "y_test shape: (8250,) float64\n",
      "\n",
      "--------\n",
      "Valor 0: 10000 ocorrência(s)- 0.33%\n",
      "Valor 1: 10000 ocorrência(s)- 0.33%\n",
      "Valor 2: 10000 ocorrência(s)- 0.33%\n",
      "Dataset :  (30000, 20001)\n"
     ]
    }
   ],
   "source": [
    "data.Spliting(data= data_fourier, random_state= 38, test_size = 0.275, shuffle = True, inplace= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape , Y shape torch.Size([64, 20000]) torch.Size([64])\n",
      "----------------\n",
      "\n",
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001E0EE4EFFD0>, <torch.utils.data.dataloader.DataLoader object at 0x000001E0EE1D94D0>)\n",
      "Length of train dataloader: 340 batches of 64\n",
      "Length of test dataloader: 129 batches of 64\n"
     ]
    }
   ],
   "source": [
    "train_dataloader , test_dataloader = data.DataLoaders(batch_size=64, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0\n",
      "---------\n",
      "Train loss: 1.34507 | Train accuracy: 38.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [13:47<3:13:01, 827.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 84.69437 | Test accuracy: 41.67%\n",
      " Epoch: 1\n",
      "---------\n",
      "Train loss: 1.23940 | Train accuracy: 48.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [27:15<2:56:50, 816.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 90.13758 | Test accuracy: 30.20%\n",
      " Epoch: 2\n",
      "---------\n",
      "Train loss: 1.08449 | Train accuracy: 65.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [41:02<2:44:14, 821.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 85.79268 | Test accuracy: 40.52%\n",
      " Epoch: 3\n",
      "---------\n",
      "Train loss: 0.99929 | Train accuracy: 74.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [54:35<2:29:58, 818.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.04421 | Test accuracy: 39.24%\n",
      " Epoch: 4\n",
      "---------\n",
      "Train loss: 0.95456 | Train accuracy: 79.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [1:08:34<2:17:34, 825.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.70774 | Test accuracy: 38.63%\n",
      " Epoch: 5\n",
      "---------\n",
      "Train loss: 0.92030 | Train accuracy: 82.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [1:22:22<2:03:55, 826.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.27540 | Test accuracy: 39.31%\n",
      " Epoch: 6\n",
      "---------\n",
      "Train loss: 0.88564 | Train accuracy: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [1:35:11<1:47:41, 807.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.88641 | Test accuracy: 38.86%\n",
      " Epoch: 7\n",
      "---------\n",
      "Train loss: 0.85450 | Train accuracy: 89.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [1:48:31<1:33:56, 805.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.64834 | Test accuracy: 37.73%\n",
      " Epoch: 8\n",
      "---------\n",
      "Train loss: 0.83719 | Train accuracy: 90.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [2:02:30<1:21:34, 815.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.55235 | Test accuracy: 38.43%\n",
      " Epoch: 9\n",
      "---------\n",
      "Train loss: 0.82399 | Train accuracy: 92.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [2:16:19<1:08:19, 819.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.34147 | Test accuracy: 38.42%\n",
      " Epoch: 10\n",
      "---------\n",
      "Train loss: 0.81576 | Train accuracy: 92.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [2:30:09<54:51, 822.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.66981 | Test accuracy: 38.00%\n",
      " Epoch: 11\n",
      "---------\n",
      "Train loss: 0.81025 | Train accuracy: 93.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [2:43:41<40:58, 819.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.86864 | Test accuracy: 37.72%\n",
      " Epoch: 12\n",
      "---------\n",
      "Train loss: 0.80280 | Train accuracy: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [2:57:12<27:13, 816.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.00118 | Test accuracy: 39.11%\n",
      " Epoch: 13\n",
      "---------\n",
      "Train loss: 0.79937 | Train accuracy: 94.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [3:10:39<13:34, 814.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 86.97332 | Test accuracy: 39.22%\n",
      " Epoch: 14\n",
      "---------\n",
      "Train loss: 0.79809 | Train accuracy: 94.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [3:24:08<00:00, 816.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 87.60427 | Test accuracy: 38.22%\n",
      "CPU times: total: 20h 14min 1s\n",
      "Wall time: 3h 24min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Torch.training_loop(data_loader_train=train_dataloader,\n",
    "data_loader_test = test_dataloader,\n",
    "        model=Torch.Cnn, \n",
    "        loss_fn=Torch.loss_fn,\n",
    "        optimizer=Torch.optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=Torch.device,\n",
    "        epochs = 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Accuracy  Test Loss   Train Accuracy  Train Loss\n",
      "0       38.215467   87.604266       38.984375    1.345068\n",
      "1       38.215467   87.604266       48.654684    1.239400\n",
      "2       38.215467   87.604266       65.315564    1.084490\n",
      "3       38.215467   87.604266       74.356447    0.999285\n",
      "4       38.215467   87.604266       79.091605    0.954565\n",
      "5       38.215467   87.604266       82.588848    0.920301\n",
      "6       38.215467   87.604266       85.979541    0.885640\n",
      "7       38.215467   87.604266       89.214495    0.854497\n",
      "8       38.215467   87.604266       90.866353    0.837193\n",
      "9       38.215467   87.604266       92.227158    0.823987\n",
      "10      38.215467   87.604266       92.979133    0.815760\n",
      "11      38.215467   87.604266       93.506774    0.810251\n",
      "12      38.215467   87.604266       94.273046    0.802804\n",
      "13      38.215467   87.604266       94.605971    0.799371\n",
      "14      38.215467   87.604266       94.717967    0.798092\n"
     ]
    }
   ],
   "source": [
    "print(Torch(test= True, train= True))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       CLEAR       0.39      0.55      0.45      2716\n",
      "        WIFI       0.41      0.34      0.37      2809\n",
      "         LTE       0.35      0.25      0.29      2725\n",
      "\n",
      "    accuracy                           0.38      8250\n",
      "   macro avg       0.38      0.38      0.37      8250\n",
      "weighted avg       0.38      0.38      0.37      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['CLEAR','WIFI','LTE']\n",
    "\n",
    "print(classification_report(data.y_test, Torch.Making_Predictions(model = Torch.Cnn, data_loader= test_dataloader),target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
